FAKULTETSOMR√ÖDET F√ñR
NATURVETENSKAPER OCH TEKNIK

pro gradu-avhandling
Matematik

Optimal stokastisk reglering och
estimering med Kalmanltret
Skribent:

Handledare:

Tuomas Virtanen

Mikael Kurula

2020

Tuomas Virtanen

F√∂rord
Arbetet som presenteras i denna avhandling, som handlar om Kalmanltret och
optimal reglering av linj√§ra stokastiska system, har gjorts vid Fakulteten f√∂r naturvetenskaper och teknik vid √Öbo Akademi. St√∂rsta delen av arbetet gjordes
under sommaren och h√∂sten 2019. Stort tack till min handledare Mikael Kurula
med all hj√§lp och tid under arbetets g√•ng. Jag vill √§ven tacka professor Paavo
Salminen f√∂r hans kommentarer. Jag vill ocks√• tacka min familj och mina v√§nner
f√∂r all st√∂d under denna tid.

√Öbo, Juli 2020

Tuomas Virtanen

ii

Tuomas Virtanen

Abstrakt
Linj√§ra system anv√§nds f√∂r matematiska modeller inom m√•nga olika omr√•den, bland annat reglerteknik. Avhandlingen behandlar teori f√∂r MIMO-system
(eng. Multiple Input Multiple Output), det vill s√§ga modeller som best√•r av
tillst√•ndsvariabler, en styrsignal best√•ende av era inputvariabler och en m√§tsignal som ger information om era av systemets tillst√•ndsvariabler. D√• systemet
dessutom p√•verkas av st√∂rningar, m√§tsignalen p√•verkas av m√§tfel och endast n√•gra av tillst√•ndsvariablerna kan m√§tas √§r systemet stokastiskt. Huvudsyftet med
avhandlingen √§r att se p√• hur man kan reglera ett stokastiskt MIMO-system
optimalt med avseende p√• att minimera en kvadratisk kostnadsfunktional. Detta √§r det s√• kallade LQG-problemet (eng. Linear Quadratic Gaussian) som √§r
ett tv√•delat problem. Eftersom systemet √§r stokastiskt m√•ste systemets tillst√•nd
estimeras och sedan m√•ste en styrsignal best√§mmas s√• att kostnaden minimeras. Metoden f√∂r estimeringen av tillst√•ndet √§r ett Kalmanlter och i denna avhandling delas ltret upp i tv√• delar, Kalmanprediktorn och Kalmankorrektorn.
Minimeringen av kostnaden kan g√∂ras separat och sedan kan skattningen given
av prediktorn eller korrektorn anv√§ndas f√∂r att ber√§kna den optimala reglersignalen f√∂r systemet. Avhandlingen belyser med ett exempel p√• reglering av tv√•
kopplade eln√§tverk att reglering med anv√§ndning av skattningen som ges av prediktorn fungerar och b√∂r anv√§ndas √§ven d√• m√§tsignalen saknas en l√§ngre tid. F√∂r
exemplet har ett simuleringsprogram skrivits i MatLab.

iii

INNEH√ÖLL

Tuomas Virtanen

Inneh√•ll
1 Inledning

1

2 Linj√§r systemteori

4

2.1

2.2

2.3

2.4

Introduktion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

4

2.1.1

Sampling av tidskontinuerliga linj√§ra system . . . . . . . .

6

Egenskaper hos tidsdiskreta LTI-system . . . . . . . . . . . . . . .

8

2.2.1

Styrbarhet . . . . . . . . . . . . . . . . . . . . . . . . . . .

8

2.2.2

Observerbarhet

. . . . . . . . . . . . . . . . . . . . . . . .

10

2.2.3

Stabiliserbarhet . . . . . . . . . . . . . . . . . . . . . . . .

12

Luenbergerobservat√∂r . . . . . . . . . . . . . . . . . . . . . . . . .

14

2.3.1

. . . . . . . . . . . . . . . . . . . . .

15

Optimal reglering . . . . . . . . . . . . . . . . . . . . . . . . . . .

16

2.4.1

21

Separationsprincipen

O√§ndlig tidshorisont

. . . . . . . . . . . . . . . . . . . . .

3 Optimal stokastisk estimering

23

3.1

Denitioner och antaganden f√∂r diskreta stokastiska system . . . .

23

3.2

Estimering med Kalmanltret

. . . . . . . . . . . . . . . . . . . .

26

3.3

Station√§rt Kalmanlter . . . . . . . . . . . . . . . . . . . . . . . .

39

3.4

Sampling av tidskontinuerliga stokastiska system . . . . . . . . . .

41

4 Optimal stokastisk reglering

47

4.1

Reglerproblemet . . . . . . . . . . . . . . . . . . . . . . . . . . . .

47

4.2

Minimering av kostnaden genom tillst√•nds√•terkoppling

51

4.3

Minimering av kostnaden genom √•terkoppling av det skattade till-

4.4

. . . . . .

st√•ndet . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

54

Optimal reglering av tv√• kopplade eln√§tverk

58

iv

. . . . . . . . . . . .

INNEH√ÖLL

Tuomas Virtanen

5 Sammanfattande diskussion

65

A Matristeori

67

A.1

Matrisalgebra

. . . . . . . . . . . . . . . . . . . . . . . . . . . . .

67

A.2

Matrisexponentialfunktionen . . . . . . . . . . . . . . . . . . . . .

70

B Sannolikhetsteori
B.1

B.2

72

Grundl√§ggande sannolikhetsl√§ra . . . . . . . . . . . . . . . . . . .

72

B.1.1

V√§ntev√§rde och varians . . . . . . . . . . . . . . . . . . . .

73

B.1.2

F√∂rdelningsfunktion . . . . . . . . . . . . . . . . . . . . . .

74

B.1.3

Oberoende stokastiska variabler

. . . . . . . . . . . . . . .

75

B.1.4

Betingat v√§ntev√§rde

. . . . . . . . . . . . . . . . . . . . .

76

Flerdimensionella stokastiska variabler
B.2.1

p-dimensionell

. . . . . . . . . . . . . . .

77

normalf√∂rdelning . . . . . . . . . . . . . . .

80

C Programkod

81

C.1

Exempel 3.24

. . . . . . . . . . . . . . . . . . . . . . . . . . . . .

81

C.2

Kopplade eln√§tverk . . . . . . . . . . . . . . . . . . . . . . . . . .

85

Litteratur

90

v

KAPITEL 1.

INLEDNING

Tuomas Virtanen

Kapitel 1
Inledning
Ett system av linj√§ra dierentialekvationer anv√§nds f√∂r att bland annat beskriva
biologiska, fysikaliska eller nansiella modeller. Inom reglerteori studeras system
som har styrbara variabler, exempelvis acceleration, samt en m√§tsignal som ger
n√•gon information om systemets olika tillst√•nd, exempelvis hastighet och position. D√• systemets tillst√•nd dessutom p√•verkas av st√∂rningar och m√§tsignalen
inneh√•ller m√§tfel, kan systemet modelleras som ett stokastiskt system. Ett exempel p√• ett s√•dant system √§r satellitnavigering, d√§r GPS-mottagaren ber√§knar
sin position utg√•ende fr√•n m√§tsignaler fr√•n era satelliter. √Öterkoppling √§r ett
centralt begrepp inom reglerteori och med detta avses att m√§tsignalen anv√§nds
f√∂r att reglera systemet.
Det linj√§rkvadratiska gaussiska reglerproblemet (LQG-problemet) √§r ett
v√§lstuderat och fundamentalt stokastiskt reglerproblem d√§r modellen √§r linj√§r,
kostnadsfunktionalen √§r kvadratisk, st√∂rningarna samt m√§tfelen √§r additivt
gaussiskt vitt brus och problemet √§r att hitta en reglersignal som minimerar
kostnadsfunktionalen.

Detta

problem

√§r

tv√•delat,

√•

ena

sidan

har

vi

det

linj√§rkvadratiska estimeringsproblemet (LQE) att skatta systemets tillst√•nd, √•
andra sidan har vi det linj√§rkvadratiska reglerproblemet (LQR) att konstruera
sj√§lva regulatorn som reglerar systemet optimalt. Det visar sig att dessa tv√•
problem kan l√∂sas oberoende av varandra och l√∂sningen p√• estimeringsproblemet
i diskret tid ges av det s√• kallade Kalmanltret, utvecklat huvudsakligen av den
ungerskf√∂dda amerikanska matematikern Rudolf Kalman p√• 1960-talet.
Avhandlingens uppl√§gg √§r att i kapitel 2 ge en kort introduktion till linj√§r systemteori av deterministiska system. I denna avhandling anv√§nds en s√•

1

KAPITEL 1.

INLEDNING

Tuomas Virtanen

kallad tillst√•ndsmodell f√∂r linj√§ra system som introduceras i introduktionskapitlet. Tillst√•ndsmodellen bygger p√• dierentialekvationer som beskriver systemet.
Ddierentialekvationen f√∂r tillst√•ndsvektorn l√∂ses i introduktionskapitlet. Denna
l√∂sning samplas, vilket betyder att systemet i kontinuerlig tid √∂verf√∂rs till ett
diskretiserat system. Styrbarhet, observerbarhet och stabiliserbarhet √§r n√•gra
egenskaper som g√•s igenom i korthet f√∂r system i diskret tid. Dessa egenskaper √§r viktiga f√∂r att regleringen av systemet ska vara anv√§ndbar och speciellt
viktiga f√∂r att kunna minimera kostnaden f√∂r regleringen. √Öterkoppling och optimal reglering av deterministiska system samt konstruktionen av en s√• kallad
Luenbergerobservat√∂r introduceras ocks√• i introduktionskapitlet. F√∂r detta introduktionskapitel har i huvudsak [HRS07], [Lue79], [LXP08] och [TSH01] anv√§nts.
Kapitel 3 behandlar teorin f√∂r optimal stokastisk estimering. I detta kapitel
denieras stokastiska system och vilka antaganden som sedan anv√§nds f√∂r att
bygga upp teorin f√∂r att kunna estimera tillst√•ndsvektorn. Detta g√∂rs vanligtvis
med ett s√• kallat Kalmanlter, men i denna avhandling ges en tv√•delad metod f√∂r
skattningen genom Kalmanprediktorn och Kalmankorrektorn. Id√©n f√∂r att dela
upp Kalmanltret har tagits fr√•n [LXP08] och i denna avhandling g√∂rs ett f√∂rs√∂k att rigor√∂st deniera och h√§rleda formler f√∂r att ber√§kna dessa skattningar,
d√§r ocks√• [LR95] och [√Öst70] har varit till stor hj√§lp. F√∂r den stokastiska teorin
har [Gir03], [Kay93], [JP03] och [Ros10] anv√§nts som k√§llor. Meningen med det
uppdelade Kalmanltret √§r att ha en optimal skattning av tillst√•ndet b√•de d√• ny
information om systemet √§r tillg√§ngligt och d√• ingen ny information √§r tillg√§nglig men en optimal skattning beh√∂vs f√∂r att optimalt reglera systemet. I detta
kapitel introduceras ocks√• kort det station√§ra Kalmanltret och samplingen av
stokastiska system i kontinuerlig tid, f√∂r dessa har ut√∂ver [√Öst70] ocks√• [HRS07]
anv√§nts som k√§lla.
Kapitel 4 behandlar teorin f√∂r optimal stokastisk reglering. I detta kapitel presenteras LQG-problemet och verktygen f√∂r att l√∂sa minimeringsproblemet av den
kvadratiska kostnadsfunktionalen h√§rleds. Konstruktionen av den optimala regulatorn f√∂r systemet best√§ms b√•de d√• m√§tsignalen ger exakt systemets tillst√•nd
och d√• m√§tsignalen p√•verkas av brus. Det andra fallet √§r huvudresultatet och ger
allts√• den optimala reglersignalen f√∂r det stokastiska systemet d√§r tillst√•ndsvektorn estimeras med Kalmanprediktorn eller Kalmankorrektorn introducerade i
kapitel 3.

2

KAPITEL 1.

INLEDNING

Tuomas Virtanen

F√∂r att till√§mpa resultatet nns ett exempel p√• reglering av kopplade eln√§tverk d√§r artiklarna [AA11], [PMH13], [Ros+13] och [Sha+16] har studerats f√∂r
√§ndam√•let. Dierentialekvationerna samt olika parameterv√§rden √§r tagna ur artiklarna. F√∂r till√§mpningen har ett simuleringsprogram skrivits i MatLab och
programkoden f√∂r detta hittas i bilagan.
I bilagan nns ocks√• grundl√§ggande teori f√∂r matrisalgebra, matrisexponentialfunktionen och sannolikhetsteori. Teorin f√∂r betingade v√§ntev√§rdet och erdimensionella normalf√∂rdelningen √§r synnerligen viktiga och l√§saren ombeds bekanta sig med dessa f√∂re kapitel 3.

3

KAPITEL 2.

LINJ√ÑR SYSTEMTEORI

Tuomas Virtanen

Kapitel 2
Linj√§r systemteori
2.1 Introduktion
Matematiska modeller vars beteende kan beskrivas med hj√§lp av era linj√§ra
dierentialekvationer ger upphov till teorin om linj√§ra system. Detta kapitel introducerar deterministiska tidsinvarianta linj√§ra system och deras egenskaper.
Deterministisk system- och reglerteori fungerar som en introduktion till den mera kr√§vande stokastiska reglerteorin som √§r den huvudsakliga teorin i denna avhandling. Som grundl√§ggande teori f√∂r linj√§r systemteori anv√§nds matristeori
samt linj√§r algebra och en kort sammanfattning av det som anv√§nts h√§r nns i
bilaga A.
Exemplet nedan anv√§nds som ett genomg√•ende exempel i avhandlingen f√∂r
att belysa de olika teoridelarna. Exemplet √§r ett utvidgat exempel av [S√§r13,
Exempel 3.6, s. 4345].

Exempel 2.1.
i planet. S√§tt
respektive
vill s√§ga

L√•t

x3 =

x1

=0

och

x2

dx1
och
dt

y -riktning.

dx3
dt

och

vara

x4 =

x-

dx2
. D√• √§r
dt

dx4
dt

u = (u1 , u2 )T . D√•
‚éõ ‚éû
dx1
dt
‚éú dx
‚éü
‚éú dt2 ‚éü
‚éú ‚éü
‚éú dx3 ‚éü
‚éù dt ‚é†
dx4
dt

x3

y -koordinaterna

och

x4

f√∂r en punkt

punktens hastighet i

x-

Anta att accelerationen √§r noll i b√•da riktningarna, det

= 0.

Vidare anta att vi kan styra punktens acceleration

och beteckna dessa inputvariabler med
och

respektive

u1

och

u2 .

L√•t nu

x = (x1 , x2 , x3 , x4 )T

kan vi beskriva systemets beteende p√• vektorform enligt

‚éõ
0
‚éú
‚éú0
=‚éú
‚éú0
‚éù
0

‚éû‚éõ ‚éû ‚éõ
0 1 0
x1
0
‚éü‚éú ‚éü ‚éú
‚éú ‚éü ‚éú
0 0 1‚éü
‚éü ‚éúx2 ‚éü + ‚éú0
‚éú ‚éü ‚éú
0 0 0‚éü
‚é† ‚éùx3 ‚é† ‚éù1
0 0 0
x4
0
4

0

‚éû

‚éü (Ô∏Ñ )Ô∏Ñ
0‚éü
‚éü u1 ,
0‚éü
‚é† u2
1

KAPITEL 2.

eller kort

LINJ√ÑR SYSTEMTEORI

xÃá = Ax + Bu.

Tuomas Virtanen

Om vi har tillg√•ng till den exakta positionen av

punkten men inte dess hastighet eller acceleration s√• kan vi beskriva en utsignal
f√∂r systemet enligt

‚éõ ‚éû
x
(Ô∏Ñ )Ô∏Ñ (Ô∏Ñ
)Ô∏Ñ ‚éú 1 ‚éü
‚éü
y1
1 0 0 0 ‚éú
‚éú x2 ‚éü ,
=
‚éü
y2
0 1 0 0 ‚éú
‚éù x3 ‚é†
x4
y = Cx.

eller kort

Modellen enligt vilken systemet i exemplet beskrivs kallas

tillst√•ndsmodellen

och √§r speciellt anv√§ndbar f√∂r linj√§ra system med era input- och outputvariabler.

MIMO-system

S√•dana system kallas ocks√•

put). Den formella denitionen f√∂r ett

(eng. Multiple Input Multiple Out-

linj√§rt tidsinvariant system

(LTI-system)

i kontinuerlig tid √§r f√∂ljande:

Denition 2.2.
t

Vektorn

x(t) ‚àà Rn

beskriver systemets tillst√•nd vid tidpunkt

tillst√•ndsvektorn, u(t) ‚àà Rm

och kallas

systemet och

p

y(t) ‚àà R

√§r en

utsignal

√§r en deterministisk

m√§tning

som ger en

insignal

som styr

av systemets tillst√•nd.

D√• kan systemet skrivas p√• tillst√•ndsmodellen

Tillst√•ndet

x(0) = x0

Ãá
x(t)
= Ax(t) + Bu(t),

(2.1)

y(t) = Cx(t) + Du(t).

(2.2)

√§r systemets

starttillst√•nd.

matris, B insignalmatris, C utsignalmatris
Matriserna

A, B , C

och

D

Avbildningen

A

kallas

system-

D direktmatris.

och

antas h√§r vara konstanta, d√§rf√∂r kallas systemet

tidsinvariant. Oftast kan direktmatrisen

D

utel√§mnas och d√• kallas systemet

strikt propert. Systemet i exempel 2.1 √§r ett exempel p√• ett strikt propert system.
Systemets tillst√•nd vid tidpunkt
tillst√•nd

x0

och en given styrsignal

t kan ber√§knas utg√•ende fr√•n ett k√§nt startu(t)

genom att l√∂sa f√∂ljande begynnelsev√§r-

desproblem:

Ãá
x(t)
= Ax(t) + Bu(t),

L√∂sning:

x(0) = x0 .

Skriv om dierentialekvationen som

Ãá ‚àí Ax(t) = Bu(t)
x(t)
och multiplicera med den integrerande faktorn
matrisexponentialfunktionen (se A.2), f√∂r att f√•

5

‚à´Ô∏Å

e

(‚àíA)dt

= e‚àíAt ,

d√§r

e‚àíAt

√§r

KAPITEL 2.

LINJ√ÑR SYSTEMTEORI

Tuomas Virtanen

)Ô∏Å
e‚àíAt x(t) = e‚àíAt Bu(t)
‚à´Ô∏Ç t
‚àíAt
e‚àíAs Bu(s)ds + x(0)
‚áê‚áí e x(t) =
0
‚à´Ô∏Ç t
At
‚áê‚áí x(t) = e x(0) +
eA(t‚àís) Bu(s)ds,

Ãá ‚àí Ax(t)) = e‚àíAt Bu(t) ‚áê‚áí
e‚àíAt (x(t)

d
dt

(Ô∏Å

0
d√§r sista ekvivalensen g√§ller enligt sats A.6. Den entydiga l√∂sningen till (2.1) blir

t

‚à´Ô∏Ç

At

eA(t‚àís) Bu(s)ds.

x(t) = e x0 +

(2.3)

0

2.1.1

Sampling av tidskontinuerliga linj√§ra system

I praktiken sker styrning eller reglering av system med datorer som opererar i
diskret tid men modellerna av system beskrivs oftast av dierentialekvationer enligt fysikaliska modeller och √§r p√• formen (2.1)(2.2). F√∂r regleringen beh√∂ver vi
beskriva systemet i diskret tid och detta utf√∂rs med
p√• det s√§ttet att systemets tillst√•nd

tk := kT ,

d√§r

T >0

evalueras vid de diskreta tidpunkterna

√§r l√§ngden av samplingsperioden. M√§tningarna av utsigna-

len g√∂rs vid tidpunkterna

tk

u(t) h√•lls konstant p√• varje samp[Ô∏Å
)Ô∏Å
t ‚àà kT, (k + 1)T . D√• styrsignalen skickas

och styrsignalen

uk := u(tk )

lingsintervall s√• att

x(t)

sampling. Samplingen utf√∂rs

d√•

fr√•n datorn till systemet g√∂rs detta oftast med

digital-till-analog-omvandlare

och

d√• styrsignalen √§r konstant p√• varje samplingsintervall har D\A-omvandlaren en

nollte ordningens h√•llkrets

(eng. zero-order hold; ZOH). Det samplade systemet

√∂nskas beskrivas av dierensekvationen
och d√• beh√∂ver matriserna

As

och

Bs

xk+1 = As xk + Bs uk ,

d√§r

xk := x(tk )

best√§mmas.

Enligt (2.3) f√•s att

Atk+1

xk+1 = x(tk+1 ) = e

‚à´Ô∏Ç
x0 +

tk+1

eA(tk+1 ‚àís) Bu(s)ds

0

= eA(k+1)T x0 +

‚à´Ô∏Ç

(k+1)T

eA((k+1)T ‚àís) Bu(s)ds

0

‚à´Ô∏Ç

kT

‚à´Ô∏Ç

AT A(kT ‚àís)

(k+1)T

e
x0 +
e e
Bu(s)ds +
eA((k+1)T ‚àís) Bu(s)ds
0
(Ô∏É
)Ô∏É ‚à´Ô∏Ç TkT
‚à´Ô∏Ç tk
= eAT eAtk x0 +
eA(tk ‚àís) Bu(s)ds +
eAœÑ Bu((k + 1)T ‚àí œÑ )dœÑ
0
0
(Ô∏É‚à´Ô∏Ç T
)Ô∏É
‚à´Ô∏Ç T
AT
AœÑ
AT
AœÑ
= e x(tk ) +
e Bu(tk )dœÑ = e xk +
e dœÑ Buk .

=e

AT AkT

0

0
(2.4)
6

KAPITEL 2.

LINJ√ÑR SYSTEMTEORI

Tuomas Virtanen

F√∂r utsignalen f√•s att

yk : = y(tk ) = Cx(tk ) + Du(tk )
= Cxk + Duk .
Det samplade systemet kan nu skrivas som

xk+1 = As xk + Bs uk ,
yk = Cs xk + Ds uk ,
f√∂r

k = 0, 1, 2, . . .
As := e

AT

och matriserna ges av

T

(Ô∏É‚à´Ô∏Ç
,

Bs :=

e

AœÑ

)Ô∏É
dœÑ

B,

Cs := C

Ds := D.

och

0

Exempel 2.3.

Vi utf√∂r sampling med ZOH-metoden av systemet som introdu-

cerades i exempel 2.1. Beteckna samplingsperioden med
och s√•ledes √§r

Ak = 0

f√∂r varje

k‚â•2

‚àÜt.

Eftersom

A2 = 0

f√•s enligt denitionen (A.2) f√∂r matrisex-

ponentialfunktionen att

‚éõ
As = e

A‚àÜt

1 0 ‚àÜt

‚éú
‚éú0 1
= I + A‚àÜt = ‚éú
‚éú0 0
‚éù

0

0 0

0

1

0

‚éû

‚éü
‚àÜt‚éü
‚éü.
0‚éü
‚é†
1

(2.5)

Vidare har vi att

‚éõ

1 0 œÑ 0

‚éû

‚éõ

0 0

‚éû

‚àÜt

‚éü
‚éü ‚éú
‚éú
‚éú0 1 0 œÑ ‚éü ‚éú0 0 ‚éü
‚éü
‚éü ‚éú
‚éú
Bs =
‚éú0 0 1 0‚éü dœÑ ‚éú1 0‚éü
0
‚é† ‚éù
‚é†
‚éù
0 1
0 0 0 1
‚éõ
‚éû
‚éõ
‚éû ‚éõ (‚àÜt)2
2
‚àÜt 0 (‚àÜt)
0
0 0
2
‚éú
‚éü ‚éú 2
(‚àÜt)2 ‚éü ‚éú
‚éú 0 ‚àÜt
‚éü ‚éú0 0 ‚éü ‚éú 0
0
2 ‚éü‚éú
‚éü=‚éú
=‚éú
‚éú0
‚éü
‚éú
‚éú
0
‚àÜt
0 ‚é† ‚éù1 0 ‚éü
‚éù
‚é† ‚éù ‚àÜt
0
0
0
‚àÜt
0 1
0
‚à´Ô∏Ç

Nu f√•s det diskretiserade systemet

xk+1 = As xk + Bs uk ,
yk = Cs xk ,
d√§r

As

och

Bs

ges av (2.5)(2.6) och

Cs =
7

(Ô∏Ñ
)Ô∏Ñ
1 0 0 0
0 1 0 0

.

0

‚éû

(‚àÜt)2 ‚éü
‚éü
2 ‚éü

.
0 ‚éü
‚é†
‚àÜt

(2.6)

KAPITEL 2.

LINJ√ÑR SYSTEMTEORI

Tuomas Virtanen

2.2 Egenskaper hos tidsdiskreta LTI-system
I forts√§ttningen behandlar vi endast strikt propra system i diskret tid och v√§ljer
d√§rf√∂r direktmatrisen
Det strikt propra

D = 0 och l√§mnar bort det nedre indexet s p√• matriserna.

tidsdiskreta LTI-systemet

enligt tillst√•ndsmodellen ges d√• av:

xk+1 = Axk + Buk ,

(2.7)

yk = Cxk .
x0

F√∂r givet starttillst√•nd

och en given styrsignal

‚àí1
u := {uk }N
k=0

kan syste-

mets (2.7) tillst√•ndsekvation itereras f√∂r att f√•

x1 = Ax0 + Bu0 ,
x2 = Ax1 + Bu1 = A(Ax0 + Bu0 ) + Bu1 ,
= A2 x0 + A1 Bu0 + A0 Bu1 ,
.
.
.

xN = AN x0 + AN ‚àí1 Bu0 + . . . + A0 BuN ‚àí1
och l√∂sningen till systemets (2.7) tillst√•ndsekvation √§r d√•

N

xN = A x0 +

N
‚àí1
‚àëÔ∏Ç

AN ‚àí1‚àík Buk .

(2.8)

k=0
Egenskaper som √§r viktiga att analysera √§r systemets styrbarhet, observerbarhet
och stabiliserbarhet. I detta avsnitt ges kortfattat vad som menas med dessa egenskaper och hur systemmatriserna i (2.7) anv√§nds f√∂r att kontrollera egenskaperna.
Denitioner och satser f√∂r styrbarhet och observerbarhet f√∂r b√•de tidsdiskreta
och tidskontinuerliga system hittas exempelvis i [Lue79, s. 276289].

2.2.1

Styrbarhet

Denition 2.4 (Styrbarhet). Ett tidsdiskret system (2.7) √§r styrbart om f√∂r varje
tillst√•nd

x‚àó ‚àà Rn

en styrsignal

och starttillst√•ndet

N ‚àí1
u := {uk }k=0

x0 = 0 nns ett √§ndligt index Nx‚àó > 0 och

som till√§mpat p√• (2.7) ger att

Fr√•gan √§r om det nns ett √§ndligt index
varje tillst√•nd

x‚àó ‚àà Rn

kan n√•s fr√•n origo p√•

8

N
N

xNx‚àó = x‚àó .

som inte beror av
steg?

x‚àó ,

men att

KAPITEL 2.

D√•

x0 = 0

LINJ√ÑR SYSTEMTEORI

kan l√∂sningen (2.8) skrivas p√• matrisform enligt

‚éõ
‚éû
u
)Ô∏Ç ‚éú N ‚àí1 ‚éü
.
N ‚àí1
‚éü
.
A
B ‚éú
‚éù . ‚é†.
u0

(Ô∏Ç
xN = B AB ¬∑ ¬∑ ¬∑

Blockmatrisen framf√∂r styrsignalen

Sats 2.5.

Tuomas Virtanen

(Ô∏Å
)Ô∏Å
T T
u = uT
N ‚àí1 , . . . , u0

Det tidsdiskreta systemet

betecknas

CN (A, B).

med A ‚àà Rn√ón och B ‚àà Rn√óm √§r

(2.7)

styrbart om och endast om det g√§ller f√∂r n √ó nm styrbarhetsmatrisen
(Ô∏Ç
)Ô∏Ç
Cn (A, B) = B AB ¬∑ ¬∑ ¬∑ An‚àí1 B
att

rang Cn (A, B) = n.
F√∂r beviset av satsen beh√∂vs f√∂rst ett hj√§lpresultat.

Lemma 2.6.

L√•t A ‚àà Rn√ón ha full rang. D√• g√§ller att An+k √§r en linj√§rkombi-

nation av matriserna I , A, . . ., An‚àí1 f√∂r varje k ‚â• 0.
Bevis.

Enligt

Cayley-Hamiltons sats

pA (A) = 0,

√§r

d√§r

pA (Œª)

√§r det karakteris-

tiska polynomet

n
‚àëÔ∏Ç

pA (Œª) = det (ŒªI ‚àí A) =

ci Œªi ,

cn = 1.

i=0
Vi f√•r att

n

0 = pA (A) = A +

n‚àí1
‚àëÔ∏Ç

ci A

i

‚áê‚áí

n

A =‚àí

n‚àí1
‚àëÔ∏Ç

i=0
det vill s√§ga

An

i=0

√§r en linj√§rkombination av

A

n+k

ci A i ,

=‚àí

n‚àí1
‚àëÔ∏Ç

I, A, . . . , An‚àí1 .

Vidare g√§ller att

ci Ai+k ,

i=0
varf√∂r

An+k

en linj√§rkombination av

Bevis av Sats 2.5.

Om

I, A, . . . , An‚àí1

rang Cn (A, B) = n

f√∂r varje

k ‚â• 0.

s√• √§r matrisen surjektiv, vilket impli-

cerar att systemet √§r styrbart.
Om systemet √§r styrbart s√• nns ett
att

CN (A, B) u = x‚àó ,

d√§r

x‚àó ‚àà Rn

N > 0 och en styrsignal u0 , . . . , uN ‚àí1

√§r godtyckligt. Anta att

9

N ‚â• n,

s√•

d√• f√•s som

KAPITEL 2.

LINJ√ÑR SYSTEMTEORI

f√∂ljd av lemma 2.6 att matrisen

B, AB, . . . , An‚àí1 B

An+k B

Tuomas Virtanen

√§r en linj√§rkombination av matriserna

i styrbarhetsmatrisen

Cn (A, B)

f√∂r varje

k ‚â• 0.

D√• kan vi

‚àó
‚àó
hitta en ny styrsignal u0 , . . . , un‚àí1 , s√• att

x‚àó = CN (A, B)u = Cn (A, B)u‚àó .
Detta visar att

Cn (A, B)

√§r surjektiv och har s√•ledes rangen

n.

Eftersom systemets styrbarhet √§r oberoende av matriserna
matrisparet

(A, B)

Exempel 2.7.

C

och

D

s√§gs att

√§r styrbart.

Vi unders√∂ker styrbarhetsmatrisen f√∂r systemet i exempel 2.3.

Systemmatriserna ges av

‚éõ

1 0 ‚àÜt

‚éú
‚éú0 1
A=‚éú
‚éú0 0
‚éù
0 0

‚éû

‚éõ (‚àÜt)2

‚éü
‚àÜt‚éü
‚éü
0‚éü
‚é†
1

‚éú 2
‚éú 0
B=‚éú
‚éú ‚àÜt
‚éù
0

0

0
1
0

och

0

‚éû

(‚àÜt)2 ‚éü
‚éü
2 ‚éü

.
0 ‚éü
‚é†
‚àÜt

Styrbarhetsmatrisen f√∂r detta system √§r d√•

‚éõ (‚àÜt)2
2

‚éú
‚éú 0
C4 (A, B) = ‚éú
‚éú ‚àÜt
‚éù
0

0

3(‚àÜt)2
2

0

5(‚àÜt)2
2

0

7(‚àÜt)2
2

(‚àÜt)2
2

0

3(‚àÜt)2
2

0

5(‚àÜt)2
2

0

0

‚àÜt

0

‚àÜt

0

‚àÜt

‚àÜt

0

‚àÜt

0

‚àÜt

0

4

Vi kan se att matrisen har rangen

2.2.2

‚éû

7(‚àÜt)2 ‚éü
‚éü
2 ‚éü

.
0 ‚éü
‚é†
‚àÜt

vilket implicerar att systemet √§r styrbart.

Observerbarhet

Denition 2.8

.

(Observerbarhet)

om det nns ett √§ndligt

observerbart

kan entydigt best√§mmas

y0 , . . . , yN ‚àí1 .

Fr√•gan √§r om det nns ett

N

Ett tidsdiskret system (2.7) √§r

N > 0 s√• att starttillst√•ndet x0

utg√•ende fr√•n m√§tningarna

hj√§lp av

0

stycken m√§tningar

N

s√• att

x0

kan alltid best√§mmas entydigt med

y0 , . . . , yN ‚àí1 ?

stemets (2.7) utsignal vid tidpunkt

N

Fr√•n l√∂sningen (2.8) ser vi att sy-

√§r

yN = CxN = CAN x0 + CAN ‚àí1 Bu0 + . . . + CA0 BuN ‚àí1 .

10

KAPITEL 2.

LINJ√ÑR SYSTEMTEORI

Tuomas Virtanen

D√• styrsignalen √§r k√§nd kan den, utan att inskr√§nka p√• allm√§ngiltigheten, antas
vara noll och d√• f√•s att

yN = CAN x0 .
Om m√§tningarna

y0 , . . . , yN ‚àí1 skrivs som en pN √ó 1 vektor
‚éõ
‚éû ‚éõ
‚éû
y
C
‚éú 0 ‚éü ‚éú
‚éü
‚éú y1 ‚éü ‚éú CA ‚éü
‚éú
‚éü ‚éú
‚éü
‚éú . ‚éü=‚éú
‚éü x0 .
.
.
‚éú .. ‚éü ‚éú
‚éü
.
‚éù
‚é† ‚éù
‚é†
yN ‚àí1
CAN ‚àí1

Blockmatrisen framf√∂r starttillst√•ndet

Sats 2.9.

Det tidsdiskreta systemet

x0

betecknas med

(2.7)

f√•s att

(2.9)

ON (C, A).

med A ‚àà Rn√ón och C ‚àà Rp√ón √§r

observerbart om och endast om det g√§ller f√∂r pn √ó n
‚éû
‚éõ
C
‚éü
‚éú
‚éú CA ‚éü
‚éü
‚éú
On (C, A) = ‚éú . ‚éü
‚éú .. ‚éü
‚é†
‚éù
n‚àí1
CA

observerbarhetsmatrisen

att

rang On (C, A) = n.
Bevis.

Om

rang On (C, A) = n

s√• √§r matrisen injektiv, vilket implicerar att

systemet observerbart.
Om systemet √§r observerbart s√• g√§ller att (2.9) har en entydig l√∂sning
n√•got

N > 0,

ger att
varje

vilket implicerar att matrisen

CAn+k

k ‚â• 0.

√§r en linj√§rkombination av matriserna

D√• f√∂ljer att om

s√•ledes rangen

ON (C, A)

N ‚â•n

s√• m√•ste

x0

f√∂r

√§r injektiv. Lemma 2.6

C, CA, . . . , CAn‚àí1

On (C, A)

f√∂r

vara injektiv och har

n.

Eftersom systemets observerbarhet √§r oberoende av matriserna
s√§gs ocks√• att matrisparet

(C, A)

B

och

D,

s√•

√§r observerbart.

(Ô∏Å
)Ô∏ÅT
Anm√§rkning 2.10. Observera att matriserna On (C, A) = Cn (AT , C T ) och
(Ô∏Å
)Ô∏ÅT
Cn (A, B) = On (B T , AT ). Detta ger att matrisparet (A, B) √§r styrbart om
och endast om matrisparet

(B T , AT ) √§r observerbart och matrisparet (C, A) √§r

observerbart om och endast om matrisparet
och observerbarhet √§r allts√•

duala

(AT , C T )

√§r styrbart. Styrbarhet

egenskaper f√∂r ett linj√§rt system.

11

KAPITEL 2.

LINJ√ÑR SYSTEMTEORI

Tuomas Virtanen

Notera dock att detta betyder inte att ett styrbart system √§r observerbart, ef-

B medan observerbarhetsmatrisen

tersom styrbarhetsmatrisen beror av matrisen
beror av matrisen

Exempel 2.11.

C.
Vi unders√∂ker observerbarhetsmatrisen f√∂r systemet i exem-

pel 2.3. Systemmatriserna ges av

‚éõ

1 0 ‚àÜt

‚éú
‚éú0 1
A=‚éú
‚éú0 0
‚éù

0

0 0

0

‚éû

0

(Ô∏Ñ

‚éü
‚àÜt‚éü
‚éü
0‚éü
‚é†
1

1

C=

och

)Ô∏Ñ
1 0 0 0
0 1 0 0

.

Observerbarhetsmatrisen f√∂r detta system √§r d√•

‚éõ

1
‚éú
‚éú0
‚éú
‚éú
‚éú1
‚éú
‚éú0
‚éú
O4 (C, A) = ‚éú
‚éú1
‚éú
‚éú
‚éú0
‚éú
‚éú1
‚éù
0
Vi kan se att matrisen har rangen

2.2.3

0

0

0

‚éû

‚éü
0 ‚éü
‚éü
‚éü
0 ‚àÜt
0 ‚éü
‚éü
1 0
‚àÜt ‚éü
‚éü
‚éü.
0 2‚àÜt 0 ‚éü
‚éü
‚éü
1 0 2‚àÜt‚éü
‚éü
0 3‚àÜt 0 ‚éü
‚é†
1 0 3‚àÜt
1

0

4 vilket implicerar att systemet √§r observerbart.

Stabiliserbarhet

Ett system med f√∂ljande tillst√•ndsekvation kallas ett

autonomt

xk+1 = Axk

system
(2.10)

och enligt (2.8) l√∂sningen

x k = Ak x 0 ,

Denition 2.12 (Stabilitet).
bilt

k ‚â• 0.

Ett autonomt system (2.10) √§r

(2.11)

(asymptotiskt) sta-

om dess l√∂sning (2.11) uppfyller

lim xk = 0,

k‚Üí‚àû
f√∂r varje val av starttillst√•nd
system (2.7) med styrsignalen

x0 ‚àà R n .
u = 0

Om detta uppfylls f√∂r icke-autonoma

s√• √§r ocks√• systemet (2.7) stabilt. D√•

systemet √§r stabilt s√§gs ocks√• att matrisen

12

A

√§r stabil.

KAPITEL 2.

LINJ√ÑR SYSTEMTEORI

Tuomas Virtanen

Om systemet har endast en tillst√•ndsvariabel

x

s√• g√§ller att

xk = Œ± k x 0
och d√• √§r detta system stabilt f√∂r varje

x0 ‚àà R

om och endast om

|Œ±| < 1.

F√∂r system med era tillst√•ndsvariabler f√•s f√∂ljande resultat enligt [Lue79, s.
155156].

Sats 2.13.

Systemet

(2.7)

√§r asymptotiskt stabilt om och endast om f√∂r varje

egenv√§rde Œªi , i ‚àà {1, . . . , n} till systemmatrisen A g√§ller att |Œªi | < 1.
Bevis.

Vi visar fallet d√•

A √§r diagonaliserbar. D√• existerar en inverterbar matris,

s√• att

A = M ŒõM ‚àí1

d√§r

Œª1 , . . . , Œªn

‚éõ
‚éû
Œª1 0 . . . 0
‚éú
‚éü
‚éú 0 Œª2 . . . 0 ‚éü
‚éú
‚éü ‚àí1
=M‚éú.
,
.
. ‚éüM
..
.
.
‚éú ..
.
.
. ‚éü
‚éù
‚é†
0 0 . . . Œªn

√§r egenv√§rdena till

A.

Nu f√•s att

xk = Ak x0 = M ŒõM ‚àí1 M ŒõM ‚àí1 ¬∑ ¬∑ ¬∑ M ŒõM ‚àí1 x0
= M Œõk M ‚àí1 x0
‚éû
‚éõ
k
Œª
0 ... 0
‚éü
‚éú 1
‚éú 0 Œªk . . . 0 ‚éü
2
‚éü ‚àí1
‚éú
x0
=M‚éú .
.
. ‚éüM
.
.
..
. ‚éü
‚éú ..
.
.
‚é†
‚éù
0 0 . . . Œªkn
och d√• g√§ller att

lim xk = 0 ‚áê‚áí |Œªi | < 1,

k‚Üí‚àû

Beviset f√∂r fallet d√•
ist√§llet p√•
resultat.

A

f√∂r varje

i ‚àà {1, . . . , n}.

inte √§r diagonaliserbar baserar sig p√• att

Jordans normalform

Stabiliseringsproblemet

A

skrivs

och d√• f√•s med liknande ber√§kningar samma
g√•r ut p√• att konstruera en

regulator

som tar

systemets (2.7) utsignal som input och ger som output en styrsignal till systemet (2.7), s√•dant att det ihopkopplade system √§r stabilt [TSH01, s. 57]. D√•
systemets tillst√•nd √§r tillg√§ngligt, det vill s√§ga matrisen
len, och regulatorn √§r statisk, f√•s en styrsignal av formen

C = I

f√∂r utsigna-

uk = ‚àíLxk

f√∂r varje

k = 0, 1, . . ., d√§r L √§r en godtycklig m √ó n matris. Denna form av reglering kallas

13

KAPITEL 2.

LINJ√ÑR SYSTEMTEORI

statisk tillst√•nds√•terkoppling

Tuomas Virtanen

och denna styrsignal till√§mpad p√• systemet (2.7)

ger tillst√•ndsekvationen

xk+1 = Axk + Buk = Axk ‚àí BLxk = (A ‚àí BL)xk .

(2.12)

Denna ekvation √§r nu i form av ett autonomt system och kallas ocks√• ett

system

slutet

eftersom tillst√•ndet √•terkopplas genom styrsignalen. Stabiliseringsproble-

met i detta fall reduceras till att best√§mma matrisen

Denition 2.14 (Stabiliserbarhet).
det nns en matris

Sats 2.15.

L,

Matrisparet

s√• att matrisen

A ‚àí BL

L

s√• att (2.12) √§r stabil.

(A, B) kallas stabiliserbart

om

√§r stabil.

L√•t matrisparet (A, B) vara styrbart. D√• g√§ller att matrisparet

(A, B) √§r stabiliserbart.
Beviset utel√§mnas men baserar sig p√• satsen om polplacering [Lue79, s. 299].

2.3 Luenbergerobservat√∂r
Tillst√•nds√•terkopplingen (2.12) kr√§ver att tillst√•ndsvektorn

xk

observat√∂r

ta √§r ofta inte fallet. H√§rn√§st kommer en s√• kallad

konstrueras, med avsikten att rekonstruera tillst√•ndsvektorn
m√§tningar

y0 , . . . , yk

och en given styrsignal

u.

√§r k√§nd, men det-

f√∂r LTI-system att

xk

utg√•ende fr√•n

Luenbergerobservat√∂ren √§r en

deterministisk version av Kalmanltret som konstrueras i n√§sta kapitel.
Konstruktionen av Luenbergerobservat√∂ren g√∂rs enligt [√Öst70, s. 142] p√• f√∂ljande s√§tt. F√∂rst skapas ett modellsystem

ÃÇ k+1 = Ax
ÃÇ k + Buk ,
x
ÃÇk,
yÃÇk = C x
d√§r

ÃÇk
x

betecknar skattningen av tillst√•ndet

som i (2.7) och styrsignalen

ÃÇ 0 = x0
x

u

xk .

Systemmatriserna √§r samma

√§r samma som f√∂r det ursprungliga systemet. Om

s√• skulle modellens l√∂sning sammanfalla med systemets (2.7) l√∂sning,

vilket skulle medf√∂ra att

ÃÇk
x

√§r en exakt skattning av tillst√•ndet f√∂r varje

Problemet √§r att starttillst√•ndet

x0

√§r ok√§nt och endast m√§tningar

tillg√§ngliga som inte beaktas av den ovanst√•ende modellen. L√•t

k ‚â• 0.

y0 , . . . , yk

√§r

ÃÇk
ek = xk ‚àí x

beteckna felet mellan skattningen och det verkliga tillst√•ndet. D√• ger den s√•

14

KAPITEL 2.

kallade

LINJ√ÑR SYSTEMTEORI

Tuomas Virtanen

innovationen yÃÉk := yk ‚àí yÃÇk = Cek

tillst√•ndet

xk ,

ett m√•tt p√• hur bra

ÃÇk
x

skattar

och detta antyder att tillst√•ndsekvationen har formen

ÃÇ k+1 = Ax
ÃÇ k + Buk + K yÃÉk ,
x
f√∂r n√•gon matris
f√•s

K.

(2.13)

Subtraheras tillst√•ndet (2.13) fr√•n systemets tillst√•nd (2.7)

felsystemet

ÃÇ k+1 = A(xk ‚àí x
ÃÇ k ) ‚àí K yÃÉk
ek+1 = xk+1 ‚àí x

(2.14)

= (A ‚àí KC)ek .
Om det g√§ller f√∂r felsystemet (2.14) att

x0

och varje val av skattning

Denition 2.16

ÃÇ0,
x

s√• kallas (2.13) en

.

(Detekterbarhet)

det nns en matris

K,

ek ‚Üí 0 d√• k ‚Üí ‚àû, f√∂r varje starttillst√•nd

Matrisparet

s√• att matrisen

A ‚àí KC

tillst√•ndsobservat√∂r.

(C, A)

kallas

detekterbart

om

√§r stabil.

Det √§r allts√• m√∂jligt att konstruera en Luenbergerobservat√∂r om och endast
om matrisparet

Sats 2.17.

(C, A)

√§r detekterbart.

L√•t matrisparet (C, A) vara observerbart. D√• g√§ller att matrisparet

(C, A) √§r detekterbart.
Bevis.

Resultatet f√•s genom dualitet. Enligt anm√§rkning 3.4 f√•s att om

(C, A)

T
T
T
T
√§r observerbart s√• √§r (A , C ) styrbart. Sats 2.15 ger att d√• √§r (A , C ) stabiliserbart. Denitionen f√∂r stabiliserbarhet s√§ger att det nns en matris
matrisen

AT ‚àíC T K T

enligt denitionen f√∂r detekterbarhet √§r matrisparet

2.3.1

A‚àíKC

√§r stabil. D√• √§r ocks√• matrisen

(C, A)

K T , s√• att

stabil och s√•ledes

detekterbart.

Separationsprincipen

L√•t nu styrsignalen till systemet (2.7) vara

ÃÇk,
uk = ‚àíLx

d√§r

ÃÇk
x

√§r skattningen

given av observat√∂ren (2.13) och √§r k√§nd eftersom observat√∂ren √§r konstruerad
p√• det s√§ttet. D√• blir tillst√•ndsekvationen f√∂r det slutna systemet

ÃÇk
xk+1 = Axk ‚àí BLx
= Axk ‚àí BL(xk ‚àí ek )
= (A ‚àí BL)xk + BLek ,

15

(2.15)

KAPITEL 2.

d√§r felet

ek

av matrisen

LINJ√ÑR SYSTEMTEORI

Tuomas Virtanen

ges av (2.14). √Ö ena sidan kan matrisen

L

K

best√§mmas oberoende

s√• att skattningen given av observat√∂ren konvergerar mot syste-

mets egentliga tillst√•nd. √Ö andra sidan kan matrisen
matrisen

K

L best√§mmas oberoende av

s√• att systemet stabiliseras. Detta kallas f√∂r

separationsprincipen

i

deterministisk reglerteori och g√§ller f√∂r linj√§ra system [Lue79, s. 307]. Felet (2.14)
och tillst√•ndet (2.15) kan skrivas som ett autonomt system

(Ô∏Ñ

xk+1
ek+1

)Ô∏Ñ
=

(Ô∏Ñ
A ‚àí BL

)Ô∏Ñ (Ô∏Ñ )Ô∏Ñ
xk

BL
A ‚àí KC

0

ek

.

(2.16)

Egenv√§rdena f√∂r denna matris √§r precis unionen av egenv√§rdena f√∂r matriserna

A ‚àí BL

och

A ‚àí KC

och detta slutna system √§r stabilt d√• matrisparet

√§r detekterbart, matrisparet
har valts s√• att

A ‚àí BL

och

(A, B)

√§r stabiliserbart och matriserna

A ‚àí KC

(C, A)

K

och

L

√§r stabila.

2.4 Optimal reglering
Det √§r av intresse att best√§mma matriserna

K

och

L

p√• ett optimalt s√§tt. I

denna avhandling √§r huvudintresset stokastiska system, f√∂r vilka Kalmanltret
kan ses som en observat√∂r, varf√∂r en explicit konstruktionen av matrisen

K

f√∂r

Luenbergerobservat√∂ren utel√§mnas h√§r.
Med optimal reglering avses att konstruera en

regulator

som styr systemet till

origo s√• att en given kostnad minimeras. Om regulatorns styrsignal √§r i form av
tillst√•nds√•terkoppling
lingsmatrisen

uk = ‚àíLxk , √§r optimal reglering best√§mning av √•terkopp-

L s√• att kostnaden minimeras. En kostnadsfunktional J(x0 , u) ger

ett skal√§rt v√§rde p√• kostnaden att utf√∂ra styrningen
tillst√•ndet

‚àí1
u = {uk }N
k=0 ,

givet start-

x0 .

H√§r anv√§nds f√∂ljande kvadratiska kostnadsfunktional

JN (x0 , u) := xT
N SN xN +

N
‚àí1
‚àëÔ∏Ç

T
(xT
k Qxk + uk Ruk ),

(2.17)

k=0
eftersom den √§r enkel att hantera matematiskt och √§r tillr√§ckligt exibel f√∂r
m√•nga till√§mpningar. Denna kostnadsfunktional har en
och

SN

√§r kostnadsmatrisen f√∂r sluttillst√•ndet vid tiden

√§ndlig tidshorisont N

N.

Systemets tillst√•nd

beskrivs oftast som en avvikelse fr√•n det √∂nskade tillst√•ndet och d√• ger
naden f√∂r denna avvikelse. Matriserna

SN

16

och

Q

Q

kost-

kan v√§ljas godtyckligt med

KAPITEL 2.

LINJ√ÑR SYSTEMTEORI

Tuomas Virtanen

restriktionen till positivt semidenita matriser s√• att termerna i (2.17) som inneh√•ller dessa matriser √§r icke-negativa. Matrisen

R

√§r kostnadsmatrisen f√∂r

styrningen och den v√§ljs s√• att den √§r positivt denit, vilket betyder att varje
term i 2.17 som inneh√•ller
Det

R

√§r positiv.

linj√§rkvadratiska reglerproblemet

eller kort

quadratic) g√•r ut p√• att hitta en reglersignal

LQ-problemet

(eng. linear-

u f√∂r ett linj√§rt system (2.7), s√•dan

att den kvadratiska kostnadsfunktionalen (2.17) minimeras.
F√∂ljande sats enligt [HRS07, Sats 5.3.1], modierad f√∂r kostnadsfunktionalen (2.17), ger den optimala reglersignalen f√∂r deterministiska LTI-system, d√• vi

xk

har tillg√•ng till systemets tillst√•nd

Sats 2.18.
nalen

vid varje tidpunkt

Reglersignalen till systemet

(2.17),

(2.7),

k.

som minimerar kostnadsfunktio-

√§r

uk = ‚àíLk xk ,

k = 0, . . . , N ‚àí 1,

d√§r den tidsvarianta √•terkopplingsmatrisen Lk ges av

Lk := (B T Sk+1 B + R)‚àí1 B T Sk+1 A

(2.18)

och Sk √§r l√∂sningen till ekvationen

Sk := AT Sk+1 A + Q ‚àí AT Sk+1 B(B T Sk+1 B + R)‚àí1 B T Sk+1 A
med begynnelsev√§rdet SN i

(2.19)

(2.17).

Vidare g√§ller att minimala kostnaden √§r

min JN (x0 , u) = xT
0 S0 x0 ,

(2.20)

u

d√§r S0 f√•s ur
Anm√§rkning

(2.19).
2.19. Om tillst√•ndet

xk

inte √§r tillg√§ngligt vid varje tidpunkt kan

enligt separationsprincipen 2.3.1 en Luenbergerobservat√∂r konstrueras om systemet √§r detekterbart. D√• kan skattningen
regleringen ist√§llet f√∂r tillst√•ndet

Anm√§rkning

ÃÇk
x

givet av observat√∂ren anv√§ndas f√∂r

xk .

2.20. De tidsvarierande √•terkopplingsmatriserna

Lk

√§r oberoende

av tillst√•ndet och utsignalen av systemet och kan allts√• ber√§knas p√• f√∂rhand s√•
snart systemmatriserna och kostnadsmatriserna √§r k√§nda.

17

KAPITEL 2.

LINJ√ÑR SYSTEMTEORI

Tuomas Virtanen

F√∂r beviset av satsen beh√∂vs f√∂rst tv√• lemman. Det f√∂rsta ang√•ende l√∂sningarna till den

dynamiska tidsdiskreta Riccatiekvationen

(2.19), vilket ofta utel√§mnas

i litteraturen vid konstruktionen av den optimala reglersignalen. Det andra (som
ocks√• beh√∂vs senare i det stokastiska fallet) hj√§lper med omskrivningen av kostnadsfunktionalen (2.17).

Lemma 2.21.

L√•t SN ‚â• 0, Q ‚â• 0 och R > 0. Deniera Sk genom

(2.19)

f√∂r

0 ‚â§ k ‚â§ N ‚àí 1. D√• g√§ller att Sk ‚â• 0 f√∂r varje k = 0, . . . , N .
Vidare om Q > 0 s√• √§r Sk > 0 f√∂r varje k = 0, . . . , N ‚àí 1.
Bevis.
D√•

Enligt antagandet √§r

R>0

s√• √§r

SN ‚â• 0. Anta nu att Sk+1 ‚â• 0 f√∂r n√•got k ‚â§ N ‚àí 1.

(B T Sk+1 B + R) > 0

och d√§rmed inverterbar, varf√∂r (2.19) ger

att

Sk = AT Sk+1 A ‚àí AT Sk+1 B(B T Sk+1 B + R)‚àí1 B T Sk+1 A + Q.
1/2

Sk+1 . Vi kan skriva
(Ô∏Å
1/2
1/2
1/2 )Ô∏Å
1/2
Sk = (Sk+1 A)T I ‚àí Sk+1 B(B T Sk+1 B + R)‚àí1 B T Sk+1 (Sk+1 A) + Q.

L√•t

D√•

Sk+1

Q‚â•0

vara den positivt semidenita kvadratroten av

g√§ller att

Sk ‚â• 0

om

(Ô∏Å
1/2
1/2
1/2 )Ô∏Å
1/2
(Sk+1 A)T I ‚àí Sk+1 B(B T Sk+1 B + R)‚àí1 B T Sk+1 (Sk+1 A) ‚â• 0.
Eftersom

L√•t

T T P T ‚â• 0 om P ‚â• 0 enligt lemma A.3 r√§cker det att
(Ô∏Å
1/2
1/2 )Ô∏Å
I ‚àí Sk+1 B(B T Sk+1 B + R)‚àí1 B T Sk+1 ‚â• 0.

R1/2

vara den positivt denita kvadratroten av

R.

visa att

Vi kan skriva

I ‚àí Sk+1 B(B T Sk+1 B + R)‚àí1 B T Sk+1
(Ô∏Å
)Ô∏Å‚àí1
1/2
1/2
= I ‚àí Sk+1 B(R1/2 )‚àí1 (R1/2 )‚àí1 B T Sk+1 B(R1/2 )‚àí1 + I (R1/2 )‚àí1 B T Sk+1 .
1/2

S√§tt

1/2

1/2

W := Sk+1 B(R1/2 )‚àí1

och d√• f√•r vi med hj√§lp av lemma A.1 att

I ‚àí Sk+1 B(B T Sk+1 B + R)‚àí1 B T Sk+1 = I ‚àí W (W T W + I)‚àí1 W T .
1/2

1/2

= (W W T + I)‚àí1 ,
vilket √§r en positivt denit matris eftersom det √§r en invers. D√• har vi visat att

Sk = (Sk+1 A)T (W W T + I)‚àí1 (Sk+1 A) + Q ‚â• 0
1/2

och enligt induktionsprincipen f√•s att
f√•s att om

Q>0

1/2

Sk ‚â• 0

s√• ser vi ur (2.21) att

f√∂r varje

Sk > 0

18

k = 0, . . . , N ‚àí 1.

f√∂r varje

(2.21)
Vidare

k = 0, . . . , N ‚àí 1.

KAPITEL 2.

LINJ√ÑR SYSTEMTEORI

Lemma 2.22.

L√•t Lk och Sk ges av

Tuomas Virtanen

(2.18)

respektive

(2.19)

och anta att matri-

serna Q och SN , √§r positivt semidenita och R positivt denit. D√• g√§ller f√∂ljande
likhet
T
T
(Axk + Buk )T Sk+1 (Axk + Buk ) ‚àí xT
k Sk xk + xk Qxk + uk Ruk

= (uk + Lk xk )T (B T Sk+1 B + R)(uk + Lk xk ).
Bevis.

(2.22)

Utveckling av v√§nstra ledet i (2.22) ger

T
T T
T T
V L = xT
k A Sk+1 Axk + xk A Sk+1 Buk + uk B Sk+1 Axk
T
T
T
T
+ uT
k B Sk+1 Buk ‚àí xk Sk xk + xk Qxk + uk Ruk

(2.23)

T
T T
= xT
k (A Sk+1 A + Q ‚àí Sk )xk + xk A Sk+1 Buk
T
T
T
+ uT
k B Sk+1 Axk + uk (B Sk+1 B + R)uk .
Lemma 2.21 ger att

Sk ‚â• 0

(B T Sk+1 B + R) > 0

f√∂r varje

k = 0, . . . , N

och d√•

R > 0

s√• √§r

och d√§rmed inverterbar enligt sats A.2. Vi kan nu sl√•

ihop de tv√• sista termerna i (2.23), med anv√§ndning av (2.18), p√• f√∂ljande s√§tt

T
T
T
uT
k B Sk+1 Axk + uk (B Sk+1 B + R)uk
(Ô∏Å
)Ô∏Å
T
T
‚àí1 T
= uT
k (B Sk+1 B + R) uk + (B Sk+1 B + R) B Sk+1 Axk
T
= uT
k (B Sk+1 B + R)(uk + Lk xk ).
Vidare g√§ller att

T
T
‚àí1
LT
k = A Sk+1 B(B Sk+1 B + R)

nering och det faktum att

R

och

Sk+1

(2.24)

enligt reglerna f√∂r transpo-

√§r symmetriska. D√• √§r

T
AT Sk+1 B = LT
k (B Sk+1 B + R).

(2.25)

Ins√§ttning av (2.24) och (2.25) i (2.23) ger att

T
T T
T
V L = xT
k (A Sk+1 A + Q ‚àí Sk )xk + xk Lk (B Sk+1 B + R)uk
T
+ uT
k (B Sk+1 B + R)(uk + Lk xk ).
Om vi nu skriver om (2.19) som

T
Sk = AT Sk+1 A + Q ‚àí LT
k (B Sk+1 B + R)Lk ,
s√• kan f√∂rsta termen i (2.26) skrivas

19

(2.26)

KAPITEL 2.

LINJ√ÑR SYSTEMTEORI

Tuomas Virtanen

T
xT
k (A Sk+1 A + Q ‚àí Sk )xk
(Ô∏Ç
(Ô∏Å T
)Ô∏Å)Ô∏Ç
TS
T (B T S
= xT
A
A
+
Q
‚àí
A
S
A
+
Q
‚àí
L
B
+
R)L
xk
k+1
k+1
k+1
k
k
k
T
T
= xT
k Lk (B Sk+1 B + R)Lk xk .

(2.27)

Ins√§ttning av (2.27) i (2.26) ger nu att

T
T T
T
T
V L = xT
k Lk (B Sk+1 B + R)Lk xk + xk Lk (B Sk+1 B + R)uk
T
+ uT
k (B Sk+1 B + R)(uk + Lk xk )
T
T
T
T
= xT
k Lk (B Sk+1 B + R)(uk + Lk xk ) + uk (B Sk+1 B + R)(uk + Lk xk )

= (uk + Lk xk )T (B T Sk+1 B + R)(uk + Lk xk ).

Bevis av Sats 2.18.

Vi g√∂r en omskrivning av kostnadsfunktionalen (2.17) enligt

f√∂ljande

JN (x0 , u) = xT
N SN xN +
= xT
0 S0 x0 +
= xT
0 S0 x0 +

N
‚àí1
‚àëÔ∏Ç

T
(xT
k Qxk + uk Ruk )

k=0
N
‚àí1
‚àëÔ∏Ç

T
(xT
k+1 Sk+1 xk+1 ‚àí xk Sk xk ) +

k=0
N
‚àí1
‚àëÔ∏Ç

N
‚àí1
‚àëÔ∏Ç

T
(xT
k Qxk + uk Ruk )

k=0

(Ô∏Å
)Ô∏Å
(Axk + Buk )T Sk+1 (Axk + Buk ) ‚àí xT
k Sk xk

k=0

+

N
‚àí1
‚àëÔ∏Ç

T
(xT
k Qxk + uk Ruk ).

k=0
Nu kan vi anv√§nda lemma 2.22 som ger att

JN (x0 , u) = xT
0 S0 x0 +

N
‚àí1
‚àëÔ∏Ç

(uk + Lk xk )T (B T Sk+1 B + R)(uk + Lk xk )

k=0
och eftersom

(B T Sk+1 B + R) > 0

s√• √§r varje term i summan st√∂rre √§n eller

lika med noll. D√• och endast d√• styrsignalen v√§ljs som

k = 0, . . . , N ‚àí 1

uk = ‚àíLk xk

f√∂r varje

s√• √§r varje term i summan lika med noll och vi f√•r att

min JN (x0 , u) = xT
0 S0 x0 .
u

20

KAPITEL 2.

2.4.1

LINJ√ÑR SYSTEMTEORI

Tuomas Virtanen

O√§ndlig tidshorisont

I vissa till√§mpningar kan det vara oklart hur man ska v√§lja tidshorisonten

N

i

kostnadsfunktionalen (2.17), vilket motiverar enligt [HRS07, s. 61] att studera
reglerproblemet med en o√§ndlig tidshorisont och f√∂ljande kostnadsfunktional

‚àû
‚àëÔ∏Ç
T
J‚àû (x0 , u) :=
(xT
k Qxk + uk Ruk ).

(2.28)

k=0
Minimeringen av denna √§r meningsfull endast d√• kostnaden kan g√∂ras √§ndlig och
ett tillr√§ckligt villkor f√∂r detta √§r att systemet √§r stabiliserbart [HRS07, s. 62].
Det visar sig att under vissa villkor kan man approximera problemet f√∂r
o√§ndlig tidshorisont med problemet f√∂r √§ndlig tidshorisont och l√•ter
L√•t

Q = H TH

f√∂r n√•gon

N ‚Üí ‚àû.

p √ó n matris H . D√• √§r Riccatiekvationen (2.19) av

formen

Sk = AT Sk+1 A + H T H ‚àí AT Sk+1 B(B T Sk+1 B + R)‚àí1 B T Sk+1 A

(2.29)

och enligt f√∂ljande sats konvergerar l√∂sningen mot ett gr√§nsv√§rde som √§r oberoende av valet av

Sats 2.23.

SN .

Anta att Q ‚â• 0, R > 0, matrisparet (H, A) √§r detekterbart, d√§r

H T H = Q och matrisparet (A, B) √§r stabiliserbart. Beteckna l√∂sningen vid
tidpunkt k = 0 till

(2.29)

startad fr√•n SN med S0 (SN ) och l√•t

L(S) := (B T SB + R)‚àí1 B T SA.

(2.30)

D√• g√§ller f√∂ljande p√•st√•enden:
1. Det nns en entydig matris S+ ‚â• 0, oberoende av SN , s√• att

lim S0 (SN ) = S+ .

N ‚Üí‚àû

Matrisen S+ satiserar den

algebraiska Riccatiekvationen

S = AT SA + Q ‚àí AT SB(B T SB + R)‚àí1 B T SA

(2.31)

och matrisen A ‚àí BL(S+ ) √§r stabil. Vidare g√§ller att om matrisparet

(A, B) √§r styrbart s√• √§r S+ > 0.
2. Reglersignalen till systemet

(2.7)

som minimerar

uk = ‚àíL(S+ )xk
och minimala kostnaden √§r J‚àû (x0 , u) = xT
0 S+ x0 .
21

(2.28)

ges av

KAPITEL 2.

LINJ√ÑR SYSTEMTEORI

Tuomas Virtanen

F√∂rsta p√•st√•endet nns bevisat i [LR95, Sats 17.5.3, s. 382] och det andra
p√•st√•endet nns bevisat i [HRS07, Sats 5.3.2, s. 62].
Observera att √•terkopplingsmatrisen i detta fall √§r tidsinvariant. Den optimala reglersignalen till systemet (2.7) som minimerar kostnadsfunktionalen (2.28)
med o√§ndlig tidshorisont √§r allts√• i form av statisk tillst√•nds√•terkoppling.

Anm√§rkning

2.24. Om

A √§r inverterbar s√• g√§ller enligt [LR95, Korollarium 13.5.3

s. 326] att bland alla positivt semidenita l√∂sningar till (2.31) √§r
l√∂sningen f√∂r vilken matrisen
alla l√∂sningar

S

A ‚àí BL(S+ )

S+ den entydiga

√§r stabil. Det g√§ller ocks√• att bland

till (2.31), f√∂r vilka matrisen

A ‚àí BL(S)

entydiga positivt semidenita l√∂sningen. Vidare g√§ller att

√§r stabil, √§r

S+

f√∂r matrisen

A

den

√§r den maximala

positivt semidenita l√∂sningen till (2.31) i den mening att f√∂r varje
l√∂ser (2.31) s√• g√§ller att matrisen

S+

S Ã∏= S+

som

S+ ‚àíS √§r positivt semidenit. Inverterbarheten

√§r inte n√∂dv√§ndig enligt [DGG86].

22

KAPITEL 3.

OPTIMAL STOKASTISK ESTIMERING

Tuomas Virtanen

Kapitel 3
Optimal stokastisk estimering
3.1 Denitioner och antaganden f√∂r diskreta stokastiska system
Repetition av grundl√§ggande sannolikhetsl√§ra och normalf√∂rdelningen f√∂r stokastiska vektorer samt notationer och begrepp som anv√§nds i denna avhandling
nns i bilaga B.
Detta kapitel b√∂rjar med n√•gra denitioner f√∂r stokastiska processer enligt [LR95, s. 375] som √§r viktiga grundl√§ggande denitioner f√∂r stokastiska
system. Teorin f√∂r stokastiska system g√∂rs h√§r endast i diskret tid, men en
metod f√∂r sampling av kontinuerliga system ges i avsnitt 3.4. Ett exempel
av samplingen och metoden f√∂r estimeringen av tillst√•ndet som g√•s igenom i
avsnitt 3.2 presenteras i slutet av kapitlet.

Denition 3.1.
(i) En

vk

stokastisk process
best√•r av

n

√§r en f√∂ljd

{vk }k‚â•0

stycken stokastiska variabler.

vitt brus

xk

√§r vitt brus, s√•som denierat ovan, och varje vektor

vk

√§r oberoende, vilket implicerar att

Gaussiskt vitt brus
√§r dessutom

j Ã∏= k

och

(ii) En stokastisk process s√§gs vara

(iii)

av stokastiska vektorer, d√§r varje

n-dimensionellt

om f√∂r

Cov(vj , vk ) = 0

d√•

g√§ller att

xj

j Ã∏= k .

normalf√∂rdelad.

(iv) En stokastisk process s√§gs ha

v√§ntev√§rdet noll

k ‚â• 0.
23

om

E(vk ) = 0

f√∂r varje

KAPITEL 3.

Ett

OPTIMAL STOKASTISK ESTIMERING

stokastiskt LTI-system

Tuomas Virtanen

ges av tillst√•ndsmodellen:

xk+1 = Axk + Buk + F vk ,

(3.1)

yk = Cxk + Gwk .

(3.2)

F√∂ljande antaganden g√∂rs f√∂r systemet (3.1)(3.2):
1.

Processbruset {vk }k‚â•0

och

m√§tbruset {wk }k‚â•0

√§r gaussiskt vitt brus med

v√§ntev√§rdet noll och givna kovariansmatriser

E(vk vkT ) = Pv ‚â• 0,

E(wk wkT ) = Pw > 0,

f√∂r varje

k.

2. Processbruset och m√§tbruset √§r oberoende processer s√• att

E(vj wkT ) = 0,
3. Starttillst√•det

G

j

och

k.

x0 antas vara normalf√∂rdelat med givna v√§ntev√§rdet m0 och

kovariansmatrisen
4. Matrisen

f√∂r varje

P0 > 0.

antas vara surjektiv.

5. Vidare antas att

x0

oberoende f√∂r varje

och

vj

√§r oberoende f√∂r varje

j

samt

x0

och

wk

√§r

k.

P√• samma s√§tt som f√∂r deterministiska system f√•s att l√∂sningen till (3.1) ges av

xn = An x0 +

n‚àí1
‚àëÔ∏Ç

An‚àí1‚àík (Buk + F vk ),

(3.3)

k=0
men l√∂sningen h√§r √§r en stokastisk vektor som f√∂ljd av processbruset. Observera
att ekvation (3.2) kan ocks√• skrivas

yk = Cxk + fk ,
d√§r

{fk }k‚â•0

√§r gaussiskt vitt brus med v√§ntev√§rdet noll och kovariansmatrisen

Pf = GPw GT .

Lemma 3.2.

L√•t x och v vara oberoende normalf√∂rdelade stokastiska vektorer

med kovariansmatriserna Cov(x) = Px och Cov(v) = Pv . L√•t A och F vara s√•dana konstanta matriser att multiplikationerna Ax och F v samt summan

Ax + F v √§r denierade. D√• √§r summan Ax + F v en normalf√∂rdelad stokastisk
vektor med v√§ntev√§rdet A E(x) + F E(v) och kovariansmatrisen

APx AT + F Pv F T .
24

KAPITEL 3.

Bevis.

OPTIMAL STOKASTISK ESTIMERING

Vi kan skriva

(Ô∏Ç

Ax + F v = A F
och d√•

x

v

och

(Ô∏Ñ )Ô∏Ñ
)Ô∏Ç x
v

√§r oberoende s√• f√∂ljer enligt p√•st√•ende

gaussisk och s√•ledes √§r

Ax + F v

Tuomas Virtanen

2

i sats B.20 att

( xv )

√§r

gaussisk. V√§ntev√§rdet f√•s direkt p√• grund av

lineariteten av v√§ntev√§rdet.
Kovariansmatrisen blir, tack vare att

x

och

v

√§r oberoende,

)Ô∏Å
(Ô∏Å
E (Ax + F v ‚àí E(Ax + F v))(Ax + F v ‚àí E(Ax + F v))T
(Ô∏Ç(Ô∏Å
)Ô∏Å(Ô∏Å
)Ô∏ÅT )Ô∏Ç
= E A(x ‚àí E(x)) + F (v ‚àí E(v)) A(x ‚àí E(x)) + F (v ‚àí E(v))
)Ô∏Å
)Ô∏Å
(Ô∏Å
(Ô∏Å
= E A(x ‚àí E(x))(x ‚àí E(x))T AT + E F (v ‚àí E(v))(v ‚àí E(v))T F T
= APx AT + F Pv F T .

Lemma 3.3.

L√•t xn vara tillst√•ndsvektorn, yn vara m√§tsignalen och un vara

reglersignalen enligt

(3.1)(3.2)

f√∂r n = 0, . . . , k , d√§r x0 , v0 , . . . , vk , w0 , . . . , wk

√§r sinsemellan oberoende gaussiska vektorer. Anta att reglersignalen un √§r en
funktion av tillst√•ndet xn och m√§tsignalen yn f√∂r varje n = 0, . . . , k . D√• g√§ller
f√∂ljande p√•st√•enden:
1. vk √§r oberoende av xn f√∂r varje n = 0, . . . , k ,
2. wk √§r oberoende av xn f√∂r varje n = 0, . . . , k ,
3. vk √§r oberoende av yn f√∂r varje n = 0, . . . , k .
Bevis.

L√∂sningen (3.3) ger att vektorn

v0 , . . . , vn‚àí1 .

Enligt antagandet √§r

xn

√§r en funktion av

un = f (xn , yn )

av

wn .

eller med ins√§ttning av

x0 , u0 , . . . , un‚àí1 , v0 , . . . , vn‚àí1

l√∂sningen (3.3) och ekvation (3.2) en funktion av
och

Upprepad anv√§ndning av antagandena ger att

x0 , v0 , . . . , vn‚àí1 , w0 , . . . , wn .

x0 , v0 , . . . , vn‚àí1 , w0 , . . . , wn‚àí1 .
av

xn

d√•

yn = Cxn + Gwn

f√∂r varje

Anm√§rkning

Vidare f√•s ocks√• att

xn

un

f√∂ljer att

√§r oberoende av

vk

xn

√§r oberoende av

yn

√§r en funktion

√§r en funktion av

Enligt antagandena f√•s nu att

n = 0, . . . , k , wk

x0 , u0 , . . . , un‚àí1 ,

f√∂r varje
f√∂r varje

vk

√§r oberoende

n = 0, . . . , k ,

och

n = 0, . . . , k .

3.4. P√• grund av lineariteten hos systemet (3.1)(3.2) och lem-

man 3.2 och 3.3 f√∂ljer att
att processerna

{xk }k‚â•0

xn

samt

och

yn

√§r gaussiska f√∂r varje

{yk }k‚â•0

n ‚â• 0.

√§r gaussiska processer.

25

Detta betyder

KAPITEL 3.

OPTIMAL STOKASTISK ESTIMERING

Tuomas Virtanen

3.2 Estimering med Kalmanltret
Ofta √§r bara en del av tillst√•ndsvariablerna tillg√§ngliga och m√§tningen av dem
p√•verkas dessutom av m√§tfel eller m√§tbrus. Detta ger upphov till ett estimeringsproblem att best√§mma den b√§sta skattningen f√∂r hela tillst√•ndsvektorn, utg√•ende fr√•n den tillg√§ngliga informationen om systemet. Ett nytt s√§tt att l√∂sa detta
problem presenterades av den ungerskf√∂dda amerikanska matematikern Rudolf
E. Kalman i sin mycket inytelserika artikel [Kal60]. L√∂sningen har senare f√•tt
namnet

Kalmanltret.

I denna avhandling ges en tv√•delad formel av skattningen, Kalmanprediktorn
och Kalmankorrektorn. Id√©n med uppdelningen √§r att systemets tillst√•nd kan
estimeras av prediktorn vid varje tidpunkt √§ven om m√§tningar saknas ibland. D√•
en ny m√§tning √§r tillg√§nglig ger korrektorn en f√∂rb√§ttrad skattning av tillst√•ndet.
Prediktiorn √§r en

a priori-skattning

eftersom den best√§ms

det nuvarande tillst√•ndet har gjorts. Korrektorn √§r en
Skattningen av tillst√•ndet betecknas med

ÃÇ
x

f√∂re

en m√§tning av

a posteriori-skattning.

och kan best√§mmas enligt olika

kriterier. Ett s√§tt att best√§mma skattningen √§r s√• att det kvadratiska medelfelet

ÃÇ 2 ) minimeras. Detta ger en s√• kallad MMSE-skattning
E(‚à•x ‚àí x‚à•

(eng. minimum

mean square error) och enligt f√∂ljande lemma ges denna skattning av det betingade v√§ntev√§rdet. Lemmat √§r baserat p√• den f√∂r skal√§ra fallet [Ros10, Proposition
6.1, s. 349] och skrivs h√§r f√∂r reellv√§rda stokastiska vektorer.

Lemma 3.5.

L√•t x och y vara stokastiska vektorer p√• samma sannolikhetsrum

och l√•t œÉ(y) vara œÉ -algebran genererad av y . D√• √§r

ÃÇ := E(x | œÉ(y))
x

(3.4)

en œÉ(y)-m√§tbar stokastisk vektor som uppfyller

)Ô∏Å
(Ô∏Å
)Ô∏Å
(Ô∏Å
ÃÇ 2 ,
min E ‚à•x ‚àí z‚à•2 = E ‚à•x ‚àí x‚à•

(3.5)

z

d√§r z √§r œÉ(y)-m√§tbar.
Bevis.

F√∂r en godtycklig

œÉ(y)-m√§tbar

stokastisk vektor

z

g√§ller att

‚à•x ‚àí z‚à•2 = ‚à•x ‚àí E(x | œÉ(y)) + E(x | œÉ(y)) ‚àí z‚à•2
= ‚à•x ‚àí E(x | œÉ(y))‚à•2 + ‚à•E(x | œÉ(y)) ‚àí z‚à•2
(Ô∏Å
)Ô∏ÅT (Ô∏Å
)Ô∏Å
+ 2 E(x | œÉ(y)) ‚àí z
x ‚àí E(x | œÉ(y)) .
26

KAPITEL 3.

OPTIMAL STOKASTISK ESTIMERING

Tuomas Virtanen

D√• √§r

(Ô∏Å
)Ô∏Å
(Ô∏Å
)Ô∏Å
(Ô∏Å
)Ô∏Å
E ‚à•x ‚àí z‚à•2 = E ‚à•x ‚àí E(x | œÉ(y))‚à•2 + E ‚à•E(x | œÉ(y)) ‚àí z‚à•2
(Ô∏Ç(Ô∏Å
)Ô∏ÅT (Ô∏Å
)Ô∏Å)Ô∏Ç
+ 2 E E(x | œÉ(y)) ‚àí z
x ‚àí E(x | œÉ(y)) .

(3.6)

Vi kan anv√§nda tredje egenskapen i sats B.18 f√∂r den sista termen

E

(Ô∏Ç(Ô∏Å

)Ô∏ÅT (Ô∏Å

)Ô∏Å)Ô∏Ç
E(x | œÉ(y)) ‚àí z
x ‚àí E(x | œÉ(y))
(Ô∏É (Ô∏Ç
)Ô∏Ç)Ô∏É
(Ô∏Å
)Ô∏ÅT (Ô∏Å
)Ô∏Å ‚Éì
‚Éì
= E E E(x | œÉ(y)) ‚àí z
x ‚àí E(x | œÉ(y)) œÉ(y)

och eftersom

(Ô∏Å

E(x | œÉ(y)) ‚àí z

)Ô∏ÅT

√§r

œÉ(y)-m√§tbar f√•s enligt egenskap 5 i sats B.18

att

(Ô∏É
E

(Ô∏Ç(Ô∏Å

)Ô∏ÅT (Ô∏Å

)Ô∏Ç
)Ô∏Å ‚Éì
x ‚àí E(x | œÉ(y)) ‚Éì œÉ(y)

)Ô∏É

E(x | œÉ(y)) ‚àí z
(Ô∏Ç(Ô∏Å
)Ô∏ÅT (Ô∏Å
)Ô∏Å)Ô∏Ç
= E E(x | œÉ(y)) ‚àí z E x ‚àí E(x | œÉ(y)) | œÉ(y)
(Ô∏Ç(Ô∏Å
)Ô∏ÅT (Ô∏Å
)Ô∏Å)Ô∏Ç
= E E(x | œÉ(y)) ‚àí z
E(x | œÉ(y)) ‚àí E(E(x | œÉ(y)) ¬∑ 1 | œÉ(y))
(Ô∏Ç(Ô∏Å
)Ô∏ÅT (Ô∏Å
)Ô∏Å)Ô∏Ç
= E E(x | œÉ(y)) ‚àí z
E(x | œÉ(y)) ‚àí E(x | œÉ(y))

E

= 0.
Den andra termen i (3.6) √§r icke-negativ och d√• f√•s f√∂r varje

œÉ(y)-m√§tbar z

att

(Ô∏Å
)Ô∏Å
(Ô∏Å
)Ô∏Å
E ‚à•x ‚àí z‚à•2 ‚â• E ‚à•x ‚àí E(x | œÉ(y))‚à•2 ,
d√§r likhet g√§ller d√• och endast d√•

z = E(x | œÉ(y)).

S√•ledes har vi visat p√•st√•en-

det (3.5), det vill s√§ga det betingade v√§ntev√§rdet (3.4) minimerar det kvadratiska
medelfelet.
Enligt f√∂ljande sats g√§ller att om
√§ven den betingade f√∂rdelningen f√∂r

x och y

√§r simultant normalf√∂rdelade s√• √§r

x

y

givet

gaussisk. V√§ntev√§rdet och kova-

riansmatrisen best√§mmer entydigt f√∂rdelningen f√∂r en gaussisk vektor och dessa
ger explicita formler f√∂r att ber√§kna skattningen (3.4) som minimerar det kvadratiska medelfelet.

27

KAPITEL 3.

Sats 3.6.

OPTIMAL STOKASTISK ESTIMERING

Tuomas Virtanen

L√•t x ‚àà Rn och y ‚àà Rp vara normalf√∂rdelade stokastiska vektorer

s√•dana att deras simultana f√∂rdelning √§r gaussisk. Anta att kovariansmatrisen

Py > 0. D√• √§r den betingade f√∂rdelningen f√∂r x givet y gaussisk och det betingade
v√§ntev√§rdet ges av

(Ô∏Å
)Ô∏Å
E(x | œÉ(y)) = E(x) + Px,y Py‚àí1 y ‚àí E(y) .

(3.7)

Den betingade kovariansmatrisen √§r

Bevis.

d√§r

Cov(x | œÉ(y)) = Px ‚àí Px,y Py‚àí1 Py,x .

(3.8)

z = C1 x + C2 y,

(3.9)

S√§tt

C1

och

C2

Vidare g√§ller att

y

och

z

z
x

och

y

normalf√∂rdelad enligt lemma 3.2.

√§r simultant normalf√∂rdelade eftersom

(Ô∏Ñ )Ô∏Ñ
y

och

z

√§r konstanta matriser. D√• √§r

(Ô∏Ñ
=

0

I

)Ô∏Ñ (Ô∏Ñ )Ô∏Ñ
x
y

C1 C2

antas vara simultant normalf√∂rdelade.

Vi vill nu best√§mma

C1

och

C2

s√• att

y

och

z

√§r oberoende, vilket f√∂r nor-

malf√∂rdelade vektorer √§r ekvivalent med att de √§r okorrelerade enligt p√•st√•ende

3

i sats B.20. S√•ledes

0 = Cov(z, y)
(Ô∏Å
)Ô∏Å
= E (z ‚àí E(z))(y ‚àí E(y))T
(Ô∏Ç(Ô∏Å
)Ô∏Å(Ô∏Å
)Ô∏ÅT )Ô∏Ç
= E C1 (x ‚àí E(x)) + C2 (y ‚àí E(y)) y ‚àí E(y)
(Ô∏Å
)Ô∏Å
(Ô∏Å
)Ô∏Å
= C1 E (x ‚àí E(x))(y ‚àí E(y))T + C2 E (y ‚àí E(y))(y ‚àí E(y))T
= C1 Px,y + C2 Py .
Eftersom vi antar att

Py > 0 s√• kan vi multiplicera med inversen Py‚àí1

fr√•n h√∂ger

och f√•r att

C2 = ‚àíC1 Px,y Py‚àí1 ,
d√§r

C1

kan v√§ljas godtyckligt. Vi kan v√§lja

C1 = I

och d√• √§r

C2 = ‚àíPx,y Py‚àí1 .

Ins√§ttning i (3.9) ger att

z = x ‚àí Px,y Py‚àí1 y
28

(3.10)

KAPITEL 3.

OPTIMAL STOKASTISK ESTIMERING

√§r nu en vektor som √§r oberoende av

y.

Tuomas Virtanen

Vi kan nu best√§mma det betingade

v√§ntev√§rdet och kovariansen f√∂r vektorn

x = z + Px,y Py‚àí1 y.
Eftersom

z

√§r oberoende av

y

och

y

√§r

œÉ(y)-m√§tbar

har vi att

E(x | œÉ(y)) = E(z + Px,y Py‚àí1 y | œÉ(y))
= E(z | œÉ(y)) + Px,y Py‚àí1 E(y | œÉ(y))
= E(z) + Px,y Py‚àí1 y,
Vidare med ins√§ttning av (3.10) f√•s att

E(z) + Px,y Py‚àí1 y = E(x ‚àí Px,y Py‚àí1 y) + Px,y Py‚àí1 y
= E(x) ‚àí Px,y Py‚àí1 E(y) + Px,y Py‚àí1 y
= E(x) + Px,y Py‚àí1 (y ‚àí E(y)),
vilket visar (3.7).
Eftersom

z

√§r best√§md s√• att

betingade kovariansmatrisen f√∂r

x

Cov(z, y) = 0

och

y

√§r

œÉ(y)-m√§tbar

f√•s den

med hj√§lp av sats B.18 som

Cov(x | œÉ(y)) = Cov(z + Px,y Py‚àí1 y | œÉ(y))
= Cov(z | œÉ(y)) + Px,y Py‚àí1 Cov(y, z | œÉ(y))
+ Cov(z, y | œÉ(y))Py‚àí1 Py,x + Px,y Py‚àí1 Cov(y | œÉ(y))Py‚àí1 Py,x
= Cov(z | œÉ(y))
= Cov(z).
Vidare har vi med ins√§ttning av (3.10) och enligt lemma B.16 att

Cov(z) = Cov(x ‚àí Px,y Py‚àí1 y)
= Cov(x) ‚àí Px,y Py‚àí1 Cov(y, x)
‚àí Cov(x, y)Py‚àí1 Py,x + Px,y Py‚àí1 Cov(y)Py‚àí1 Py,x
= Px ‚àí Px,y Py‚àí1 Py,x ‚àí Px,y Py‚àí1 Py,x + Px,y Py‚àí1 Py Py‚àí1 Py,x
= Px ‚àí Px,y Py‚àí1 Py,x ,
vilket visar (3.8).

29

KAPITEL 3.

OPTIMAL STOKASTISK ESTIMERING

Enligt anm√§rkning 3.4 √§r tillst√•ndsvektorn

Gwk

gaussiska f√∂r varje

k ‚â• 0.

xk

Tuomas Virtanen

och m√§tningen

Eftersom m√§tbruset

wk

yk = Cxk +

√§r gaussiskt och obero-

xk enligt lemma 3.3 s√• f√∂ljer att vektorn
(Ô∏Ñ )Ô∏Ñ (Ô∏Ñ
)Ô∏Ñ (Ô∏Ñ
)Ô∏Ñ (Ô∏Ñ )Ô∏Ñ
xk
xk
I 0
xk
=
=
yk
Cxk + Gwk
C G
wk

ende av tillst√•ndet

√§r ocks√• gaussisk. Tillst√•ndsvektorn

xk

och m√§tningen

yk

√§r allts√• simultant

gaussiska och d√• √§r enligt sats 3.6 den betingade f√∂rdelningen f√∂r
gaussisk. D√• en m√§tning av

yk

xk

givet

yk

har gjorts kan det betingade v√§ntev√§rdet (3.7)

ber√§knas och kovariansmatrisen f√•s genom (3.8).

l

inf√∂rs be-

P0

f√∂r start-

F√∂r m√§ngden av tillg√§nglig information om systemet vid tiden
teckningen
tillst√•ndet

Yl ,
x0

vilket innefattar v√§ntev√§rdet
samt alla

tillg√§ngliga

Observera att f√∂r m√§ngden
tidpunkt
s√§ga

l = ‚àí1

Yk

m0

m√§tningar

och kovariansen

yi

upp till och med tidpunkt

beh√∂ver det inte g√§lla att m√§tningen

l.

yk ‚àà Yk . Vid

√§r endast information om starttillst√•ndet tillg√§ngligt, det vill

Y‚àí1 = {m0 , P0 }. A priori - och a posteriori -skattningarna kan nu denieras

enligt f√∂ljande.

Denition 3.7.

Prediktionen

vet informationen

2

ÃÇ k ‚à• ).
E(‚à•xk ‚àí x

Yl ,

d√§r

vid tiden

l < k,

k

√§r skattningen av tillst√•ndet

xk

gi-

som minimerar det kvadratiska medelfelet

Prediktionen betecknas med

ÃÇ k|l
x

och ges av det betingade v√§n-

tev√§rdet, allts√•

ÃÇ k|l := E(xk | Yl ),
x

l < k.

(3.11)

Den tillh√∂rande betingade kovariansmatrisen betecknas med

Pk|l := Cov(xk | Yl ),
Anm√§rkning
tillst√•ndet

l < k.

(3.12)

3.8. Det f√∂ljer direkt fr√•n denna denition att prediktionen av start-

x0

√§r

ÃÇ 0|‚àí1 = m0 ,
x

P0|‚àí1 = P0 .

(3.13)

Dessa √§r startv√§rden f√∂r b√•de prediktorn och korrektorn.
F√∂r korrektionen g√§ller ut√∂ver prediktionen att m√§tningen vid nuvarande tidpunkt √§r tillg√§nglig och denna m√§tning skrivs d√§rf√∂r ut explicit i det betingade
v√§ntev√§rdet och kovariansen.

30

KAPITEL 3.

OPTIMAL STOKASTISK ESTIMERING

Denition 3.9.

Yl ,

informationen
ka medelfelet

Korrektionen
d√§r

l<k
2

vid tiden

k

√§r skattningen av tillst√•ndet

samt m√§tningen

ÃÇ k ‚à• ).
E(‚à•xk ‚àí x

Tuomas Virtanen

yk ,

xk

givet

som minimerar det kvadratis-

Korrektionen betecknas med

ÃÇ k|k
x

och ges av det

betingade v√§ntev√§rdet, allts√•

ÃÇ k|k := E(xk | Yl , yk ),
x

l < k.

(3.14)

Den tillh√∂rande betingade kovariansmatrisen betecknas med

Pk|k := Cov(xk | Yl , yk ),
F√∂r

k ‚â• 1

l < k.

(3.15)

f√•s f√∂ljande resultat f√∂r prediktionen av tillst√•ndet

xk

som en

rekursion.

Sats 3.10 (Kalmanprediktorn). L√•t Yl , l < k vara den tillg√§ngliga informationen
och uk‚àí1 = f (Yl ) vara den k√§nda delen av reglersignalen u i tidsintervallet [k ‚àí

ÃÇ k‚àí1|l vara en given optimal skattning av tillst√•ndet vid
1 ‚àí ‚àÜt, k ‚àí 1). Vidare l√•t x
tidpunkt k ‚àí 1 och Pk‚àí1|l vara den givna tillh√∂rande kovariansmatrisen.
D√• f√•s prediktionen av tillst√•ndet xk , k ‚â• 1, f√∂r systemet

ÃÇ k|l = Ax
ÃÇ k‚àí1|l + Buk‚àí1 ,
x

(3.1)

enligt

l ‚â§k‚àí1

(3.16)

och den tillh√∂rande betingade kovariansmatrisen ges av

Pk|l = APk‚àí1|l AT + F Pv F T ,

(3.17)

d√§r Pv √§r kovariansmatrisen f√∂r processbruset.
Bevis.

Det stokastiska LTI-systemets tillst√•ndsekvation (3.1) kan ocks√• skrivas

xk = Axk‚àí1 + Buk‚àí1 + F vk‚àí1

(3.18)

och ins√§ttning av (3.18) i denitionen f√∂r prediktionen (3.11) ger

ÃÇ k|l = E(xk | Yl )
x
= E(Axk‚àí1 + Buk‚àí1 + F vk‚àí1 | Yl )
= A E(xk‚àí1 | Yl ) + B E(uk‚àí1 | Yl ) + F E(vk‚àí1 | Yl ).
Eftersom

vk‚àí1

uk‚àí1 = f (Yl ) √§r Yl -m√§tbar och som f√∂ljd av lemma 3.3 √§r processbruset

oberoende av informationen

Yl

s√• f√•r vi att

31

KAPITEL 3.

OPTIMAL STOKASTISK ESTIMERING

Tuomas Virtanen

A E(xk‚àí1 | Yl ) + B E(uk‚àí1 | Yl ) + F E(vk‚àí1 | Yl )
= A E(xk‚àí1 | Yl ) + Buk‚àí1 + F E(vk‚àí1 ).
Vidare d√•

E(vk‚àí1 ) = 0

och omskrivning med denitionen (3.11) f√•s

ÃÇ k‚àí1|l + Buk‚àí1 ,
A E(xk‚àí1 | Yl ) + Buk‚àí1 + F E(vk‚àí1 ) = Ax
vilket visar (3.16).
Den tillh√∂rande kovariansmatrisen √§r enligt denitionerna (3.12), (B.9)
och (3.11)

Pk|l = Cov(xk | Yl )
(Ô∏Ç(Ô∏Å
)Ô∏Ç
)Ô∏Å(Ô∏Å
)Ô∏ÅT
= E xk ‚àí E(xk | Yl ) xk ‚àí E(xk | Yl ) | Yl
(Ô∏Å
)Ô∏Å
ÃÇ k|l )(xk ‚àí x
ÃÇ k|l )T | Yl
= E (xk ‚àí x
Med ins√§ttning av (3.16) och (3.18) f√•s att

(Ô∏Å
)Ô∏Å
ÃÇ k|l )(xk ‚àí x
ÃÇ k|l )T | Yl
E (xk ‚àí x
(Ô∏Ç(Ô∏Å
)Ô∏Ç
)Ô∏Å(Ô∏Å
)Ô∏ÅT
ÃÇ k‚àí1|l ) + F vk‚àí1 A(xk‚àí1 ‚àí x
ÃÇ k‚àí1|l ) + F vk‚àí1 | Yl .
= E A(xk‚àí1 ‚àí x
Anv√§ndning av lemma 3.3 som s√§ger att
informationen

E

Yl

vk‚àí1

√§r oberoende av

xk‚àí1

samt av

ger att

(Ô∏Ç(Ô∏Å
)Ô∏Ç
)Ô∏Å(Ô∏Å
)Ô∏ÅT
ÃÇ k‚àí1|l ) + F vk‚àí1 A(xk‚àí1 ‚àí x
ÃÇ k‚àí1|l ) + F vk‚àí1 | Yl
A(xk‚àí1 ‚àí x
(Ô∏Å
)Ô∏Å
T )F T .
ÃÇ k‚àí1|l )(xk‚àí1 ‚àí x
ÃÇ k‚àí1|l )T | Yl AT + F E(vk‚àí1 vk‚àí1
= A E (xk‚àí1 ‚àí x

Slutligen ger en omskrivning med hj√§lp av denitionerna att

(Ô∏Å
)Ô∏Å
T )F T
ÃÇ k‚àí1|l )(xk‚àí1 ‚àí x
ÃÇ k‚àí1|l )T | Yl AT + F E(vk‚àí1 vk‚àí1
A E (xk‚àí1 ‚àí x
= A Cov(xk‚àí1 | Yl )AT + F Cov(vk‚àí1 )F T
= APk‚àí1|l AT + F Pv F T ,
vilket visar (3.17).

32

KAPITEL 3.

OPTIMAL STOKASTISK ESTIMERING

Tuomas Virtanen

F√∂r att kunna anv√§nda prediktionen (3.16) i sats 3.10 f√∂r att best√§mma
korrektionen (3.14) beh√∂vs f√∂rst n√•gra hj√§lpresultat. F√∂ljande lemma √§r enligt [√Öst70, Sats 7.3.3, s. 220].

Lemma 3.11.

L√•t x, y1 och y2 vara simultant normalf√∂rdelade stokastiska vek-

torer. Anta att y1 och y2 √§r oberoende och att kovariansmatriserna Py1 och Py2
√§r positivt denita. D√• g√§ller att

Bevis.

L√•t

E(x | y1 , y2 ) = E(x | y1 ) + E(x | y2 ) ‚àí E(x).
(Ô∏Ñ )Ô∏Ñ
(Ô∏Ñ
)Ô∏Ñ
y1
E(y1 )
y=
, d√• √§r E(y) =
och vi f√•r att
y2
E(y2 )

(Ô∏Ç(Ô∏Å
)Ô∏Å(Ô∏Å
)Ô∏ÅT )Ô∏Ç
x ‚àí E(x) y ‚àí E(y)
‚éõ
(Ô∏Ñ
)Ô∏ÑT ‚éû
(Ô∏Å
)Ô∏Å y1 ‚àí E(y1 )
‚é†
= E ‚éù x ‚àí E(x)
y2 ‚àí E(y2 )
(Ô∏Ç (Ô∏Ç(Ô∏Å
)Ô∏Å(Ô∏Å
)Ô∏ÅT )Ô∏Ç (Ô∏Ç(Ô∏Å
)Ô∏Å(Ô∏Å
)Ô∏ÅT )Ô∏Ç)Ô∏Ç
= E x ‚àí E(x) y1 ‚àí E(y1 )
, E x ‚àí E(x) y2 ‚àí E(y2 )
(Ô∏Ç
)Ô∏Ç
= Px,y1 Px,y2 .

Px,y = E

Eftersom

y1

och

y2

antas vara oberoende ges kovariansmatrisen f√∂r

(Ô∏Ñ
Py =

P y1

0

0

P y2

av

)Ô∏Ñ
,

observera att denna matris √§r inverterbar eftersom vi antar att

Py2 > 0.

y

P y1 > 0

och

Sats 3.6 ger nu att

E(x | y1 , y2 ) = E(x | y)
(Ô∏Å
)Ô∏Å
= E(x) + Px,y Py‚àí1 y ‚àí E(y)
(Ô∏Ñ
)Ô∏Ñ (Ô∏Ñ
)Ô∏Ñ
(Ô∏Ç
)Ô∏Ç P ‚àí1
0
y1 ‚àí E(y1 )
y1
= E(x) + Px,y1 Px,y2
0 Py‚àí1
y2 ‚àí E(y2 )
2
(Ô∏Å
)Ô∏Å
(Ô∏Å
)Ô∏Å
= E(x) + Px,y1 Py‚àí1
y1 ‚àí E(y1 ) + Px,y2 Py‚àí1
y2 ‚àí E(y2 )
1
2
(Ô∏Å
)Ô∏Å
(Ô∏Å
)Ô∏Å
‚àí1
= E(x) + Px,y1 Py‚àí1
y
‚àí
E(y
)
+
E(x)
+
P
P
y
‚àí
E(y
)
‚àí E(x)
1
1
x,y
2
2
2
y
1
2
= E(x | y1 ) + E(x | y2 ) ‚àí E(x).

33

KAPITEL 3.

Deniera

OPTIMAL STOKASTISK ESTIMERING

skattningsfelet

ÃÉ := x ‚àí x
ÃÇ,
x

enligt

Tuomas Virtanen

d√§r skattningen

ÃÇ
x

ges av (3.4).

D√• kan skattningsfelet f√∂r prediktionen respektive korrektionen betecknas med

ÃÉ k|l := xk ‚àí x
ÃÇ k|l ,
x

l < k,

och

ÃÉ k|k := xk ‚àí x
ÃÇ k|k .
x

F√∂ljande hj√§lpresultat enligt [√Öst70, s. 218220] ger n√•gra anv√§ndbara egenskaper
f√∂r skattningsfelet, bland annat att skattningsfelet

ÃÉ √§r oberoende av m√§tningen
x

y.

Lemma 3.12.

L√•t x och y vara simultant normalf√∂rdelade stokastiska vektorer.

ÃÇ = E(x | œÉ(y)) och x
ÃÉ =x‚àíx
ÃÇ . D√• g√§ller att x
ÃÉ och y √§r oberoende och att
L√•t x
ÃÉ och x
ÃÇ √§r oberoende. Vidare g√§ller att
x
ÃÉ = 0 och
E(x)
Bevis.

Det √§r klart att

ÃÉ = Cov(x | y) = Px|y .
Cov(x)

ÃÉ = E(x) ‚àí E( E(x | y)) = 0.
E(x)

simultant gaussiska vektorer s√• √§r ocks√•

ÃÉ
x

och

y

Eftersom

x

och

y

√§r

simultant gaussiska vektorer.

Eftersom de √§r gaussiska r√§cker det att visa att de √§r okorrelerade. Kovariansmatrisen f√∂r

ÃÉ
x

och

y

blir med ins√§ttning av (3.7)

(Ô∏Ç (Ô∏Å
)Ô∏ÅT )Ô∏Ç
ÃÉ y ‚àí E(y)
Px,y
ÃÉ = E x
(Ô∏Ç(Ô∏Å
)Ô∏Å(Ô∏Å
)Ô∏ÅT )Ô∏Ç
= E x ‚àí E(x | y) y ‚àí E(y)
)Ô∏É
(Ô∏É(Ô∏Ç
(Ô∏Å
)Ô∏Å)Ô∏Ç
‚àí1
T
= E x ‚àí E(x) + Px,y Py (y ‚àí E(y)) (y ‚àí E(y))
(Ô∏Ç(Ô∏Å
(Ô∏Ç(Ô∏Å
)Ô∏Å(Ô∏Å
)Ô∏ÅT )Ô∏Ç
)Ô∏Å(Ô∏Å
)Ô∏ÅT )Ô∏Ç
= E x ‚àí E(x) y ‚àí E(y)
‚àí Px,y Py‚àí1 E y ‚àí E(y) y ‚àí E(y)
= Px,y ‚àí Px,y Py‚àí1 Py
= 0.
S√•ledes √§r

y

och

ÃÉ
x

oberoende. Eftersom

egenskap 2 i sats B.18 s√• f√∂ljer att
och

ÃÉ
x

√§r oberoende av

y

ÃÇ
x

ÃÇ = E(x | y)
x

och

ÃÉ
x

√§r en funktion av

√§r oberoende.

Vidare d√•

f√•s att

ÃÉ = E(x
ÃÉx
ÃÉ T ) = E(x
ÃÉx
ÃÉ T | y)
Cov(x)
(Ô∏Å
)Ô∏Å
= E (x ‚àí E(x | y))(x ‚àí E(x | y))T | y
= Cov(x | y).

34

y

enligt

ÃÉ =0
E(x)

KAPITEL 3.

Anm√§rkning

OPTIMAL STOKASTISK ESTIMERING

Tuomas Virtanen

3.13. Observera att enligt lemma 3.12 f√•s att kovariansmatriserna

f√∂r skattningsfelen av prediktionen och korrektionen √§r lika med kovariansmatriserna (3.12) och (3.15), det vill s√§ga

ÃÉ k|l ) = Pk|l ,
Cov(x
F√∂r en given prediktion

ÃÇ k|l
yÃÇk|l := C x

ÃÇ k|l , l < k ,
x

ÃÉ k|k ) = Pk|k .
Cov(x
f√∂rv√§ntas utsignalen vid tidpunkt

innovationen

och d√• denieras

l < k.

Innovationen √§r allts√• den nya informationen som m√§tningen

ÃÇk
x

av tillst√•ndet

xk

vara

som

yÃÉk|l := yk ‚àí yÃÇk|l ,

ningen

k

(3.19)

yk

ger till skatt-

[Kay93, s. 395]. F√∂ljande hj√§lpresultat ger n√•gra

egenskaper f√∂r innovationen.

Lemma 3.14.

L√•t {wk }k‚â•0 vara gaussiskt vitt brus med v√§ntev√§rdet noll,

Cov(wk ) = Pw > 0 och wk √§r oberoende av x0 f√∂r varje k . D√• g√§ller f√∂r
innovationen

(3.19)

att

E(yÃÉk|l ) = 0.
ÃÇ k|l , f√•s kovariansGivet den tillh√∂rande kovariansmatrisen Pk|l f√∂r prediktionen x
matrisen f√∂r innovationen som

PyÃÉk|l = CPk|l C T + GPw GT

(3.20)

och denna kovariansmatris √§r inverterbar d√• G antas vara surjektiv. Vidare √§r

yÃÉk|l oberoende av alla m√§tningar y0 , . . . , yl , l < k .
Bevis.

Med hj√§lp av ekvationen (3.2) f√∂r utsignalen kan vi skriva innovatio-

nen (3.19) som

ÃÇ k|l
yÃÉk|l = Cxk + Gwk ‚àí C x
ÃÇ k|l ) + Gwk
= C(xk ‚àí x

(3.21)

ÃÉ k|l + Gwk .
= Cx
Lemma 3.12 ger att v√§ntev√§rdet f√∂r skattningsfelet
√§r

E(wk ) = 0,

ÃÉ k|l √§r 0 och enligt antagandet
x

d√• √§r

ÃÉ k|l ) + G E(wk ) = 0.
E(yÃÉk|l ) = C E(x

35

KAPITEL 3.

OPTIMAL STOKASTISK ESTIMERING

Enligt lemma 3.3 √§r

wk

wk

och

xn

oberoende f√∂r varje

ÃÉ k|l = xk ‚àí x
ÃÇ k|l
x

ocks√• oberoende av

f√∂r varje

Tuomas Virtanen

n, 0 ‚â§ n ‚â§ k , och d√§rmed √§r

l < k . D√• f√•s kovariansmatrisen

f√∂r innovationen som

PyÃÉk|l

)Ô∏Å(Ô∏Å
)Ô∏ÅT )Ô∏Ç
= E yÃÉk|l ‚àí E(yÃÉk|l ) yÃÉk|l ‚àí E(yÃÉk|l )
(Ô∏Å
)Ô∏Å
ÃÉ k|l + Gwk )(C x
ÃÉ k|l + Gwk )T
= E (C x
(Ô∏Ç(Ô∏Å

T
T T
ÃÉ k|l x
ÃÉT
= C E(x
k|l )C + G E(wk wk )G

= CPk|l C T + GPw GT .
Vidare ger lemma 3.12 att

ÃÉ k|l
x

√§r oberoende av m√§tningarna

y0 , . . . , yl

och d√•

f√∂ljer att innovationen (3.21) ocks√• √§r oberoende av dessa m√§tningar.
Kovariansmatrisen (3.20) f√∂r innovationen √§r inverterbar eftersom

y T (CPk|l C T + GPw GT )y = (C T y)T Pk|l (C T y) + (GT y)T Pw (GT y)
‚â• (GT y)T Pw (GT y)
‚â• 0,
d√§r likhet g√§ller d√• och endast d√•
endast d√•

y‚â°0

GT y = 0.

PyÃÉk|l > 0

och det f√∂ljer att

D√•

G

√§r surjektiv g√§ller detta

och s√•ledes inverterbar.

F√∂ljande resultat ger korrektionssteget f√∂r Kalmanltret.

Sats 3.15

.

(Kalmankorrektorn)

ÃÇ k|l vara den optimala skattF√∂r l < k , l√•t x

ningen av tillst√•ndet xk givet informationen Yl och l√•t Pk|l vara den tillh√∂rande
kovariansmatrisen. Dessa ges av Kalmanprediktorn i sats 3.10. L√•t yk vara en
m√§tning vid nuvarande tidpunkt k . D√• ges korrektionen av

ÃÇ k|k = x
ÃÇ k|l + Kk yÃÉk|l ,
x
d√§r Kk √§r

Kalmanf√∂rst√§rkningen

(3.22)

denierad enligt

Kk := Pk|l C T (CPk|l C T + GPw GT )‚àí1
och yÃÉk|l √§r innovationen

(3.19).

(3.23)

Den tillh√∂rande kovariansmatrisen √§r

Pk|k = (I ‚àí Kk C)Pk|l .
Bevis.
av

D√• prediktionen

(Yl , yk )

enligt

ÃÇ k|l = E(xk | Yl )
x

ÃÇ k|l
yÃÉk|l = yk ‚àí C x

√§r given s√• best√§ms

(3.24)

(Yl , yÃÉk|l )

och d√• g√§ller f√∂ljande likhet

ÃÇ k|k = E(xk | Yl , yk ) = E(xk | Yl , yÃÉk|l ).
x
36

entydigt

KAPITEL 3.

OPTIMAL STOKASTISK ESTIMERING

Lemma 3.14 s√§ger att innovationen
kovariansmatrisen

PyÃÉk|l

yÃÉk|l

Tuomas Virtanen

√§r oberoende av informationen

Yl

och

√§r inverterbar. D√• kan vi anv√§nda lemma 3.11, sats 3.6

och lemma 3.14 f√∂r att f√•

E(xk | Yl , yÃÉk|l ) = E(xk | Yl ) + E(xk | yÃÉk|l ) ‚àí E(xk )
(Ô∏Å
)Ô∏Å
ÃÇ k|l + E(xk ) + Pxk ,yÃÉk|l PyÃÉ‚àí1
ÃÉ
ÃÉ
=x
y
‚àí
E(
y
)
‚àí E(xk )
k|l
k|l
k|l

(3.25)

ÃÇ k|l + Pxk ,yÃÉk|l PyÃÉ‚àí1
=x
yÃÉk|l .
k|l
Lemma 3.14 ger kovariansmatrisen

PyÃÉk|l

och vi beh√∂ver √§nnu best√§mma

Pxk ,yÃÉk|l .

ÃÇ k|l + xk ‚àí x
ÃÇ k|l = x
ÃÇ k|l + x
ÃÉ k|l och eftersom E(yÃÉk|l ) = 0
xk = x
(Ô∏Ç(Ô∏Å
)Ô∏Å T )Ô∏Ç
Pxk ,yÃÉk|l = E xk ‚àí E(xk ) yÃÉk|l
(Ô∏Ç(Ô∏Å
)Ô∏Å T )Ô∏Ç
ÃÇ k|l + x
ÃÉ k|l ‚àí E(x
ÃÇ k|l + x
ÃÉ k|l ) yÃÉk|l
=E x
(Ô∏Ç(Ô∏Å
(Ô∏Ç(Ô∏Å
)Ô∏Å T )Ô∏Ç
)Ô∏Å T )Ô∏Ç
ÃÇ k|l ‚àí E(x
ÃÇ k|l ) yÃÉk|l
ÃÉ k|l ‚àí E(x
ÃÉ k|l ) yÃÉk|l
.
+E x
=E x

Vi kan skriva

f√•s att

(3.26)

ÃÇ k|l √§r en funktion av Yl
yÃÉk|l oberoende
av Yl och eftersom x
(Ô∏Ç(Ô∏Å
)Ô∏Å T )Ô∏Ç
ÃÉ k|l ) = 0 och d√• √§r
ÃÇ k|l ‚àí E(x
ÃÇ k|l ) yÃÉk|l = 0. Enligt lemma 3.12 √§r E(x
E x

Enligt lemma 3.14 √§r
f√•s att

E

(Ô∏Ç(Ô∏Å
(Ô∏Ç(Ô∏Å
(Ô∏Å
)Ô∏Å T )Ô∏Ç
)Ô∏Å T )Ô∏Ç
T )Ô∏Å.
ÃÉ k|l yÃÉk|l
ÃÇ k|l ‚àí E(x
ÃÇ k|l ) yÃÉk|l
ÃÉ k|l ‚àí E(x
ÃÉ k|l ) yÃÉk|l
=E x
+E x
x
wk

Enligt lemma 3.3 √§r
√§r

wk

och

ocks√• oberoende av

xn

oberoende f√∂r varje

ÃÉ k|l = xk ‚àí x
ÃÇ k|l
x

f√∂r varje

n, 0 ‚â§ n ‚â§ k ,

l < k.

(3.27)

och d√§rmed

Nu f√•s med ins√§ttning

av (3.21) i (3.27) att

(Ô∏Å
)Ô∏Å
T )Ô∏Å = E (Ô∏Åx
ÃÉ k|l yÃÉk|l
ÃÉ k|l (C x
ÃÉ k|l + Gwk )T
E x
T
ÃÉ k|l x
ÃÉT
ÃÉ k|l wkT )GT
= E(x
k|l )C + E(x

(3.28)

= Pk|l C T .
Ins√§ttning av (3.20) och (3.28) i (3.25) ger att

ÃÇ k|k = x
ÃÇ k|l + Pk|l C T (CPk|l C T + GPw GT )‚àí1 yÃÉk|l
x
ÃÇ k|l + Kk yÃÉk|l .
=x
Den tillh√∂rande kovariansmatrisen blir enligt (3.22), (3.21), lemma 3.12 och an-

37

KAPITEL 3.

OPTIMAL STOKASTISK ESTIMERING

Tuomas Virtanen

m√§rkning 3.13

ÃÉ k|k )
Pk|k = Cov(x
)Ô∏Å
(Ô∏Å
ÃÇ k|k )(xk ‚àí x
ÃÇ k|k )T
= E (xk ‚àí x
(Ô∏Ç(Ô∏Å
)Ô∏Å(Ô∏Å
)Ô∏ÅT )Ô∏Ç
ÃÇ
ÃÉ
ÃÇ
ÃÉ
= E xk ‚àí (xk|l + Kk yk|l ) xk ‚àí (xk|l + Kk yk|l )
(Ô∏Ç(Ô∏Å
)Ô∏Å(Ô∏Å
)Ô∏ÅT )Ô∏Ç
ÃÉ k|l ‚àí Kk (C x
ÃÉ k|l + Gwk ) x
ÃÉ k|l ‚àí Kk (C x
ÃÉ k|l + Gwk )
=E x
(Ô∏Ç(Ô∏Å
)Ô∏Å(Ô∏Å
)Ô∏ÅT )Ô∏Ç
ÃÉ k|l ‚àí Kk Gwk (I ‚àí Kk C)x
ÃÉ k|l ‚àí Kk Gwk
= E (I ‚àí Kk C)x

(3.29)

T
T
T
ÃÉ k|l x
ÃÉT
= (I ‚àí Kk C) E(x
k|l )(I ‚àí Kk C) + Kk G E(wk wk )(Kk G)

= (I ‚àí Kk C)Pk|l (I ‚àí Kk C)T + Kk GPw GT KkT .
Vidare kan vi f√∂renkla detta uttryck enligt

(I ‚àí Kk C)Pk|l (I ‚àí Kk C)T + Kk GPw GT KkT
= (I ‚àí Kk C)Pk|l ‚àí (I ‚àí Kk C)Pk|l C T KkT + Kk GPw GT KkT
= (I ‚àí Kk C)Pk|l ‚àí Pk|l C T KkT + Kk CPk|l C T KkT + Kk GPw GT KkT
= (I ‚àí Kk C)Pk|l + (Kk CPk|l C T + Kk GPw GT ‚àí Pk|l C T )KkT
(Ô∏Å
)Ô∏Å
= (I ‚àí Kk C)Pk|l + Kk (CPk|l C T + GPw GT ) ‚àí Pk|l C T KkT
= (I ‚àí Kk C)Pk|l + (Pk|l C T ‚àí Pk|l C T )KkT
= (I ‚àí Kk C)Pk|l ,
vilket visar (3.24).

Anm√§rkning

3.16. Observera att

Kk CPk|l = Pk|l C T (CPk|l C T + GPw GT )‚àí1 CPk|l ‚â• 0
och d√• √§r

Pk|k = Pk|l ‚àí Kk CPk|l ‚â§ Pk|l .
Den tillh√∂rande kovariansmatrisen f√∂r korrektionen √§r allts√• mindre √§n den tillh√∂rande kovariansmatrisen f√∂r prediktionen.
Kovariansmatrisen p√• sista raden i (3.29) √§r i

Josephs form

och den √§r att

Pk|k

√§r symmetrisk.

f√∂redra i numeriska ber√§kningar eftersom den s√§kerst√§ller att

Avrundningsfel kan f√∂rorsaka att (3.24) inte √§r positivt denit, vilket kr√§vs av
teorin. En anm√§rkningsv√§rd egenskap f√∂r prediktionen och korrektionen samt
deras tillh√∂rande kovariansmatriser √§r att de kan ges som rekursiva formler, enligt

38

KAPITEL 3.

OPTIMAL STOKASTISK ESTIMERING

Tuomas Virtanen

satserna 3.10 och 3.15. S√•ledes beh√∂vs allts√• endast den f√∂reg√•ende optimala
skattningen f√∂r att ber√§kna n√§sta optimala skattning och tidigare skattningar
ger ingen ytterligare information. Detta √§r den s√• kallade

Markovegenskapen

f√∂r

stokastiska processer.

3.3 Station√§rt Kalmanlter
Som p√•pekades i anm√§rkning 3.8 beh√∂vs

E(x0 ) = m0

och

Cov(x0 ) = P0

som

startv√§rden f√∂r att kunna rekursivt ber√§kna den optimala skattningen av tillst√•ndet. Under vissa villkor konvergerar kovariansmatrisen och s√•ledes Kalmanf√∂rst√§rkningen till station√§ra v√§rden, som √§r oberoende av startv√§rdet

P0 .

Den

tillh√∂rande kovariansmatrisen f√∂r korrektorn enligt (3.24) √§r

Pk|k = (I ‚àí Kk C)Pk|k‚àí1 .
Med ins√§ttning av Kalmanf√∂rst√§rkningen (3.23) f√•s att

Pk|k = Pk|k‚àí1 ‚àí Pk|k‚àí1 C T (CPk|k‚àí1 C T + GPw GT )‚àí1 CPk|k‚àí1 .
Prediktorns kovariansmatris (3.17) vid tidpunkt

k+1

(3.30)

√§r

Pk+1|k = APk|k AT + F Pv F T .
Beteckna

Œ£k := Pk+1|k

och l√•t

Pv = J J T

f√∂r n√•gon

(3.31)

n√óq

matris

J.

D√• ger

ins√§ttning av (3.30) i (3.31) att

(Ô∏Å
)Ô∏Å
Œ£k = A Pk|k‚àí1 ‚àí Pk|k‚àí1 C T (CPk|k‚àí1 C T + GPw GT )‚àí1 CPk|k‚àí1 AT + F Pv F T
= AŒ£k‚àí1 AT + F JJ T F T ‚àí AŒ£k‚àí1 C T (CŒ£k‚àí1 C T + GPw GT )‚àí1 CŒ£k‚àí1 AT .
(3.32)
Detta liknar Riccatiekvationen (2.29) f√∂r deterministisk optimal reglering och ett
liknande resultat f√•s f√∂r konvergens. Resultatet f√∂ljer direkt fr√•n sats 2.23.

Sats 3.17.

Anta att Pv ‚â• 0, Pw > 0, G surjektiv, matrisparet (C, A) √§r de-

tekterbart och matrisparet (A, F J ) √§r stabiliserbart, d√§r J J T = Pv . Beteckna
l√∂sningen vid tidpunkt k = N till

(3.32),

startad fr√•n Œ£0 , med Œ£N (Œ£0 ) och l√•t

K(Œ£) := Œ£C T (CŒ£C T + GPw GT )‚àí1 .
D√• g√§ller f√∂ljande p√•st√•enden:
39

(3.33)

KAPITEL 3.

OPTIMAL STOKASTISK ESTIMERING

Tuomas Virtanen

Det nns en entydig matris Œ£‚àí ‚â• 0, oberoende av Œ£0 , s√• att

lim Œ£N (Œ£0 ) = Œ£‚àí .

N ‚Üí‚àû

Matrisen Œ£‚àí satiserar den algebraiska Riccatiekvationen

Œ£ = AŒ£AT + F Pv F T ‚àí AŒ£C T (CŒ£C T + GPw GT )‚àí1 CŒ£AT

(3.34)

och matrisen A‚àíAK(Œ£‚àí )C √§r stabil. Vidare g√§ller att om matrisparet (A, F J )
√§r styrbart s√• √§r Œ£‚àí > 0.
Eftersom matrisen

Œ£‚àí

√§r entydig s√• kan vi beteckna den tidsinvarianta Kal-

manf√∂rst√§rkningen med

K := K(Œ£‚àí ) = Œ£‚àí C T (CŒ£‚àí C T + GPw GT )‚àí1
och det

station√§ra Kalmanltret

ges av

ÃÇ k+1 = Ax
ÃÇ k + Buk + AK yÃÉk ,
x
d√§r

(3.35)

(3.36)

ÃÇ k . Detta system har en liknande form som Luenbergerobservat√∂yÃÉk = yk ‚àíC x

ren (2.13) och √§r en tillst√•ndsobservat√∂r till det stokastiska systemet (3.1)(3.2),
det vill s√§ga

xk+1 = Axk + Buk + F vk ,
yk = Cxk + Gwk .
Skattningsfelet ges av

ÃÉ k = xk ‚àí x
ÃÇk,
x

(3.1)
(3.2)

s√• felsystemet √§r

ÃÉ k+1 = xk+1 ‚àí x
ÃÇ k+1
x
ÃÇ k + Buk + AK yÃÉk )
= Axk + Buk + F vk ‚àí (Ax
ÃÇ k ) + F vk ‚àí AK(yk ‚àí C x
ÃÇk)
= A(xk ‚àí x
ÃÇ k ) + F vk ‚àí AK(Cxk + Gwk ‚àí C x
ÃÇk)
= A(xk ‚àí x
ÃÉ k + F vk ‚àí AKGwk .
= (A ‚àí AKC)x
Skattningsfelet √§r allts√• ett stokastiskt system med systemmatrisen
och vitt brus

F Pv F

T

matrisen

Œ∑k = F vk ‚àí AKGwk

+ AKGPw (AKG)
A ‚àí AKC

T

A ‚àí AKC

med v√§ntev√§rdet noll och kovariansen

. Om antagandena i sats 3.17 √§r uppfylda s√• √§r

stabil och d√• kovergerar det station√§ra Kalmanltrets till-

st√•nd (3.36) mot det stokastiska systemets tillst√•nd.

40

KAPITEL 3.

OPTIMAL STOKASTISK ESTIMERING

Tuomas Virtanen

Sambandet mellan det station√§ra Kalmanltret och prediktorn samt korrektorn i denna avhandling f√•s enligt f√∂ljande. Prediktionen som ges av sats 3.10
√§r

ÃÇ k+1|k = Ax
ÃÇ k|k + Buk ,
x
d√§r

ÃÇ k|k
x

(3.37)

√§r korrektionen i sats 3.15, det vill s√§ga

ÃÇ k|k = x
ÃÇ k|k‚àí1 + Kk yÃÉk|k‚àí1 .
x

(3.38)

Ins√§ttning av (3.38) i (3.37) ger

ÃÇ k+1|k = A(x
ÃÇ k|k‚àí1 + Kk yÃÉk|k‚àí1 ) + Buk
x
ÃÇ k|k‚àí1 + Buk + AKk yÃÉk|k‚àí1 ,
= Ax
vilket √§r p√• formen (3.36), med tidsvariant Kalmanf√∂rst√§rkning. D√• villkoren i
sats 3.17 √§r uppfylda kovergerar

Kk

mot den tidsinvarianta (3.35).

3.4 Sampling av tidskontinuerliga stokastiska system
Hittills har tidsdiskreta stokastiska system behandlats och hur man best√§mmer
en optimal skattning av tillst√•ndet baserat p√• tillg√§nglig information, s√• att det
kvadratiska medelfelet minimeras. Modellerna f√∂r systemen √§r f√∂rst√•s oftast tidskontinuerliga. Fr√•gan √§r om ett tidskontinuerligt stokastiskt system kan samplas
s√• att det diskretiserade systemet har samma stokastiska egenskaper som det
tidskontinuerliga systemet vid samplingstidpunkterna. Bruset f√∂r tidskontinuerliga system modelleras med

Denition 3.18.
(‚Ñ¶, A, P)
1.

En

Brownsk r√∂relse,

ocks√• kallad

Wienerprocess {Wt }t‚â•0

i

R

p√•

Wienerprocess.
sannolikhetsrummet

uppfyller f√∂ljande villkor:

W0 = 0.
Wt ‚àº N (0, œÉ 2 t).

2. F√∂r

t>0

3. F√∂r

0 ‚â§ t1 < . . . < tk

√§r

g√§ller att inkrementen

oberoende.
4. F√∂r varje

œâ‚àà‚Ñ¶

√§r

t ‚Üí Wt (œâ)

kontinuerlig.

41

Wtk ‚àí Wtk‚àí1 , . . . , Wt2 ‚àí Wt1

√§r

KAPITEL 3.

OPTIMAL STOKASTISK ESTIMERING

Denition 3.19.
en

En process

{Wt }t‚â•0 := {( Wt(1)

n-dimensionell Wienerprocess

(2)

Wt

Tuomas Virtanen

(n)

... Wt

)T }t‚â•0

i

Rn

kallas

(1)
(2)
(n)
om dess komponenter Wt , Wt , . . . , Wt
√§r

oberoende endimensionella Wienerprocesser.

Denition 3.20. Autokorrelationsfunktionen rX (t1 , t2 ) f√∂r en stokastisk process
{Xt }t‚â•0 denieras som
rX (t1 , t2 ) := E(Xt1 XT
t2 ).
Om autokorrelationsfunktionen beror endast p√• skillnaden

œÑ = t‚àís, s < t, skrivs

rX (œÑ ) := E(Xs XT
s+œÑ ).

Denition 3.21.
n√§r

En tidskontinuerlig stokastisk process

{Xt }t‚ààR

√§r

svagt statio-

om det g√§ller att

1.

E(Xt ) = ¬µ,

2.

rX (t1 , t2 ) = rX (t1 ‚àí t2 ),

f√∂r varje

t ‚àà R,
f√∂r varje

t1 , t2 ‚àà R.

F√∂ljande lemma f√∂ljer direkt fr√•n denitionerna.

Lemma 3.22.
(i)

d√§r Wt

L√•t {Wt }t‚â•0 = {( Wt(1)

(2)

Wt

‚éõ

œÉ12 œÑ

‚éú
rW (œÑ ) = Cov(WœÑ ) = ‚éú
‚éù
0
Matrisen PW kallas ibland

d√§r

)T }t‚â•0 vara en Wienerprocess,

‚àº N (0, œÉi2 t). D√• √§r {Wt }t‚â•0 en svagt station√§r process och det g√§ller

att

En

(n)

... Wt

0
..

.

œÉn2 œÑ

‚éû
‚éü
‚éü = PW œÑ.
‚é†

inkrementella kovariansmatrisen

f√∂r processen Wt .

stokastisk dierentialekvation √§r av formen
‚éß
(Ô∏Å
)Ô∏Å
‚é®dx(t) = Ax(t) + Bu(t) dt + HdWt ,
‚é© x(0) = x0 ,

Wt

(3.39)

√§r en Wienerprocess. L√∂sningen ges av en stokastisk integral, f√∂r vilken

teorin √§r omfattande och kan l√§sas i till exempel [√òks98]. H√§r ges endast resultatet som diskretiserar systemet, enligt [√Öst70, Sats 3.10.1, s. 84], modierad att
ocks√• inneh√•lla styrsignalen

u(t)

som samplas med nollte ordningens h√•llkrets

p√• samma s√§tt som i avsnitt 2.1.1 f√∂r deterministiska system.

42

KAPITEL 3.

Sats 3.23.

OPTIMAL STOKASTISK ESTIMERING

Tuomas Virtanen

L√•t T > 0 vara samplingstiden. D√• f√•s att systemets

(3.39)

tillst√•nd

vid de diskreta tidpunkterna tk = kT , k = 0, 1, . . . √§r

xk+1 = Ad (T )xk + Bd (T )uk + vk ,
d√§r

Ad (T ) := e

AT

och Bd (T ) :=

(3.40)

T

‚à´Ô∏Ç

eAœÑ dœÑ B.

0

Processen {vk }k‚â•0 √§r gaussiskt vitt brus med v√§ntev√§rdet noll och kovariansmatrisen

T

‚à´Ô∏Ç
Pv =

Ad (œÑ )HPW H T AT
d (œÑ )dœÑ,

(3.41)

0

d√§r PW √§r inkrementella kovariansmatrisen f√∂r Wienerprocessen Wt i

(3.39).

Exempel 2.1 kan nu utvidgas med st√∂rningar. Systemet samplas och sedan
kan Kalmanltret till√§mpas p√• det diskretiserade systemet f√∂r att estimera positionen.

Exempel 3.24.
y

L√•t st√∂rningarna vara i form av √§ndringar i acceleration i

x och

riktningar. D√• kan tillst√•ndsekvationen i exempel 2.3 skrivas som en stokastisk

dierentialekvation

‚éõ
‚éû‚éõ ‚éû
0
x1
0 0 1 0
‚éú
‚éü‚éú ‚éü
‚éú ‚éü ‚éú
‚éú
‚éúdx2 ‚éü ‚éú0 0 0 1‚éü ‚éúx2 ‚éü
‚éü ‚éú ‚éü dt + ‚éú0
‚éú ‚éü=‚éú
‚éú1
‚éúdx ‚éü ‚éú0 0 0 0‚éü ‚éúx ‚éü
‚éù
‚é† ‚éù 3‚é†
‚éù 3‚é† ‚éù
0
x4
0 0 0 0
dx4
‚éõ

d√§r

x1 , x2

√§r

riktning och

dx1

x

‚éû

‚éõ

respektive

dv1 , dv2

y

positionen,

x3 , x4

0

‚éû

‚éü (Ô∏Ñ )Ô∏Ñ
0‚éü
‚éü dv1 ,
0‚éü
‚é† dv2
1

√§r hastigheten i

x

(3.42)

respektive

y

√§r st√∂rningar. Ekvation (3.42) √§r p√• formen

dx(t) = Ax(t)dt + HdVt
och detta diskretiseras med samplingsperioden

‚àÜt.

Den diskreta tillst√•ndsekva-

tion f√∂r systemet √§r

xk+1 = As xk + vk .
Sats 3.23 ger att

As = e

A‚àÜt

‚éõ
1
‚éú
‚éú0
=‚éú
‚éú0
‚éù
0
43

0 ‚àÜt
1

0

0

1

0

0

0

‚éû

‚éü
‚àÜt‚éü
‚éü,
0‚éü
‚é†
1

KAPITEL 3.

OPTIMAL STOKASTISK ESTIMERING

vilken ber√§knades redan i exempel 2.3 . Processen

{vk }k‚â•0

Tuomas Virtanen

√§r gaussiskt vitt brus

med v√§ntev√§rdet noll och kovariansen blir enligt sats 3.23

‚àÜt

‚à´Ô∏Ç
Pv =

eAs HPV (eAs H)T ds.

0
Vi har att

L√•t

Vt ,

PV =

‚éû‚éõ
0
1 0 s 0
‚éü‚éú
‚éú
‚éú0 1 0 s ‚éü ‚éú0
‚éü‚éú
eAs H = ‚éú
‚éú0 0 1 0‚éü ‚éú1
‚é†‚éù
‚éù
0
0 0 0 1
)Ô∏Ç
‚éõ

(Ô∏Ç

2
œÉv1
0
2
0 œÉv2

‚éû
s 0
‚éü
‚éü ‚éú
‚éú0 s‚éü
0‚éü
‚éü
‚éü=‚éú
‚éú1 0‚éü .
0‚éü
‚é†
‚é† ‚éù
0 1
1
0

‚éû

‚éõ

vara inkrementella kovariansmatrisen f√∂r Wienerprocessen

d√• √§r

‚éû
s 0
)Ô∏Ñ (Ô∏Ñ
)Ô∏Ñ
‚éü (Ô∏Ñ 2
‚à´Ô∏Ç ‚àÜt ‚éú
‚éú0 s‚éü œÉv1
0
s
0
1
0
‚éü
‚éú
ds
Pv =
‚éú1 0 ‚éü 0 œÉ 2
0
s
0
1
0
‚é†
‚éù
v2
0 1
‚éû
‚éõ
2 2
2
œÉv1
s
0
œÉv1
s 0
‚éü
‚à´Ô∏Ç ‚àÜt ‚éú
2 ‚éü
2 2
‚éú 0
s‚éü
s
0 œÉv2
œÉv2
‚éú
ds
=
‚éú œÉ2 s
2
0
œÉv1
0 ‚éü
0
‚é†
‚éù v1
2
2
s
0
œÉv2
0
œÉv2
‚éõ œÉ2 (‚àÜt)3
‚éû
2 (‚àÜt)2
œÉv1
v1
0
0
2
2 (‚àÜt)3
2 (‚àÜt)2 ‚éü
‚éú 3
œÉv2
œÉv2
‚éú 0
‚éü
0
3
2
‚éü.
=‚éú
2
2
‚éú œÉv1 (‚àÜt)
‚éü
2
0
œÉ
‚àÜt
0
‚éù 2
‚é†
v1
2 (‚àÜt)2
œÉv2
2
0
0
œÉv2 ‚àÜt
2
‚éõ

(3.43)

L√•t m√§tbruset vara gaussiskt vitt brus med v√§ntev√§rdet noll och kovariansmatrisen

Pw =

(Ô∏Ç

2
œÉw1
0
2
0 œÉw2

)Ô∏Ç

.

(3.44)

Den tidsdiskreta modellen av systemet ges nu av

xk+1 = Axk + vk ,

vk ‚àº N4 (0, Pv ),

yk = Cxk + wk ,

wk ‚àº N2 (0, Pw ),

44

KAPITEL 3.

OPTIMAL STOKASTISK ESTIMERING

Tuomas Virtanen

d√§r systemmatriserna ges av

‚éõ

1 0 ‚àÜt

‚éú
‚éú0 1
A=‚éú
‚éú0 0
‚éù
0 0

0
1
0

0

‚éû

‚éü
‚àÜt‚éü
‚éü,
0‚éü
‚é†
1

(Ô∏Ñ
C=

)Ô∏Ñ
1 0 0 0
0 1 0 0

och kovariansmatriserna ges av (3.43) samt (3.44).
F√∂r att se hur estimatet som ges av prediktionen eller korrektionen avviker
sig fr√•n det verkliga tillst√•ndet och m√§tningen har detta simulerats med Mat-

lab. Koden f√∂r programmet nns i bilaga C.1. Bilens starttillst√•nd
slumpm√§ssigt enligt en normalf√∂rdelning med v√§ntev√§rdet
ansmatrisen

P0 = I .

m0 = 0

x0

v√§ljs

och kovari-

Varianserna f√∂r processbruset och m√§tbruset antas vara

2
2
2
2
= 14 , œÉv1
=1
= œÉw2
= œÉv2
œÉw1

och samplingsintervallet s√§tts till

‚àÜt =

1
. D√• √§r
10

processbrusets kovariansmatris f√∂r det diskretiserade systemet

‚éõ

0.0003

0

0.0050

0

‚éû

‚éü
‚éú
‚éü
‚éú 0
0.0003
0
0.0050
‚éü.
Pv = ‚éú
‚éú0.0050
0
0.1000
0 ‚éü
‚é†
‚éù
0
0.0050
0
0.1000
Prediktionen ges av

ÃÇ k|l = Ax
ÃÇ k‚àí1|l ,
x

Pk|l = APk‚àí1|l AT + Pv

och korrektionen ges av

ÃÇ k|k = x
ÃÇ k|k‚àí1 + Kk (yk ‚àí C x
ÃÇ k|k‚àí1 ),
x
Kk = Pk|k‚àí1 C T (CPk|k‚àí1 C T + Pw )‚àí1 ,
Pk|k = Pk|k‚àí1 ‚àí Kk CPk|k‚àí1 .
Prediktionen av starttillst√•ndet √§r

ÃÇ 0|‚àí1 = m0 = 0,
x

P0|‚àí1 = P0 = I.

En simulering med dessa parametrar d√§r m√§tningen g√∂rs vid varje steg och
s√•ledes kan korrektionen anv√§ndas vid varje steg illustreras i gur 3.1. Anv√§ndning av samma bana och st√∂rningar men m√§tningar vid var fj√§rde steg, s√• att
prediktionen anv√§nds f√∂r att estimera positionen vid de √∂vriga tidpunkterna,
illustreras i gur 3.2.

45

KAPITEL 3.

OPTIMAL STOKASTISK ESTIMERING

Tuomas Virtanen

Figur 3.1: Simulerad bana, m√§tningar och skattning av positionen enligt Kalmankorrektorn.

Figur 3.2: Samma bana som gur 3.1, m√§tningar vid var fj√§rde steg och skattning
av positionen enligt Kalmanprediktorn.

46

KAPITEL 4.

OPTIMAL STOKASTISK REGLERING

Tuomas Virtanen

Kapitel 4
Optimal stokastisk reglering
4.1 Reglerproblemet
I avsnitt 2.4 best√§mdes den optimala reglersignalen som minimerar den kvadratiska kostnadsfunktionalen (2.17) f√∂r det linj√§ra deterministiska systemet (2.7).
Motsvarande fundamentala stokastiska reglerproblem √§r det

gaussiska reglerproblemet

eller

LQG-problemet

linj√§rkvadratiska

(eng. linear-quadratic-Gaussian

control problem) f√∂r linj√§ra system med vitt brus. D√• tillst√•ndsvektorn √§r stokastisk blir kostnaden (2.17) en stokastisk variabel och kostnadsfunktionalen f√∂r
stokastiska reglerproblemet v√§ljs att vara v√§ntev√§rdet av (2.17) och betecknas
med

(Ô∏Ñ
)Ô∏Ñ
N
‚àí1
‚àëÔ∏Ç
(Ô∏Å
)Ô∏Å
T
(xT
lN (x0 , u) := E JN (x0 , u) = E xT
N SN xN +
k Qxk + uk Ruk ) .

(4.1)

k=0
Analogt med deterministiska fallet anv√§nds h√§r en kostnadsfunktional med √§ndlig
tidshorisont.
F√∂r att best√§mma den optimala reglersignalen, som minimerar (4.1), √§r det
viktigt att specicera vad som √§r en

till√•ten reglersignal.

Den tillg√§ngliga in-

formationen som anv√§nds f√∂r att reglera systemet √§r m√§tningar av systemets
tillst√•nd vid olika tidpunkter, som p√•verkas av brus. Om
vation (3.2) f√∂r m√§tsignalen s√• √§r
v√§rdet p√• tillst√•ndsvektorn

xk .

C=I

och

G = 0 i ek-

yk = xk , det vill s√§ga m√§tningen ger det exakta

I detta fall ger inga andra f√∂reg√•ende m√§tningar

n√•gon ytterligare information om tillst√•ndet och d√• kan den till√•tna reglersignalen vara en funktion av tillst√•ndet,
form av

tillst√•nds√•terkoppling

uk = f (xk ),

det vill s√§ga regleringen √§r i

och behandlas i avsnitt 4.2.

47

KAPITEL 4.

OPTIMAL STOKASTISK REGLERING

Vanligtvis √§r matriserna

C Ã∏= I

och

G Ã∏= 0, det vill s√§ga det exakta v√§rdet p√•

tillst√•ndet √§r inte tillg√§ngligt. D√• ger m√§ngden
f√∂rdelning

ji ‚â§ k ,

(m0 , P0 )

Tuomas Virtanen

Yk ,

samt tillg√§ngliga m√§tningar

det vill s√§ga starttillst√•ndets

yj0 , . . . , yji , 0 ‚â§ j0 < . . . <
k.

den tillg√§ngliga informationen f√∂r systemet vid tidpunkt

D√• kan den

till√•tna reglersignalen endast vara en funktion av denna information, det vill s√§ga

uk = f (Yk ).
Den optimala skattningen av tillst√•ndet

ÃÇk,
x

som ges av Kalmanprediktorn

i sats 3.10 eller Kalmankorrektorn i sats 3.15, anv√§nder ocks√• den tillg√§ngliga
informationen

ÃÇ k = g(Yk ). Reglersignaler av formen uk = f (x
ÃÇk)
Yk , det vill s√§ga x

√§r allts√• till√•tna. I detta fall anv√§nds

√•terkoppling av det skattade tillst√•ndet

och

behandlas i avsnitt 4.3.
Det stokastiska reglerproblemet kan enligt [√Öst70, s. 258] formuleras p√• f√∂ljande s√§tt:

Problem 4.1.

Hitta en till√•ten reglersignal f√∂r det stokastiska systemet

xk+1 = Axk + Buk + F vk ,

(3.1)

yk = Cxk + Gwk ,

(3.2)

s√• att den kvadratiska kostnadsfunktionalen

(Ô∏Ñ

lN (x0 , u) = E xT
N SN xN +

)Ô∏Ñ

N
‚àí1
‚àëÔ∏Ç

T
(xT
k Qxk + uk Ruk )

(4.1)

k=0
minimeras.
Analogt med deterministiska fallet g√∂rs f√∂rst en omskrivning av uttrycket
innanf√∂r v√§ntev√§rdet i kostnadsfunktionalen (4.1) enligt f√∂ljande lemma [√Öst70,
Lemma 8.6.1, s. 278].

Lemma 4.2.

Anta att SN ‚â• 0, Q ‚â• 0 och R > 0 i

(4.1)

och l√•t

Lk = (B T Sk+1 B + R)‚àí1 B T Sk+1 A,

(2.18)

Sk = AT Sk+1 A + Q ‚àí AT Sk+1 B(B T Sk+1 B + R)‚àí1 B T Sk+1 A,

(2.19)

f√∂r varje k = 0, . . . , N ‚àí 1.

48

KAPITEL 4.

OPTIMAL STOKASTISK REGLERING

Tuomas Virtanen

D√• g√§ller att

xT
N SN xN +
+

N
‚àí1
‚àëÔ∏Ç

T
T
(xT
k Qxk + uk Ruk ) = x0 S0 x0 +

k=0
N
‚àí1
‚àëÔ∏Ç

N
‚àí1
‚àëÔ∏Ç

vkT F T Sk+1 F vk

k=0

(uk + Lk xk )T (B T Sk+1 B + R)(uk + Lk xk )

k=0
N
‚àí1
‚àëÔ∏Ç

+2

(4.2)

vkT F T Sk+1 (Axk + Buk ).

k=0

Bevis.

Analogt med beviset av sats 2.18 skriver vi om uttrycket i v√§nstra ledet

av (4.2) med anv√§ndning av tillst√•ndsekvation (3.1). D√• f√•s att

xT
N SN xN +

N
‚àí1
‚àëÔ∏Ç

T
(xT
k Qxk + uk Ruk )

k=0

= xT
0 S0 x0 +
= xT
0 S0 x0 +

N
‚àí1
‚àëÔ∏Ç
k=0
N
‚àí1
‚àëÔ∏Ç

(Ô∏Å T
)Ô∏Å
T
T
xk+1 Sk+1 xk+1 ‚àí xT
k Sk xk + xk Qxk + uk Ruk
(Ô∏Å T
)Ô∏Å
T
xk Qxk + uT
k Ruk ‚àí xk Sk xk

k=0

+

N
‚àí1
‚àëÔ∏Ç

(Axk + Buk + F vk )T Sk+1 (Axk + Buk + F vk )

k=0

= xT
0 S0 x0 +

N
‚àí1
‚àëÔ∏Ç

(Ô∏Å T
T S x )Ô∏Å
xk Qxk + uT
Ru
‚àí
x
k
k
k k k

k=0

+

N
‚àí1
‚àëÔ∏Ç

(Axk + Buk )T Sk+1 (Axk + Buk ) +

k=0
N
‚àí1
‚àëÔ∏Ç

+2

N
‚àí1
‚àëÔ∏Ç

vkT F T Sk+1 F vk

k=0

vkT F T Sk+1 (Axk + Buk ).

k=0
Eftersom

SN ‚â• 0, Q ‚â• 0

och

R>0

s√• √§r

Sk ‚â• 0

f√∂r varje

k = 0, . . . , N

lemma 2.21 . D√• ger lemma 2.22 att

xT
N SN xN +
+

N
‚àí1
‚àëÔ∏Ç

N
‚àí1
‚àëÔ∏Ç

k=0
N
‚àí1
‚àëÔ∏Ç

k=0

T
T
(xT
k Qxk + uk Ruk ) = x0 S0 x0 +

vkT F T Sk+1 F vk

(uk + Lk xk )T (B T Sk+1 B + R)(uk + Lk xk )

k=0
N
‚àí1
‚àëÔ∏Ç

+2

vkT F T Sk+1 (Axk + Buk ).

k=0

49

enligt

KAPITEL 4.

OPTIMAL STOKASTISK REGLERING

Tuomas Virtanen

De esta termer i (4.2) √§r av kvadratisk form och f√∂ljande lemma enligt [√Öst70, Lemma 8.3.3, s. 262] ger en enkel formel f√∂r att ber√§kna v√§ntev√§rdet
av kvadratisk form.

Lemma 4.3.

L√•t x ‚àà Rn vara en stokastisk vektor med v√§ntev√§rdet mx och

kovariansmatrisen Px . F√∂r en godtycklig matris S ‚àà Rn√ón g√§ller att

E(xT Sx) = mT
x Smx + tr(SPx ).
Bevis.

Vi har att

(Ô∏Å
)Ô∏Å
T
T
E(xT Sx) = E (x ‚àí mx )T S(x ‚àí mx ) + mT
x Sx + x Smx ‚àí mx Smx
(Ô∏Å
)Ô∏Å
T
T
= E (x ‚àí mx )T S(x ‚àí mx ) + mT
x S E(x) + E(x )Smx ‚àí mx Smx
)Ô∏Å
(Ô∏Å
= E (x ‚àí mx )T S(x ‚àí mx ) + mT
x Smx .
(4.3)
Eftersom

(x ‚àí mx )T S(x ‚àí mx )

√§r en skal√§r s√• g√§ller att

(Ô∏Ç (Ô∏Å
(Ô∏Å
)Ô∏Å
)Ô∏Å)Ô∏Ç
T
T
E (x ‚àí mx ) S(x ‚àí mx ) = E tr (x ‚àí mx ) S(x ‚àí mx ) .
Vidare eftersom

tr(AB) = tr(BA)

s√• √§r

(Ô∏Ç (Ô∏Å
(Ô∏Ç (Ô∏Å
)Ô∏Å)Ô∏Ç
)Ô∏Å)Ô∏Ç
E tr (x ‚àí mx )T S(x ‚àí mx ) = E tr S(x ‚àí mx )(x ‚àí mx )T .
Sp√•ret √§r summan av diagonalelementen och v√§ntev√§rdet av en summa √§r summan av v√§ntev√§rdena s√• kan vi byta ordningen p√• operationerna f√∂r v√§ntev√§rdet
och sp√•ret f√∂r att f√•

(Ô∏Ç (Ô∏Å
(Ô∏Ç (Ô∏Å
)Ô∏Å)Ô∏Ç
)Ô∏Å)Ô∏Ç
E tr S(x ‚àí mx )(x ‚àí mx )T = tr E S(x ‚àí mx )(x ‚àí mx )T
(Ô∏Ç
(Ô∏Å
)Ô∏Å)Ô∏Ç
= tr S E (x ‚àí mx )(x ‚àí mx )T

(4.4)

= tr(SPx ).
Ins√§ttning av (4.4) i (4.3) ger p√•st√•endet.

Anm√§rkning

4.4. Observera att lemma 4.3 kan ocks√• anv√§ndas f√∂r betingade

v√§ntev√§rdet av kvadratisk form. Om

E(x | y) = mx|y

och

Cov(x | y) = Px|y

g√§ller att

E(xT Sx | y) = mT
x|y Smx|y + tr(SPx|y ),
vilket bevisas p√• samma s√§tt som beviset f√∂r lemma 4.3.

50

s√•

KAPITEL 4.

OPTIMAL STOKASTISK REGLERING

Tuomas Virtanen

4.2 Minimering av kostnaden genom tillst√•nds√•terkoppling
I detta avsnitt best√§ms reglersignalen som minimerar kostnaden d√• den till√•tna
reglersignalen √§r en funktion av tillst√•ndet, det vill s√§ga d√• m√§tsignalen ger
exakta v√§rdet p√• alla tillst√•ndsvariabler och p√•verkas inte av n√•got m√§tbrus.
F√∂ljande lemma, som √§r en omformulering av [√Öst70, Lemma 8.3.1, s.260],
implicerar att operationen att minimera kostnaden (4.1) med avseende p√• reglersignaler som √§r funktioner av tillst√•ndet kommuterar med operationen att ta
v√§ntev√§rdet av kostnaden.

Lemma 4.5.

Anta att den till√•tna reglersignalen √§r en funktion av tillst√•ndet,

u = f (x), f : Rn ‚Üí Rm . Vidare anta att funktionen l(x, u) antar ett minsta
v√§rde i ett entydigt u f√∂r varje givet v√§rde p√• den stokastiska vektorn x.
D√• g√§ller att

(Ô∏Å
)Ô∏Å
(Ô∏Å
)Ô∏Å
min E l(x, u) = E min l(x, u) .
u

Bevis.

u

F√∂r varje till√•ten reglersignal

f (x)

g√§ller att

l(x, f (x)) ‚â• min l(x, u),
u

varf√∂r enligt (B.11) f√•s att

(Ô∏Å
)Ô∏Å
(Ô∏Å
)Ô∏Å
E l(x, f (x)) ‚â• E min l(x, u) .
u

Minimering av v√§nstra ledet med avseende p√• alla till√•tna reglersignaler

f (x)

ger att

(Ô∏Å
)Ô∏Å
(Ô∏Å
)Ô∏Å
min E l(x, u) ‚â• E min l(x, u) .
u

L√•t

u‚àó (x)

tersom

beteckna v√§rdet p√•

u‚àó (x)

u

u

f√∂r vilken

l(x, u)

(4.5)

antar sitt minsta v√§rde. Ef-

√§r en till√•ten reglersignal g√§ller samtidigt att

(Ô∏Å
)Ô∏Å
(Ô∏Å
)Ô∏Å
(Ô∏Å
)Ô∏Å
E min l(x, u) = E l(x, u‚àó (x)) ‚â• min E l(x, u) .
u

u

(4.6)

P√•st√•endet f√∂ljer fr√•n olikheterna (4.5) och (4.6).
Nu kan reglersignalen som minimerar kostnadsfunktionalen (4.1) f√∂r det stokastiska systemet med tillst√•ndsekvationen (3.1) best√§mmas enligt [√Öst70, Sats
8.6.2, s. 281], d√• det exakta tillst√•ndet √§r tillg√§ngligt.

51

KAPITEL 4.

Sats 4.6.

OPTIMAL STOKASTISK REGLERING

Tuomas Virtanen

‚àí1
Det nns en f√∂ljd av entydigt best√§mda reglersignaler u‚àó = {u‚àók }N
k=0 ,

d√§r u‚àók = f (xk ) f√∂r varje k , till systemet

xk+1 = Axk + Buk + F vk ,
yk = xk ,
som minimerar kostnadsfunktionalen

(4.1).

u‚àók = ‚àíLk xk ,
d√§r Lk ges av

(2.18)(2.19),

Vidare g√§ller att

k = 0, . . . , N ‚àí 1,

som i sats 2.18 f√∂r deterministiska fallet. Den mi-

nimala kostnaden √§r

min lN (x0 , u) = mT
0 S0 m0 + tr(S0 P0 ) +
u

N
‚àí1
‚àëÔ∏Ç

tr(F T Sk+1 F Pv ),

k=0

d√§r m0 och P0 √§r v√§ntev√§rdet respektive kovariansmatrisen f√∂r x0 och Pv √§r
kovariansmatrisen f√∂r processbruset {vk }k‚â•0 .
Bevis.

Enligt lemma 4.2 √§r kostnaden (4.1) lika med

lN (x0 , u) = E(xT
0 S0 x0 ) +

N
‚àí1
‚àëÔ∏Ç

E(vkT F T Sk+1 F vk )

k=0

+

N
‚àí1
‚àëÔ∏Ç

(Ô∏Å
)Ô∏Å
E (uk + Lk xk )T (B T Sk+1 B + R)(uk + Lk xk )

k=0
N
‚àí1
‚àëÔ∏Ç

+2

(4.7)

(Ô∏Å
)Ô∏Å
E vkT F T Sk+1 (Axk + Buk ) .

k=0
L√•t

uk = f (xk )

f√∂r n√•gon funktion

lemma 3.3 s√• √§r ocks√•

vk

N
‚àí1
‚àëÔ∏Ç

f.

oberoende av

Eftersom

uk ,

vk

√§r oberoende av

xk

enligt

vilket ger att

)Ô∏Å
(Ô∏Å
E vkT F T Sk+1 (Axk + Buk ) = 0.

(4.8)

k=0
F√∂r de √∂vriga termerna kan vi anv√§nda lemma 4.3. F√∂r det f√∂rsta har vi att

T
E(xT
0 S0 x0 ) = m0 S0 m0 + tr(S0 P0 ).
D√•

E(vk ) = 0

och

Cov(vk ) = Pv

(4.9)

f√•s f√∂r det andra att

(Ô∏Å
)Ô∏Å
E(vkT F T Sk+1 F vk ) = E(vk )T F T Sk+1 F E(vk ) + tr F T Sk+1 F Cov(vk )
= tr(F T Sk+1 F Pv ).
52

(4.10)

KAPITEL 4.

OPTIMAL STOKASTISK REGLERING

Vidare eftersom

(B T Sk+1 B + R) > 0

Tuomas Virtanen

s√• g√§ller att

lk (xk , uk ) = (uk + Lk xk )T (B T Sk+1 B + R)(uk + Lk xk ) ‚â• 0
och likhet g√§ller d√• och endast d√•

uk + Lk xk = 0,

eller

uk = ‚àíLk xk .
D√• har

lk (xk , uk )

ett minsta v√§rde

best√§ms entydigt f√∂r varje v√§rde p√•

0
xk

(4.11)

med avseende p√•

uk

f√∂r varje

k

och

uk

enligt (4.11). Lemma 4.5 ger att

(Ô∏Å
)Ô∏Å
min E (uk + Lk xk )T (B T Sk+1 B + R)(uk + Lk xk )
uk
(Ô∏Å
)Ô∏Å
= E min(uk + Lk xk )T (B T Sk+1 B + R)(uk + Lk xk ) = 0.
uk

(4.12)

Minimala kostnaden f√•s med inst√§ttning av (4.8), (4.9), (4.10) och (4.12)
i (4.7) som

min lN (x0 , u) = mT
0 S0 m0 + tr(S0 P0 ) +
u

N
‚àí1
‚àëÔ∏Ç

tr(F T Sk+1 F Pv )

k=0

+

N
‚àí1
‚àëÔ∏Ç

(Ô∏Å
)Ô∏Å
min E (uk + Lk xk )T (B T Sk+1 B + R)(uk + Lk xk )

k=0

uk

= mT
0 S0 m0 + tr(S0 P0 ) +

N
‚àí1
‚àëÔ∏Ç

tr(F T Sk+1 F Pv ),

k=0
d√•

uk = ‚àíLk xk ,

f√∂r varje

k = 0, . . . , N ‚àí 1.

Observera att reglersignalen h√§r √§r densamma som i deterministiska fallet,
det vill s√§ga processbruset p√•verkar inte valet av reglersignalen ifall systemets
tillst√•nd kan m√§tas exakt vid varje tidpunkt. Processbruset ger dock upphov
till en st√∂rre minimal kostnad √§n om systemet inte hade brus, j√§mf√∂r med den
minimala kostnaden f√∂r deterministisk optimal reglering (2.20).

53

KAPITEL 4.

OPTIMAL STOKASTISK REGLERING

Tuomas Virtanen

4.3 Minimering av kostnaden genom √•terkoppling
av det skattade tillst√•ndet
Kalmankorrektorn

ger

den

optimala

skattningen

yk

minstakvadratmening, givet m√§tningen

saknas.

P√•

basen

av

den

b√§sta

av

ÃÇk
x

av tillst√•ndet

tillg√§ngliga

optimala

xk

tillst√•ndet

och informationen

manprediktorn ger den optimala skattningen

yk

ÃÇk
x

Yl , l < k .
xk

i

Kal-

d√• m√§tningen

skattningen

kan

reglersignalen som minimerar kostnadsfunktionalen

(Ô∏Ñ

lN (x0 , u) = E xT
N SN xN +

)Ô∏Ñ

N
‚àí1
‚àëÔ∏Ç

T
(xT
k Qxk + uk Ruk )

(4.1)

k=0
best√§mmas. Reglersignalen
informationen

Yk

uk

i detta fall √§r en funktion av den tillg√§ngliga

upp till och med tidpunkten

k.

Enligt lemma 4.2 och ekvatio-

nerna (4.9) och (4.10) kan kostnadsfunktionalen (4.1) skrivas som

T
lN (x0 , u) = mT
0 S0 m0 + tr(S0 P0 ) +

N
‚àí1
‚àëÔ∏Ç

tr(F T Sk+1 F Pv )

k=0

+

N
‚àí1
‚àëÔ∏Ç

(Ô∏Å
)Ô∏Å
E (uk + Lk xk )T (B T Sk+1 B + R)(uk + Lk xk )

k=0
N
‚àí1
‚àëÔ∏Ç

+2

(Ô∏Å
)Ô∏Å
E vkT F T Sk+1 (Axk + Buk ) .

k=0
Enligt antagandena f√∂r processbruset och m√§tbruset √§r

uk = f (Yk ),

som visades i lemma 3.3. Vidare eftersom

f (y0 , . . . , yk ),

och

ma 3.3, f√∂ljer att

vk

vk

√§r oberoende av

√§r oberoende av

yn

uk .

f√∂r varje

vk

oberoende av

det vill s√§ga

n = 0, . . . , k ,

xk

uk =

enligt lem-

D√§rmed √§r alla termer i sista summan

lika med noll, det vill s√§ga

T
lN (x0 , u) = mT
0 S0 m0 + tr(S0 P0 ) +

N
‚àí1
‚àëÔ∏Ç

tr(F T Sk+1 F Pv )

k=0

+

N
‚àí1
‚àëÔ∏Ç

(4.13)

(Ô∏Å
)Ô∏Å
E (uk + Lk xk )T (B T Sk+1 B + R)(uk + Lk xk ) .

k=0
F√∂r att minimera termerna

(Ô∏Å
)Ô∏Å
E (uk + Lk xk )T (B T Sk+1 B + R)(uk + Lk xk ) s√•

beh√∂vs ett liknande hj√§lpresultat till lemma 4.5 d√§r minimeringen nu g√∂rs med
avseende p√• reglersignaler som √§r funktioner av det skattade tillst√•ndet. F√∂ljande
lemma √§r en omformulering av [√Öst70, Lemma 8.3.2, s. 261].

54

KAPITEL 4.

OPTIMAL STOKASTISK REGLERING

Tuomas Virtanen

Lemma 4.7.

Anta att den till√•tna reglersignalen √§r en funktion av m√§tsignalen,
(Ô∏Å
)Ô∏Å
u = f (y), f : Rp ‚Üí Rm . Vidare anta att funktionen g(y, u) = E l(x, y, u) | y
antar ett minsta v√§rde i ett entydigt u f√∂r varje givet v√§rde p√• den stokastiska
vektorn y .
D√• g√§ller att

(Ô∏Å
)Ô∏Å
(Ô∏Å
)Ô∏Å
(Ô∏Å
(Ô∏Å
)Ô∏Å)Ô∏Å
min E l(x, y, u) = E min g(y, u) = E min E l(x, y, u) | y .
u

Bevis.

u

F√∂r varje till√•ten reglersignal

u

f (y)

g√§ller att

(Ô∏Å
)Ô∏Å
g y, f (y) ‚â• min g(y, u),
u

eller

(Ô∏Å
)Ô∏Å
(Ô∏Å
)Ô∏Å
E l(x, y, f (y)) | y ‚â• min E l(x, y, u) | y ,
u

varf√∂r enligt B.11 f√•s att

(Ô∏Ç (Ô∏Å
(Ô∏Ç
)Ô∏Å)Ô∏Ç
(Ô∏Å
)Ô∏Å)Ô∏Ç
E E l(x, y, f (y)) | y ‚â• E min E l(x, y, u) | y ,
u

d√§r v√§nstra ledet kan skrivas med egenskap 3 i sats B.18 som

(Ô∏Å
)Ô∏Å
(Ô∏Å
)Ô∏Å)Ô∏Ç
E E l(x, y, f (y)) | y = E l(x, y, f (y)) .
(Ô∏Ç

Minimering av v√§nstra ledet med avseende p√• alla till√•tna reglersignaler

f (y)

ger att

(Ô∏Å
)Ô∏Å
(Ô∏Å
)Ô∏Å
min E l(x, y, u) ‚â• E min E(l(x, y, u) | y) .
u

L√•t

u‚àó (y)

tersom

u

beteckna v√§rdet p√•

u‚àó (y)

u

f√∂r vilken

g(y, u)

(4.14)

antar sitt minsta v√§rde. Ef-

√§r en till√•ten reglersignal g√§ller samtidigt att

(Ô∏Å
)Ô∏Å
(Ô∏Å
)Ô∏Å
E g(y, u‚àó (y)) ‚â• min E g(y, u) ,
u

det vill s√§ga

(Ô∏Å
)Ô∏Å
(Ô∏Å
)Ô∏Å
E min E(l(x, y, u) | y) ‚â• min E l(x, y, u) .
u

u

(4.15)

P√•st√•endet f√∂ljer fr√•n olikheterna (4.14) och (4.15).
Vi kan nu bevisa f√∂ljande sats som √§r huvudresultatet i denna avhandling.
Satsen √§r en generalisering av [√Öst70, Sats 8.6.3, s.282] och ger l√∂sningen till
LQG problemet ocks√• ifall m√§tningar inte g√∂rs vid varje tidpunkt.

55

KAPITEL 4.

Sats 4.8.

OPTIMAL STOKASTISK REGLERING

Tuomas Virtanen

‚àí1
‚àó
Det nns en entydig reglersignal u‚àó = {u‚àók }N
k=0 , d√§r uk = f (Yk ) f√∂r

varje k , till systemet

xk+1 = Axk + Buk + F vk ,
yk = Cxk + Gwk ,

(3.1)
(3.2)

d√§r x0 ‚àº Nn (m0 , P0 ), vk ‚àº Nn (0, Pv ) och wk ‚àº Np (0, Pw ), som minimerar
kostnadsfunktionalen

(4.1).

Reglersignalen ges av

u‚àók =

‚éß
‚é®‚àíLk x
ÃÇ k|k ,

om yk ‚àà Yk ,

‚é© ‚àíLk x
ÃÇ k|l ,

om yk ‚àà
/ Yk ,

ÃÇ k|l ges av Kalmanprediktorn
d√§r x

(3.16)

ÃÇ k|k ges av Kalmankorrektorn
och x

(3.22).

√Öterkopplingsmatrisen f√•s som i deterministiska fallet enligt

Lk = (B T Sk+1 B + R)‚àí1 B T Sk+1 A,

k = 0, . . . , N ‚àí 1

(2.18)

d√§r Sk , k = 0, . . . , N ‚àí 1 √§r l√∂sningen till Riccatiekvationen

Sk = AT Sk+1 A + Q ‚àí AT Sk+1 B(B T Sk+1 B + R)‚àí1 B T Sk+1 A

(2.19)

med begynnelsev√§rdet SN , och matriserna SN ‚â• 0, Q ‚â• 0 och R > 0 √§r givna i
kostnadsfunktionalen

(4.1).

Vidare √§r den minimala kostnaden

min lN (x0 , u) = mT
0 S0 m0 + tr(S0 P0 ) +
u

N
‚àí1
‚àëÔ∏Ç

tr(F T Sk+1 F )

k=0

+

N
‚àí1
‚àëÔ∏Ç

(4.16)

T
tr(Pk|l LT
k B Sk+1 A),

k=0

d√§r kovariansmatrisen Pk|l ges av

(3.17)

f√∂r prediktorn om l < k eller av

(3.24)

f√∂r korrektorn om l = k och yk √§r tillg√§nglig.
(Ô∏Å
)Ô∏Å
Bevis. L√•t f (Yl , uk ) = E (uk + Lk xk )T (B T Sk+1 B + R)(uk + Lk xk ) | Yl ,

uk = g(Yl )

och

l ‚â§ k.

d√§r

D√• f√•r vi enligt anm√§rkning 4.4 att

(Ô∏Å
)Ô∏Å
E (uk + Lk xk )T (B T Sk+1 B + R)(uk + Lk xk ) | Yl
= E(uk + Lk xk | Yl )T (B T Sk+1 B + R) E(uk + Lk xk | Yl )
(Ô∏Å
)Ô∏Å
+ tr (B T Sk+1 B + R) Cov(uk + Lk xk | Yl ) .
56

(4.17)

KAPITEL 4.

Eftersom

uk

OPTIMAL STOKASTISK REGLERING

√§r

Yl -m√§tbar

Tuomas Virtanen

ger sats B.18 att

ÃÇ k|l
E(uk + Lk xk | Yl ) = uk + Lk E(xk | Yl ) = uk + Lk x

(4.18)

Cov(uk + Lk xk | Yl ) = Lk Cov(xk | Yl )Lk = Lk Pk|l Lk .

(4.19)

och

Nu f√•s att

(Ô∏Å
)Ô∏Å
E (uk + Lk xk )T (B T Sk+1 B + R)(uk + Lk xk ) | Yl
ÃÇ k|l )T (B T Sk+1 B + R)(uk + Lk x
ÃÇ k|l )
= (uk + Lk x
)Ô∏Å
(Ô∏Å
+ tr (B T Sk+1 B + R)Lk Pk|l LT
k .
Eftersom

(B T Sk+1 B + R) > 0

(4.20)

s√• √§r

ÃÇ k|l )T (B T Sk+1 B + R)(uk + Lk x
ÃÇ k|l ) ‚â• 0,
(uk + Lk x
d√§r likhet f√•s d√• och endast d√•

ÃÇ k|l = 0,
uk + Lk x

eller

ÃÇ k|l .
uk = ‚àíLk x
Funktionen

k

f (Yl , uk )

(4.21)

har allts√• ett minsta v√§rde med avseende p√•

och best√§ms entydigt f√∂r varje v√§rde p√•

ÃÇ k|l
x

uk

f√∂r varje

enligt (4.21). Vi kan nu anv√§nda

lemma 4.7 och f√•r att

(Ô∏Å
)Ô∏Å
min E (uk + Lk xk )T (B T Sk+1 B + R)(uk + Lk xk )
uk
(Ô∏Ç
(Ô∏Å
)Ô∏Å)Ô∏Ç
T
T
= E min E (uk + Lk xk ) (B Sk+1 B + R)(uk + Lk xk ) | Yl .
uk

(4.22)

Ins√§ttning av (4.20) i (4.22) ger nu att

(Ô∏Å
)Ô∏Å
min E (uk + Lk xk )T (B T Sk+1 B + R)(uk + Lk xk )
uk
(Ô∏Å
)Ô∏Å
ÃÇ k|l )T (B T Sk+1 B + R)(uk + Lk x
ÃÇ k|l )
= E min(uk + Lk x
uk
(Ô∏Å
)Ô∏Å
+ tr (B T Sk+1 B + R)Lk Pk|l LT
k
(Ô∏Å
)Ô∏Å
= tr (B T Sk+1 B + R)Lk Pk|l LT
k ,
d√§r minsta v√§rdet antas d√•
av

Lk

och d√•

(4.23)

ÃÇ k|l . Vi kan skriva om (4.23) med ins√§ttning
uk = ‚àíLk x

tr(AB) = tr(BA)

f√•r vi att

)Ô∏Å
tr (B T Sk+1 B + R)Lk Pk|l LT
k
(Ô∏Å
)Ô∏Å
T
= tr Pk|l LT
k (B Sk+1 B + R)Lk
(Ô∏Å
)Ô∏Å
T
T
‚àí1 T
= tr Pk|l LT
k (B Sk+1 B + R)(B Sk+1 B + R) B Sk+1 A
)Ô∏Å
(Ô∏Å
TS
= tr Pk|l LT
B
A
.
k+1
k
(Ô∏Å

57

(4.24)

KAPITEL 4.

OPTIMAL STOKASTISK REGLERING

Tuomas Virtanen

Minsta v√§rdet (4.16) p√• kostnadsfunktionalen (4.1) f√•s nu enligt (4.13), (4.23)
och (4.24) som

T
min lN (x0 , u) = mT
0 S0 m0 + tr(S0 P0 ) +
u

N
‚àí1
‚àëÔ∏Ç

tr(F T Sk+1 F )

k=0

+

N
‚àí1
‚àëÔ∏Ç

(Ô∏Å
)Ô∏Å
min E (uk + Lk xk )T (B T Sk+1 B + R)(uk + Lk xk )
uk

k=0

T
= mT
0 S0 m0 + tr(S0 P0 ) +

N
‚àí1
‚àëÔ∏Ç

tr(F T Sk+1 F )

k=0

+

N
‚àí1
‚àëÔ∏Ç

(Ô∏Å
)Ô∏Å
TS
tr Pk|l LT
B
A
,
k+1
k

k=0
d√•

ÃÇ k|l
uk = ‚àíLk x

Anm√§rkning

f√∂r varje

k = 0, . . . , N ‚àí 1

och

l ‚â§ k.

4.9. Som p√•pekades i anm√§rkning 3.16 √§r den tillh√∂rande kovarians-

matrisen f√∂r korrektorn mindre √§n f√∂r prediktorn. Detta ger att minsta kostnaden
f√∂r regleringen f√•s om m√§tningar √§r tillg√§ngliga vid varje tidpunkt, s√• att korrektorn kan ber√§knas vid varje steg och den anv√§nda reglersignalen ber√§knas som
√•terkoppling av det skattade tillst√•ndet fr√•n korrektorn.

4.4 Optimal reglering av tv√• kopplade eln√§tverk
Problemst√§llningen med kopplade eln√§tverk √§r att reglera referenspunkterna f√∂r
belastningseekten p√• b√•da n√§tverken s√• att frekvensen p√• n√§tverken h√•lls konstant. Det intressanta med kopplade n√§tverk √§r att om det ena n√§tverket uts√§tts
f√∂r en stor √§ndring i belastningen s√• kommer mera eekt √∂da fr√•n det ena n√§tverket till det andra och referenspunkterna beh√∂ver √§ndras f√∂r b√•da n√§tverken.
F√∂r regleringen anv√§nds vanligtvis en PI- eller PID-reglerare, men h√§r anv√§nds
linj√§rkvadratisk reglering, d√§r tillst√•ndsvariablerna f√∂r systemet estimeras med
Kalmanprediktorn eller Kalmankorrektorn. F√∂r teorin om eln√§tverk och hur ekvationerna nedan beskriver systemet h√§nvisas l√§saren till [Kun94]. Ekvationerna
och anv√§nda parametrar har tagits ur artiklarna [AA11], [PMH13], [Ros+13]
och [Sha+16] som studerats f√∂r detta √§ndam√•l.

58

KAPITEL 4.

OPTIMAL STOKASTISK REGLERING

Tuomas Virtanen

Tv√• kopplade eln√§tverk beskrivs av f√∂ljande dierentialekvationer:

d‚àÜfi
dt
d‚àÜPmechi
dt
d‚àÜPGi
dt
i,j
d‚àÜPtie
dt
d√§r indexen

= ‚àí T1P i ‚àÜfi ‚àí

i,j
KP i
‚àÜPtie
TP i

= ‚àí T1T i ‚àÜPmechi +
= ‚àí T1Gi ‚àÜPGi +

och

j

KP i
‚àÜPmechi
TP i

‚àí

KP i
‚àÜPLi ,
TP i

j Ã∏= i,

1
‚àÜPGi ,
TT i

1
‚àÜPrefi
TGi

= 2œÄTi,j (‚àÜfi ‚àí ‚àÜfj ),
i

+

‚àí

(4.25)
(4.26)

1
‚àÜfi
TGi Ri

(4.27)

j Ã∏= i,

(4.28)

betecknar vilket eln√§tverk det √§r. Beteckningen

‚àÜ

anv√§nds

f√∂r att betona att tillst√•ndsvariablerna √§r avvikelser fr√•n det station√§ra v√§rdet.
Parametrarna och variablerna f√∂r n√§tverket f√∂rklaras i tabell 4.1.

Parameter

Beskrivning

TP i

Elsystemets tidskonstant

KP i

Elsystemets f√∂rst√§rkning

TT i

√Öngturbinens tidskonstant

TGi

Centrifugalregulatorns tidskonstant

Ri

√Öngturbinens reglerparameter

Ti,j

Kopplingslinans tidskonstant

fi

Frekvens

Pmech

Mekanisk eekt

PLi

Frekvensoberoende belastning

PGi

√Öngturbinens eekt

Prefi

Referenspunkt f√∂r belastningseekt

i,j

Ptie

Eekt√∂de fr√•n omr√•de

i

till

j

Tabell 4.1: Beskrivning av parametrarna och variablerna f√∂r modellen.

Om n√§tverken antas ha en konstant belastning s√• √§r

d‚àÜPLi
dt

= 0,

sm√• f√∂r√§nd-

ringar i belastningen simuleras med processbrus. Tillst√•ndsvektorerna f√∂r tv√•
n√§tverk √§r d√•

x

(1)

x(2)

(Ô∏Ç

1,2

)Ô∏ÇT

= ‚àÜf1 ‚àÜPmech1 ‚àÜPG1 ‚àÜPtie
,
(Ô∏Ç
)Ô∏ÇT
2,1
.
= ‚àÜf2 ‚àÜPmech2 ‚àÜPG2 ‚àÜPtie

59

KAPITEL 4.

OPTIMAL STOKASTISK REGLERING

Eftersom eekt√∂det f√∂r det andra systemet √§r

Tuomas Virtanen

2,1
1,2
‚àÜPtie
= ‚àí‚àÜPtie

kan vi kombi-

nera dessa tillst√•ndsvektorer till en tillst√•ndsvektor:

(Ô∏Ç
)Ô∏ÇT
1,2
x = ‚àÜf1 ‚àÜPmech1 ‚àÜPG1 ‚àÜf2 ‚àÜPmech2 ‚àÜPG2 ‚àÜPtie
.
‚àÜf1 ‚Üí 0

Fr√•n (4.28) f√•s att d√•

och

1,2
‚àÜPtie
‚Üí0

s√•

‚àÜf2 ‚Üí 0.

(4.29)

Variablerna som

kan regleras √§r referenspunkterna f√∂r belastningseekten p√• b√•da n√§tverken och

(Ô∏Ç
)Ô∏ÇT
u = ‚àÜPref1 ‚àÜPref2 . Belastningsf√∂r√§ndringar simuleras som
(Ô∏Ç
)Ô∏ÇT
v = ‚àÜPL1 ‚àÜPL2 . Systemet kan nu skrivas p√• tillst√•ndsformen

d√• √§r insignalen
processbrus

Ãá
x(t)
= Ax(t) + Bu(t) + Hv(t),
d√§r systemmatriserna f√•s ur (4.25)(4.28) som

‚éõ

‚àí TP1 1

‚éú
‚éú
0
‚éú
‚éú
‚éú‚àí (TG11R1 )
‚éú
A=‚éú
0
‚éú
‚éú
‚éú
0
‚éú
‚éú
0
‚éù
2œÄT1,2
B=
(Ô∏Ñ
H=

KP 1
TP 1
‚àí TT1 1

0

0

0

0

1

0

0

0

TT 1

0

1
‚àí TG1

0

0

0

0

0

‚àí TP1 2

0

0

0

0

KP 2
TP 2
‚àí TT1 2

0

0

‚àí (TG21R2 )

0

0

0

‚àí2œÄT1,2

0

(Ô∏Ñ
0 0 1/TG1 0 0
0 0

0

1
TT 2
1
‚àí TG2

0

0

0

0 0 ‚àíKP 2 /TP 2 0 0 0

0

‚éü
0 ‚éü
‚éü
‚éü
0 ‚éü
‚éü
KP 2 ‚éü
,
TP 2 ‚éü
‚éü
0 ‚éü
‚éü
0 ‚éü
‚é†
0

,

)Ô∏ÑT
0 0 0

0

‚éû

)Ô∏ÑT

0 0 1/TG2 0

‚àíKP 1 /TP 1 0 0

P1
‚àíK
TP 1

.

D√• processbruset modelleras med en Wienerprocess beskrivs systemet av en stokastisk dierentialekvation

dx(t) = Ax(t)dt + Bu(t)dt + HdVt .
Systemet samplas med perioden

T

och d√• f√•s det diskretiserade systemet

xk+1 = As xk + Bs uk + vk ,
d√§r matriserna ges enligt sats 3.23 av

As = e

AT

(Ô∏É‚à´Ô∏Ç
,

Bs =

As

)Ô∏É

e ds B
0

60

T

(4.30)

KAPITEL 4.

OPTIMAL STOKASTISK REGLERING

Parameter N√§tverk 1

Tuomas Virtanen

N√§tverk 2

TP i

20 s

20 s

KP i

120 Hz/MW

120 Hz/MW

TT i

0.3 s

0.3 s

TGi

0.08 s

0.08 s

Ri

2.4 Hz/MW

2.4 Hz/MW

Tabell 4.2: Anv√§nda v√§rden p√• parametrar f√∂r simuleringen

och kovariansmatrisen f√∂r det diskreta processbruset ges av (3.41)

T

‚à´Ô∏Ç
Pv =

eAœÑ HPV (eAœÑ H)T dœÑ,

0
d√§r

PV

√§r inkrementella kovariansmatrisen f√∂r Wienerprocessen

F√∂r simuleringen antar vi att

T1,2 = 0.545

‚àí5

PV = 10 I ,

A s , Bs

och

Pv

1,2
‚àÜPtie

M√§tbruset

‚àÜf1

fr√•n det f√∂rsta n√§tverket och ef-

mellan n√§tverken, s√• att utsignalen √§r

yk = Cxk + wk ,

10 I ,

kopplingslinans tidskonstant √§r

ber√§knas numeriskt med Matlab.

De m√§tbara variablerna √§r frekvensen

‚àí5

i (4.30).

och √∂vriga anv√§nda v√§rden p√• parametrarna f√∂r simuleringen hittas

i tabell 4.2. Matriserna

fekt√∂det

Vt

wk

C=

(Ô∏Ñ
)Ô∏Ñ
1 0 0 0 0 0 0
0 0 0 0 0 0 1

antas vara vitt brus, med v√§ntev√§rdet

.

0 och kovariansmatrisen

oberoende av processbruset. Kostnadsmatriserna v√§ljs enligt

Q = 5 C TC ,

R=I

och

detta s√• att kostnaden √§r endast p√• de uppm√§tta tillst√•nden och

√§r st√∂rre √§n kostnaden p√• regleringen av systemet.
Vi antar att systemet har k√∂rts en tid och √§r i ett station√§rt tillst√•nd. Detta
motiverar att starttillst√•ndets v√§ntev√§rde √§r

m0 = 0

och station√§ra tillst√•ndets

kovariansmatris kan ber√§knas med hj√§lp av sats 3.17 genom att l√∂sa den algebraiska Riccatiekvationen (3.34). L√∂sningen hittas med Matlab-funktionen `idare'
och denna kovariansmatris anv√§nds som

P0

f√∂r simuleringen.

Vi kan nu till√§mpa Sats 4.8 f√∂r att reglera systemet optimalt. Matlab-koden
f√∂r denna simulering hittas i bilaga C.2. Varje simulering g√∂rs med en belastnings√∂kning p√• n√§tverk 2 vid

t=1

s. P√• gurerna ses m√§tningen av frekvensen p√•

n√§tverk 1 uppe till v√§nster, m√§tningen av belastningen p√• kopplingslinan uppe
till h√∂ger och de nedre graferna √§r insignalen till respektive n√§tverk.

61

OPTIMAL STOKASTISK REGLERING

Tuomas Virtanen

Figur 4.1: M√§tning varje sekund, samplingstid T=1s.

KAPITEL 4.

62

Figur 4.2: M√§tning var fj√§rde sekund, samplingstid T=1s.

KAPITEL 4.
OPTIMAL STOKASTISK REGLERING

63

Tuomas Virtanen

OPTIMAL STOKASTISK REGLERING

Tuomas Virtanen

Figur 4.3: M√§tning varje sekund, samplingstid T=0.1s.

KAPITEL 4.

64

KAPITEL 5.

SAMMANFATTANDE DISKUSSION

Tuomas Virtanen

Kapitel 5
Sammanfattande diskussion
Arbetet betraktade det linj√§rkvadratiska gaussiska reglerproblemet och estimeringsproblemet f√∂r stokastiska system. Kalmanltret som ger den b√§sta skattningen av tillst√•ndsvektorn med avseende p√• det kvadratiska medelfelet delades upp
i Kalmanprediktorn och Kalmankorrektorn. En uppdelning av Kalmanltret √§r
inte vanligt i litteraturen och d√§rf√∂r bestod mycket av arbetet att rigor√∂st bevisa
att prediktorn och korrektorn ger optimala skattningar av tillst√•ndsvektorn givet den tillg√§ngliga informationen om systemet. Speciellt var det n√∂dv√§ndigt att
hitta ett s√§tt att f√• fram det betingade v√§ntev√§rdet och kovariansen f√∂r gaussiska vektorer utan att anv√§nda t√§thetsfunktionen eller f√∂rdelningsfunktionen f√∂r
normalf√∂rdelningen vilket man ofta anv√§nder som denitioner f√∂r normalf√∂rdelningen. Detta eftersom tillst√•ndsvektorns kovariansmatris kan i vissa fall vara
singul√§r, vilket den inte f√•r vara i t√§thetsfunktionen.
Behovet av uppdelningen av Kalmanltret kommer fram d√• m√§tsignalen inte
√§r tillg√§nglig vid varje tidpunkt men en optimal skattning av tillst√•ndet beh√∂vs
f√∂r regleringen. F√∂r att till√§mpa den h√§rledda teorin och p√• n√•got s√§tt f√• fram
data att optimal reglering fungerar med prediktorn och korrektorn besl√∂ts att
anv√§nda MatLab f√∂r att simulera reglering av tv√• kopplade eln√§tverk. Dierentialekvationerna och parameterv√§rdena som beskriver kopplade eln√§tverk framkom ur artiklarna som anv√§ndes. √Ñven om MatLab har f√§rdiga funktioner f√∂r
att sampla systemet och ber√§kna Kalmanf√∂rst√§rkningen f√∂r att reglera systemet
s√• anv√§ndes dessa inte eftersom de n√∂dv√§ndigtvis inte √§r exakt samma som presenterats i denna avhandling. Ist√§llet nns dessa funktioner i programmet som
hittas i bilagan.

65

KAPITEL 5.

SAMMANFATTANDE DISKUSSION

Tuomas Virtanen

M√•let med att reglera de kopplade eln√§tverken √§r att h√•lla frekvensen f√∂r eln√§tet stabilt. Simuleringarna gjordes s√• att det ena eln√§tverket uts√§tts f√∂r en stor
belastnings√∂kning och olika samplingstider och m√§tintervall unders√∂ktes. Som
det framkommer ur gurerna 4.1, 4.2 och 4.3 s√• fungerar Kalmanprediktorn utm√§rkt d√• samplingstiden och d√§rmed reglerintervallet √§r mycket kortare j√§mf√∂rt
med hur ofta en m√§tning √§r tillg√§nglig. Det l√∂nar sig allts√• att anv√§nda Kalmanprediktorn f√∂r att optimalt reglera systemet och att ha en kort samplingstid √§ven
om nya m√§tningnar √§r s√§llan tillg√§ngliga.
Det √§r v√§rt att po√§ngtera att under projektets g√•ng framkom det ocks√• att
om systemet √§r s√•dant att man √∂nskar h√•lla det i ett station√§rt tillst√•nd och
vissa villkor f√∂r systemmatriserna samt kovariansmatriserna f√∂r starttillst√•ndet
uppfylls s√• √§r det station√§ra Kalmanltret ett utm√§rkt verktyg f√∂r att ber√§kna
kovariansmatrisen f√∂r systemet.
Det kan konstateras att samplingen av ett tidskontinuerligt stokastiskt system
gicks inte igenom grundligt och endast ekvationen f√∂r tillst√•ndsvektorn samplades. Skulle m√§tsignalen och m√§tbruset ocks√• f√∂rst modelleras som en stokastisk
dierentialekvation ger samplingen upphov till att processbruset och m√§tbruset
inte n√∂dv√§ndigtvis √§r oberoende av varandra efter samplingen. I detta fall beh√∂vs
ocks√• teorin och formlerna f√∂r estimeringen och optimala regleringen uppdateras
d√§r ist√§llet f√∂r att ha tv√• olika oberoende processer f√∂r st√∂rningen i form av processbruset och m√§tbruset anv√§nds endast en st√∂rningsprocess. Detta g√∂rs delvis
i [HRS07] men d√§r √§r Kalmanltret inte uppdelat. Det kunde ocks√• vara intressant att unders√∂ka hur teorin kunde utvecklas d√• m√§tsignalen ger information
om olika tillst√•ndsvariabler vid olika tidpunkter.

66

BILAGA A.

MATRISTEORI

Tuomas Virtanen

Bilaga A
Matristeori
A.1 Matrisalgebra
L√•t

A

vara en

m√ón

‚éõ
‚éú
A=‚éú
‚éù
huvuddiagonalen

ai j , i = 1, . . . , m; j = 1, . . . , n.
‚éû

matris med reella element

A

f√∂r matrisen

a1 1

¬∑¬∑¬∑

a1 n

.
.
.

..

.
.
.

.

am 1 ¬∑ ¬∑ ¬∑

‚éü
‚éü,
‚é†

am n

ges av elementen

a1 1 , a2 2 , . . . , aq q ,

d√§r

q =

min(m, n).
Transponatet
elementen

av matrisen

A

betecknas med

AT

och √§r en

n√óm

matris med

aj i .
‚éõ
‚éú
AT = ‚éú
‚éù

F√∂r de reella matriserna

A

och

B

a1 1 ¬∑ ¬∑ ¬∑
.
.
.

..

am 1
.
.
.

.

a1 n ¬∑ ¬∑ ¬∑

‚éû
‚éü
‚éü
‚é†

am n

g√§ller att

(AB)T = B T AT .
En

kvadratisk

matris √§r en matris f√∂r vilken

m = n, det vill s√§ga den har lika

m√•nga rader som kolonner. En kvadratisk matris √§r

diagonalmatris

symmetrisk

om

AT = A. En

√§r en kvadratisk matris f√∂r vilken g√§ller att alla element utanf√∂r

huvuddiagonalen √§r nollor.

Identitetsmatrisen I

element p√• huvuddiagonalen √§r ettor. En matris

67

√§r en diagonalmatris, d√§r alla

A

√§r

ortogonal

om

AT A = I .

BILAGA A.

Rangen

MATRISTEORI

av en

m√ón

matris

Tuomas Virtanen

A

anger hur m√•nga linj√§rt oberoende rader eller

kolonner matrisen har. Det g√§ller alltid att

rang A ‚â§ min(m, n)
och om

rang A = min(m, n)

√§r matrisen
En

surjektiv

n√ón

matris

‚àí1

att

A A=I

en

h√∂gerinvers

och

och om

A

‚àí1

= I,

till matrisen

inverterbara matriser

A

rang A = n

inverterbar

√§r

AA

s√• s√§gs matrisen ha

och

Lemma A.1.

s√• √§r matrisen

A.

Inversen

B

g√§ller att

A

A‚àí1

och

‚àí1

Om

rang A = m

s√•

injektiv.

n√ón

om det nns en

det vill s√§ga

(AT )‚àí1 = (A‚àí1 )T

full rang.

matris

√§r b√•de en

A‚àí1 ,

s√•dan

v√§nsterinvers

och

√§r entydig d√• den existerar. F√∂r

(AB)‚àí1 = B ‚àí1 A‚àí1 .

L√•t S ‚àà Rm√ón och T ‚àà Rn√óm vara godtyckliga matriser. D√• √§r

ST + I inverterbar om och endast om T S + I √§r inverterbar och det g√§ller att
(ST + I)‚àí1 = I ‚àí S(T S + I)‚àí1 T .
Bevis.

Anta att

ST + I

√§r inverterbar och s√§tt

U = I ‚àí T (ST + I)‚àí1 S .

D√•

g√§ller att

(Ô∏Å
)Ô∏Å
(T S + I)U = (T S + I) I ‚àí T (ST + I)‚àí1 S
= T S ‚àí T ST (ST + I)‚àí1 S + I ‚àí T (ST + I)‚àí1 S
= T S + I ‚àí T (ST + I)(ST + I)‚àí1 S
=I
och

(Ô∏Å
)Ô∏Å
U (T S + I) = I ‚àí T (ST + I)‚àí1 S (T S + I)
= T S + I ‚àí T (ST + I)‚àí1 ST S ‚àí T (ST + I)‚àí1 S
= T S + I ‚àí T (ST + I)‚àí1 (ST + I)S
= I.
S√•ledes √§r
√§r

ST + I

U

inversen av

T S + I.

Analogt f√•s att d√•

inverterbar och inversen ges av

68

TS + I

√§r inverterbar s√•

I ‚àí S(T S + I)‚àí1 T .

BILAGA A.

Sp√•ret

MATRISTEORI

av en

m√ón

Tuomas Virtanen

A,

matris

vilket betecknas

tr(A),

√§r summan av huvud-

diagonalelementen

tr(A) = a1 1 + . . . + aq q ,
d√§r

q = min(m, n).

tr(B).

Det √§r klart att

tr(AT ) = tr(A)

och

tr(A + B) = tr(A) +

Dessutom g√§ller att

tr(AB) = tr(BA),
ifall multiplikationerna
L√•t

A

AB

BA

och

vara symmetrisk och

(A.1)

√§r denierade.

x = (x1 , x2 , . . . , xn )T

d√• √§r funktionen

Q(x) := xT Ax
en

kvadratisk form.

A ‚â• 0,

Matrisen

A

s√§gs vara

positivt semidenit,

vilket betecknas

om den √§r symmetrisk och det g√§ller att kvadratiska formen √§r icke-

negativ f√∂r varje vektor

x,

det vill s√§ga

xT Ax ‚â• 0,

‚àÄx.

Om det √§ven g√§ller att

xT Ax > 0,
s√• s√§gs

A

positivt denit,

vara

Sats A.2.

‚àÄx Ã∏= 0

vilket betecknas

A > 0.

En positivt semidenit matris A √§r positivt denit om och endast om

A √§r inverterbar.
Se [HJ12, Korollarium 7.1.7, s. 431] f√∂r bevis.

Lemma A.3.

L√•t P vara en positivt semidenit n √ó n matris och l√•t T vara en

n √ó m matris. D√• √§r T T P T positivt semidenit.
Bevis.

L√•t

x ‚àà Rm

och

y = T x.

D√• g√§ller att

xT T T P T x = y T P y ‚â• 0.

Lemma A.4.

L√•t A vara en positivt (semi)denit matris. D√• nns en en-

tydig positivt (semi)denit kvadratrot av A, vilket betecknas A1/2 , s√•dan att

A1/2 A1/2 = A.
Lemmat √§r ett specialfall av [HJ12, Sats 7.2.6, s. 439].

69

BILAGA A.

MATRISTEORI

Tuomas Virtanen

A.2 Matrisexponentialfunktionen
Matrisexponentialfunktionen

√§r en funktion f√∂r kvadratiska matriser och de-

nieras med hj√§lp av Taylorutvecklingen f√∂r den skal√§ra exponentialfunktionen
enligt

At

e

‚àû k k
‚àëÔ∏Ç
t A

:=

k!

k=0
d√§r

= I + tA +

t2
A2
2

+ ...,

(A.2)

A √§r en godtycklig kvadratisk matris. Denitionen √§r meningsfull om matris-

serien (A.2) konvergerar. Detta visas med hj√§lp av

matrisnormen, som denieras

enligt

|Ax|
.
xÃ∏=0 |x|

‚à•A‚à• = sup

Lemma A.5.

F√∂ljande egenskaper g√§ller f√∂r matrisnormen:

1. |Ax| ‚â§ ‚à•A‚à• ¬∑ |x|,
2. |ajk | ‚â§ ‚à•A‚à• f√∂r alla matriselement ajk ,
(Ô∏Ñ n
)Ô∏Ñ1/2
‚àëÔ∏Ç
3. ‚à•A‚à• ‚â§
|ajk |2
,
j,k=1

4. ‚à•A + B‚à• ‚â§ ‚à•A‚à• + ‚à•B‚à•,
5. ‚à•AB‚à• ‚â§ ‚à•A‚à• ¬∑ ‚à•B‚à•,
6. ‚à•tA‚à• = |t| ‚à•A‚à•

(t ‚àà C).

F√∂r bevis se [AB89, Lemma 2.2, s. 90].
Fr√•n egenskaperna

5.

och

6.

f√•s nu att

‚É¶ k k‚É¶ ‚Éì k‚Éì
‚É¶t A ‚É¶ ‚Éìt ‚Éì
k
‚É¶
‚É¶ ‚Éì ‚Éì
‚É¶ k! ‚É¶ ‚â§ ‚Éì k! ‚Éì ‚à•A‚à• ,
d√§r h√∂gra ledet √§r en term i en konvergent serie. Det f√∂ljer att

‚àû ‚É¶ k k‚É¶
‚àëÔ∏Ç
‚É¶t A ‚É¶
‚É¶
‚É¶
‚É¶ k! ‚É¶ < ‚àû,
k=0

vilket visar att matrisserien (A.2) √§r konvergent.

70

BILAGA A.

Sats A.6.

MATRISTEORI

Tuomas Virtanen

F√∂ljande egenskaper g√§ller f√∂r matrisexponentialfunktionen:

1. eA+B = eA ¬∑ eB

om AB = BA,

2. (eA )‚àí1 = e‚àíA ,
3.

d At
e
dt

= AeAt = eAt A,

t ‚àà R.

F√∂r bevis se [AB89, Sats 2.2, s. 93], likheten

AeAt = eAt A i egenskap 3. f√∂ljer

fr√•n denitionen (A.2).
Som f√∂ljd av egenskap

1.

och denitionen (A.2) f√•s, d√•

eA ¬∑ e‚àíA = eA‚àíA = e0 = I,
det vill s√§ga

eA

och

e‚àíA

√§r varandras inverser.

71

B = ‚àíA,

att

BILAGA B.

SANNOLIKHETSTEORI

Tuomas Virtanen

Bilaga B
Sannolikhetsteori
Som k√§lla till det h√§r kapitlet har i huvudsak [JP03], [Ros10] och [DV85] anv√§nts.

B.1 Grundl√§ggande sannolikhetsl√§ra
L√•t

‚Ñ¶ vara en icke-tom m√§ngd med elementen œâ . M√§ngden ‚Ñ¶ kallas utfallsrummet

Denition B.1.
m√§ngden

‚Ñ¶

En familj

A

‚Ñ¶

av delm√§ngder av

s√§gs vara en

œÉ -algebra

√∂ver

om det g√§ller att

1.

‚Ñ¶ ‚àà A,

2.

A ‚àà A =‚áí Ac ‚àà A

3.

A1 , A2 , . . . ‚àà A =‚áí

‚àû
‚ãÉÔ∏Å

Ai ‚àà A.

i=1
Elementen

Ai i œÉ -algebran A

Denition B.2.
œÉ -algebran A
1.

2.

En avbildning

kallas

h√§ndelser.

P : A ‚Üí [0, 1]

s√§gs vara ett

sannolikhetsm√•tt

p√•

om det g√§ller att

P(‚Ñ¶) = 1
(Ô∏É ‚àû )Ô∏É
‚àû
‚ãÉÔ∏Å
‚àëÔ∏Å
P
Ai =
P(Ai ),
i=1

d√•

A1 , A2 , . . . ‚àà A

och

Ai ‚à© Aj = ‚àÖ, i Ã∏= j.

i=1

Sannolikhetsm√•ttet ger sannolikheten f√∂r varje h√§ndelse

Ai ‚àà A.

Denition B.3. Ett sannolikhetsrum ges av trippeln (‚Ñ¶, A, P), d√§r ‚Ñ¶ √§r en icketom m√§ngd,
p√•

A

√§r

œÉ -algebran

av delm√§ngder av

A.
72

‚Ñ¶

och

P

√§r sannolikhetsm√•ttet

BILAGA B.

SANNOLIKHETSTEORI

Denition B.4.

L√•t

(‚Ñ¶, A, P)

Tuomas Virtanen

vara ett sannolikhetsrum. En avbildning

X:‚Ñ¶‚ÜíR
stokastisk variabel

s√§gs vara en

om f√∂r varje

x‚ààR

g√§ller att

{œâ ‚àà ‚Ñ¶ : X(œâ) ‚â§ x} ‚àà A
och d√• s√§gs

X

vara en

X:‚Ñ¶‚ÜíR

L√•t

m√§tbar

funktion med avseende p√•

œÉ -algebran A.

vara en stokastiskt variabel. D√• √§r

œÉ(X) := {X ‚àí1 (A) | A ‚àà A}
œÉ -algebra

en

algebran som

B.1.1

och kallas

X

œÉ -algebran som genereras av X .

Det √§r den minsta

œÉ-

√§r m√§tbar med avseende p√•.

V√§ntev√§rde och varians

Denition B.5.
variabel.

L√•t

V√§ntev√§rdet

(‚Ñ¶, A, P)
av

X

X

vara ett sannolikhetsrum och

en stokastisk

ges av

‚à´Ô∏Ç
Xd P .

E(X) :=
‚Ñ¶
F√∂r att v√§ntev√§rdet ska existera kr√§vs att

‚à´Ô∏Ç
|X| d P < ‚àû

E(|X|) =
‚Ñ¶
och d√• s√§gs

X

Variansen

vara
f√∂r

X

integrerbar.
ges av

‚à´Ô∏Ç
Var(X) :=

(X ‚àí E(X))2 d P .

‚Ñ¶
Notera att

(Ô∏Å
)Ô∏Å
Var(X) = E (X ‚àí E(X))2 = E(X 2 ) ‚àí E(X)2
och om

X2

√§r integrerbar, det vill s√§ga

E(X 2 ) < ‚àû,

s√• √§r

Var(X)

(B.1)
v√§ldenierat.

V√§ntev√§rdet √§r en linj√§r avbildning, det vill s√§ga f√∂r stokastiska variablerna

X

och

Y

och ett tal

Œ≤‚ààR

g√§ller att

E(Œ≤X) = Œ≤ E(X)
Om

X

och

Y

och

E(X + Y ) = E(X) + E(Y ).

√§r integrerbara stokastiska variabler, s√•dana att

att

E(X) ‚â§ E(Y ).
73

X ‚â§ Y,

s√• g√§ller

BILAGA B.

B.1.2

SANNOLIKHETSTEORI

Tuomas Virtanen

F√∂rdelningsfunktion

Denition B.6.

(‚Ñ¶, A, P) vara ett sannolikhetsrum och l√•t X : ‚Ñ¶ ‚Üí R vara

L√•t

en stokastisk variabel.

F√∂rdelningsfunktionen f√∂r X

√§r funktionen

FX : R ‚Üí [0, 1]

och best√§ms av

FX (x) := P(X ‚â§ x)
Om

f√∂r varje

x ‚àà R.

X1 , . . . , Xn : ‚Ñ¶ ‚Üí R √§r stokastiska variabler ges deras simultana f√∂rdelnings-

funktion

av

FX1 ,...,Xn : Rn ‚Üí [0, 1]

genom

FX1 ,...,Xn (x1 , . . . , xn ) := P(X1 ‚â§ x1 , . . . , Xn ‚â§ xn )

Denition B.7.

L√•t

xi ‚àà R, i = 1, . . . , n.

X : ‚Ñ¶ ‚Üí R vara en stokastisk variabel och l√•t FX

delningsfunktionen f√∂r

fX : R ‚Üí R,

f√∂r varje

vara f√∂r-

X . Om det existerar en icke-negativ, integrerbar funktion

s√•dan att

‚à´Ô∏Ç

x

FX (x) =

fX (u)du,
‚àí‚àû

s√• s√§gs

fX

vara

Lemma B.8.

t√§theten

f√∂r

X.

L√•t X : ‚Ñ¶ ‚Üí R vara en integrerbar stokastisk variabel med t√§t-

hetsfunktionen fX . L√•t g : R ‚Üí R och Y = g(X). D√• g√§ller att
‚à´Ô∏Ç
g(u)fX (u)du.
E(Y ) =
R

Speciellt f√•s att

‚à´Ô∏Ç

ufX (u)du och

E(X) =

‚à´Ô∏Ç
Var(X) =

R

(u ‚àí E(X))2 fX (u)du.

R

Normalf√∂rdelningen
Den stokastiska variabeln
parametrarna

Om det dessutom

X

√§r

normalf√∂rdelad

gaussisk

eller

med

2

¬µ ‚àà R och œÉ > 0, vilket betecknas med X ‚àº N (¬µ, œÉ ), om den har

t√§theten

har

X : ‚Ñ¶ ‚Üí R

1 x‚àí¬µ 2
1
fX (x) = ‚àö e‚àí 2 ( œÉ ) x ‚àà R.
œÉ 2œÄ
till√•ts att œÉ = 0 s√§gs X vara singul√§rt normalf√∂rdelad

och d√•

ingen t√§thet.

Det g√§ller att v√§ntev√§rdet och variansen f√∂r en normalf√∂rdelad stokastisk
variabel ges av

E(X) = ¬µ,

Var(X) = œÉ 2 ,

vilket kan verieras med hj√§lp av lemma B.8. Dessa parametrar best√§mmer entydigt f√∂rdelningen f√∂r en normalf√∂rdelad stokastisk variabel.

74

BILAGA B.

B.1.3
L√•t
Den

SANNOLIKHETSTEORI

Tuomas Virtanen

Oberoende stokastiska variabler

(‚Ñ¶, A, P) vara ett sannolikhetsrum och A, B ‚àà A √§r h√§ndelser med P(B) > 0.
betingade sannolikheten

f√∂r h√§ndelsen

P(A | B) :=
Man kan visa att

P(A | B)

Denition B.9.

H√§ndelserna

A

givet h√§ndelsen

B

ges av

P(A ‚à© B)
.
P(B)

(B.2)

√§r ett sannolikhetsm√•tt.

A

och

B

s√§gs vara

oberoende

om

P(A ‚à© B) = P(A) P(B).
Om

A

och

B

√§r oberoende h√§ndelser f√•s att

P(A | B) =

Denition B.10.
1. L√•t

L√•t

P(A ‚à© B)
P(A) P(B)
=
= P(A).
P(B)
P(B)

(‚Ñ¶, A, P)

vara ett sannolikhetsrum.

(Ai )i‚ààI ‚äÜ A vara œÉ -algebror. D√• s√§gs Ai

vara

oberoende œÉ -algebror

J ‚äÇ I och varje h√§ndelse Ai ‚àà Ai
(Ô∏Ñ
)Ô∏Ñ
‚àèÔ∏Ç
‚ãÇÔ∏Ç
P
P(Ai ).
Ai =

f√∂r varje √§ndlig indexm√§ngd

2. Stokastiska variabler

œÉ(Xi )

Sats B.11.

√§r oberoende

(Xi )i‚ààI

om

g√§ller att

i‚ààJ

i‚ààJ

s√§gs vara

oberoende stokastiska variabler

om

œÉ -algebror.

L√•t f, g vara integrerbara funktioner och X, Y stokastiska variabler.

D√• g√§ller att f (X) och g(Y ) √§r oberoende och

(Ô∏Å
)Ô∏Å
E f (X)g(Y ) = E(f (X)) E(g(Y )).

Denition B.12.

Kovariansen

mellan tv√• stokastiska variabler

(B.3)

X

och

Y

med

√§ndliga varianser denieras enligt

(Ô∏Å
)Ô∏Å
Cov(X, Y ) := E (X ‚àí E(X))(Y ‚àí E(Y )) = E(XY ) ‚àí E(X) E(Y ).
Om

Cov(X, Y ) = 0

D√•

X

och

Y

s√• s√§gs

X

och

Y

vara

(B.4)

okorrelerade.

√§r oberoende s√• g√§ller enligt (B.3) att

E(XY ) = E(X) E(Y ) och

s√•ledes √§r oberoende stokastiska variabler ocks√• okorrelerade, men omv√§ndningen
g√§ller vanligtvis inte.

75

BILAGA B.

B.1.4

SANNOLIKHETSTEORI

Tuomas Virtanen

Betingat v√§ntev√§rde

Denition B.13.

L√•t

(‚Ñ¶, A, P)

stokastiska variabler p√•

‚Ñ¶.

Det

vara ett sannolikhetsrum och l√•t

X

betingade v√§ntev√§rdet av X givet Y

och

Y

√§r en

vara

œÉ(Y )-

m√§tbar stokastisk variabel, betecknad

E(X | Y ),
s√•dan att

‚à´Ô∏Ç

‚à´Ô∏Ç
E(X | Y )d P

Xd P =
A

f√∂r varje

A ‚àà œÉ(Y ).

A

Denition B.14.

L√•t

stokastisk variabel p√•

(‚Ñ¶, A, P)

vara ett sannolikhetsrum och

X

en integrerbar

‚Ñ¶. L√•t V ‚äÜ A vara en œÉ -algebra. Det betingade v√§ntev√§rdet
E(X | V)

√§r en

V -m√§tbar

stokastisk variabel p√•

‚Ñ¶,

f√∂r vilken det g√§ller att

‚à´Ô∏Ç

‚à´Ô∏Ç

E(X | V)d P

Xd P =

f√∂r varje

A ‚àà V.

A

A

Fr√•n denitionerna ser man att

E(X | Y ) = E(X | œÉ(Y )).
Nedan f√∂ljer viktiga resultat f√∂r det betingade v√§ntev√§rdet. F√∂r bevis av resultaten, se [JP03, Kapitel 23, s. 197-207].

Sats B.15.

L√•t (‚Ñ¶, A, P) vara ett sannolikhetsrum. L√•t X och Y vara integrer-

bara stokastiska variabler p√• ‚Ñ¶ och V ‚äÜ A √§r en œÉ -algebra. F√∂ljande p√•st√•enden
g√§ller
1. Avbildningen X ‚Üí E(X | Y ) √§r linj√§r.
2. Det nns en funktion f , s√•dan att E(X | Y ) = f (Y ).

(Ô∏Å
)Ô∏Å
3. E E(X | Y ) = E(X).
4. E(X | Y ) = E(X) om X och Y √§r oberoende.
5. E(XY | V) = X E(Y | V) om XY √§r integrerbar och X √§r V -m√§tbar.
6. F√∂r konstanter a, b ‚àà R g√§ller att E(aX+bY | V) = a E(X | V)+b E(Y | V).
76

BILAGA B.

SANNOLIKHETSTEORI

Tuomas Virtanen

7. Olikheten X ‚â§ Y implicerar att E(X | V) ‚â§ E(Y | V).
Betingade variansen

f√∂r

X

givet

Y

denieras enligt

(Ô∏Å
)Ô∏Å
Var(X | Y ) := E (X ‚àí E(X | Y ))2 | Y
betingade kovariansen

och

kastiska variabeln

Z

mellan tv√• stokastiska variabler

X

och

Y

givet sto-

denieras enligt

(Ô∏Å
)Ô∏Å
Cov(X, Y | Z) := E (X ‚àí E(X | Z))(Y ‚àí E(Y | Z)) | Z .

B.2 Flerdimensionella stokastiska variabler
L√•t

X1 , . . . , Xn

vara stokastiska variabler p√• sannolikhetsrummet

T
kallas kolonnvektorn x := (X1 , . . . , Xn )
en

en

(‚Ñ¶, A, P).

n-dimensionell stokastisk vektor

D√•

eller

n-dimensionell stokastisk variabel.
x = (X1 , . . . , Xn )T ges av
‚à´Ô∏Ç
(Ô∏Ç‚à´Ô∏Å
)Ô∏ÇT (Ô∏Ç
)Ô∏ÇT
‚à´Ô∏Å
E(x) :=
xd P = ‚Ñ¶ X1 d P . . . ‚Ñ¶ Xn d P = E(X1 ) . . . E(Xn ) .
V√§ntev√§rdet av en stokastisk vektor

‚Ñ¶

(B.5)

stokastisk matris genom
‚éõ
‚éû
X1,1 . . . X1,n
‚éú .
‚éü
. ‚éü
..
.
.
M =‚éú
.
.
.
‚éù
‚é†
Xm,1 . . . Xm,n

P√• samma s√§tt denieras en

och v√§ntev√§rdet av en stokastisk matris ges av

‚éõ

E(X1,1 ) . . . E(X1,n )
.
.
.

‚éú
E(M ) := ‚éú
‚éù

..

.

.
.
.

‚éû
‚éü
‚éü.
‚é†

(B.6)

E(Xm,1 ) . . . E(Xm,n )
Lineariteten hos v√§ntev√§rdet g√§ller ocks√• f√∂r stokastiska vektorer och matriser.
Det g√§ller allts√• f√∂r den

n-dimensionella

stokastiska vektorn

x

att

E(Ax + b) = A E(x) + b,
d√§r

A

√§r en konstant

Det g√§ller ocks√• f√∂r

m√ón

matris och

n-dimensionella

b

en konstant

stokastiska vektorer

m-dimensionell
x1 , x2 , . . . , xk

E(x1 + x2 + . . . + xk ) = E(x1 ) + E(x2 ) + . . . + E(xk )
77

vektor.

att

BILAGA B.

SANNOLIKHETSTEORI

Kovariansmatrisen Px = Cov(x)

Tuomas Virtanen

f√∂r en stokastisk vektor

x = (X1 , . . . , Xn )T

denieras som

(Ô∏Å
)Ô∏Å
Px := E (x ‚àí E(x))(x ‚àí E(x))T

(B.7)

och enligt denitionerna (B.1), (B.4) och (B.6) f√•s att

‚éõ

‚éû
. . . (X1 ‚àí E(X1 ))(Xn ‚àí E(Xn ))
‚éú
‚éü
.
.
..
‚éü
.
.
Px = E ‚éú
.
.
.
‚éù
‚é†
2
(Xn ‚àí E(Xn ))(X1 ‚àí E(X1 )) . . .
(Xn ‚àí E(Xn ))
‚éõ
‚éû
Var(X1 )
. . . Cov(X1 , Xn )
‚éú
‚éü
.
.
..
‚éü.
.
.
=‚éú
.
.
.
‚éù
‚é†
Cov(Xn , X1 ) . . .
Var(Xn )
(X1 ‚àí E(X1 ))2

P√• samma s√§tt denieras kovariansmatrisen
stokastiska vektorer

n

x‚ààR

m

y‚ààR

och

Px,y = Cov(x, y)

mellan tv√•

som

(Ô∏Å
)Ô∏Å
Px,y := E (x ‚àí E(x))(y ‚àí E(y))T .
D√• alla par av variabler
√§r oberoende f√•s att

(Xi , Yj )

(B.8)

√§r oberoende, det vill s√§ga vektorerna

Px,y = 0 och

d√• s√§gs vektorerna

x och y

x

och

y

vara okorrelerade,

omv√§ndningen g√§ller vanligtvis inte. F√∂ljande r√§kneregler, som f√∂ljer direkt fr√•n
denitionerna och lineariteten hos v√§ntev√§rdet, g√§ller f√∂r kovariansmatrisen.

Lemma B.16. L√•t x ‚àà Rn och y ‚àà Rm vara stokastiska vektorer och l√•t A och B
vara konstanta matriser, s√•dana att multiplikationerna nedan √§r v√§ldenierade.
Det g√§ller att
T .
1. Py,x = Px,y

2. Cov(Ax ¬± By) = A Cov(x)AT ¬± A Cov(x, y)B T

¬± B Cov(y, x)AT + B Cov(y)B T .

Denition B.17.

L√•t

stokastiska vektorer p√•

(‚Ñ¶, A, P)
‚Ñ¶.

Det

vara ett sannolikhetsrum och l√•t

betingade v√§ntev√§rdet av x givet y

m√§tbar stokastisk vektor, betecknad

E(x | y),
s√•dan att

‚à´Ô∏Ç

‚à´Ô∏Ç
E(x | y)d P

xd P =
A

x

A
78

f√∂r varje

A ‚àà œÉ(y).

och

y

√§r en

vara

œÉ(y)-

BILAGA B.

SANNOLIKHETSTEORI

Tuomas Virtanen

betingade kovariansmatrisen Px|y = Cov(x | y)

Den
givet

y

f√∂r en stokastisk vektor

denieras som

(Ô∏Å
)Ô∏Å
Cov(x | y) := E (x ‚àí E(x | y))(x ‚àí E(x | y))T | y .
Den

x

(B.9)

betingade kovariansmatrisen mellan x och y givet z ges av
(Ô∏Ç(Ô∏Å
)Ô∏Å(Ô∏Å
)Ô∏ÅT ‚Éì )Ô∏Ç
Cov(x, y | z) := E x ‚àí E(x | z) y ‚àí E(y | z) ‚Éì z .

(B.10)

F√∂ljande resultat f√∂ljer fr√•n resultaten f√∂r endimensionella fallet.

Sats B.18. L√•t (‚Ñ¶, A, P) vara ett sannolikhetsrum. L√•t x och y vara integrerbara
stokastiska variabler p√• ‚Ñ¶ och œÉ(y) ‚äÜ A √§r œÉ -algebran som genereras av y .
F√∂ljande p√•st√•enden g√§ller
1. Avbildningen x ‚Üí E(x | œÉ(y)) √§r linj√§r.
2. Det nns en funktion f , s√•dan att E(x | œÉ(y)) = f (y).

(Ô∏Å
)Ô∏Å
3. E E(x | œÉ(y)) = E(x).
4. Om x √§r oberoende av y f√•s att E(x | œÉ(y)) = E(x).
5. E(xz | œÉ(y)) = x E(z | œÉ(y)) om z och xz √§r integrerbara och x √§r

œÉ(y)-m√§tbar.
6. Om x √§r œÉ(y)-m√§tbar f√•s att E(x | œÉ(y)) = x och Cov(x | œÉ(y)) = 0.
7. Cov(Ax ¬± Bz | œÉ(y)) = A Cov(x | œÉ(y))AT ¬± A Cov(x, z | œÉ(y))B T

¬± B Cov(z, x | œÉ(y))AT + B Cov(z | œÉ(y))B T .
Om de stokastiska vektorerna
olikheten

x‚â§y

att

Xi ‚â§ Yi

x

och

f√∂r varje

y

√§r av samma dimension

i = 1, . . . , n

E(x) ‚â§ E(y).

79

n

s√• betyder

och det g√§ller att

(B.11)

BILAGA B.

B.2.1

SANNOLIKHETSTEORI

p-dimensionell

Denition B.19.
malf√∂rdelade

Tuomas Virtanen

normalf√∂rdelning

X1 , . . . , X p

s√§gs vara

simultant nor-

om det g√§ller f√∂r varje f√∂ljd av reella tal

a1 , . . . , a p

att den stokas-

Stokastiska variablerna

tiska variabeln

Z :=

p
‚àëÔ∏Ç

ai X i

i=1
√§r normalf√∂rdelad. En stokastisk vektor
eller

p-dimensionellt normalf√∂rdelad

x = (X1 , . . . , Xp )T

s√§gs vara

om de stokastiska variablerna

gaussisk

X1 , . . . , X p

√§r

simultant normalf√∂rdelade.
Denna denition till√•ter att komponenterna kan vara singul√§rt normalf√∂rdelade, i vilket fall vektorn

x

saknar t√§thet i

Rp .

Ifall

x

har en t√§thet s√• kan den

gaussiska vektorn denieras med hj√§lp av den simultana t√§thetsfunktionen.
Det √§r uppenbart fr√•n denitionen att komponenterna

X1 , . . . , X p

i en

gaussisk vektor √§r gaussiska. Omv√§ndningen g√§ller n√∂dv√§ndigtvis inte, det vill
s√§ga det faktum att tv√• stokastiska variabler
inte att vektorn

x = (X1 , X2 )T

X1

och

X2

√§r gaussiska implicerar

√§r gaussisk, det √§r allts√• viktigt att de √§r ocks√•

simultant normalf√∂rdelade.
Som f√∂r den normalf√∂rdelade stokastiska variabeln s√• best√§ms f√∂rdelningen f√∂r
den gaussiska vektorn

Cov(x) = Px ,

x entydigt av v√§ntev√§rdet E(x) = ¬µ och kovariansmatrisen

vilket kan betecknas

x ‚àº Np (¬µ, Px ).

Nedan f√∂ljer n√•gra viktiga resultat f√∂r gaussiska vektorer, d√§r det tredje p√•st√•endet √§r ett √∂verraskande och anv√§ndbart resultat. F√∂r bevis, se [JP03, Sats
16.2, s. 129], [JP03, Sats 16.3, s. 130] och [JP03, Sats 16.4, s. 131].

Sats B.20.

L√•t x vara en n-dimensionell gaussisk vektor med v√§ntev√§rdet ¬µ och

l√•t y vara en m-dimensionell gaussisk vektor oberoende av x. F√∂ljande p√•st√•enden g√§ller
1. Det nns oberoende stokastiska variabler Z1 , . . . , Zn , d√§r Zi ‚àº N (0, Œªi ),

Œªi ‚â• 0, f√∂r varje 1 ‚â§ i ‚â§ n och en ortogonal matris A, s√•dan att x =
¬µ + Az , d√§r z = (Z1 , . . . , Zn )T .
(Ô∏Ñ )Ô∏Ñ
x
2. Vektorn h =
√§r gaussisk i Rn+m .
y
3. Tv√• komponenter Xj och Xk av x = (X1 , . . . , Xn )T √§r oberoende om och
endast om de √§r okorrelerade.
80

BILAGA C.

PROGRAMKOD

Tuomas Virtanen

Bilaga C
Programkod
C.1 Exempel 3.24
1

clear;

clf;

2

t = 12;

%simuleringstid i sekunder

3

dt = 0.1;

%samplingsintervall

4

dy = 0.1;

%m√§tintervall f√∂r bild 1

5

n = t/dt;

%antalet iterationer av simuleringen

6
7

%systemmatriser

8

A1 = [0, 0, 1,

9

A = expm(A1*dt);

0;0, 0,

0, 1;0, 0,

10

H = [0, 0, 1, 0;0, 0, 0, 1]';

11

C = [1, 0, 0, 0;0, 1, 0, 0];

0,

0;0, 0,

0,

0];

12
13

%processbrusets v√§ntev√§rde och kovarians

14

q1 = 1;

15

Pv = integral(@(s)expm(A1*s)*H*r*H'*expm(A1'*s),0,dt,'ArrayValued',true);

16

mv = zeros(size(A,1),1);

q2 = 1;

r = [q1^2, 0;0, q2^2];

F = eye(size(Pv,1));

17
18

%m√§tbrusets v√§ntev√§rde och kovarians

19

r1 = 0.5;

20

mw = zeros(size(C,1),1);

r2 = 0.5;

Pw = [r1^2, 0;0, r2^2];
G = eye(size(Pw,1));

21
22

%starttillst√•ndets v√§ntev√§rde och kovarians

23

m0 = zeros(size(A,1),1);

P0 = eye(size(A,1));

24

x0 = mvnrnd(m0,P0,1)';

p1 = plot(x0(1),x0(2),'b*');

25

81

hold on

BILAGA C.

PROGRAMKOD

Tuomas Virtanen

26

%allokering av variabler

27

x = cell(1,n);

y = cell(1,n);

28

x_pred = cell(1,n);

x_korr = cell(1,n);

29

P_pred = cell(1,n);

P_korr = cell(1,n);

x_est = cell(1,n);

30
31

if dy == dt %g√∂r m√§tning vid t = 0 om m√§tintervall = samplingsintervall

32
33

y0 = C*x0 + G*mvnrnd(mw,Pw,1)';
[x_est_0, P_est_0] = kf_korrektion(m0,P0,y0,C,G,Pw);

34

[x_pred{1},P_pred{1}] = kf_prediktion(x_est_0,P_est_0,A,F,Pv);

35

p3 = plot(y0(1),y0(2),'r.');

36

else

37

[x_pred{1},P_pred{1}] = kf_prediktion(m0,P0,A,F,Pv);

38

x_est_0 = m0;

39

end

40
41

p4 = plot(x_est_0(1),x_est_0(2),'k*');

42
43

for k = 1:n

44

%iterera tillst√•ndet och ber√§kna prediktionen

45

if k == 1

46
47

x{1} = A*x0 + F*mvnrnd(mv,Pv,1)';
else

48
49

=

=

=

=

=

[x_pred{k},P_pred{k}] = kf_prediktion(x_pred{k 1},P_pred{k 1},A,F,Pv);

50
51

else

[x_pred{k},P_pred{k}] = kf_prediktion(x_korr{k 1},P_korr{k 1},A,F,Pv);

52
53
54

=

x{k} = A*x{k 1} + F*mvnrnd(mv,Pv,1)';
if isempty(x_korr{k 1})

end
end

55
56

%g√∂r m√§tning och ber√§kna korrektion vid varje m√§tintervall dy

57

if mod(k*dt,dy) == 0

58

y{k} = C*x{k} + G*mvnrnd(mw,Pw,1)';
[x_korr{k},P_korr{k}] = kf_korrektion(x_pred{k},P_pred{k},y{k},C,G,Pw);

59
60

end

61
62

if isempty(x_korr{k})
x_est{k} = x_pred{k};

63
64

else
x_est{k} = x_korr{k};

65
66

end

82

BILAGA C.

67

PROGRAMKOD

Tuomas Virtanen

if k == 1

==');

68

p2 = plot([x0(1),x{1}(1)],[x0(2),x{1}(2)],'b

69

p4 = plot([x_est_0(1),x_est{k}(1)],[x_est_0(2),x_est{k}(2)],'k ');

70

else

=

=

=

==');

71

p2 = plot([x{k 1}(1),x{k}(1)],[x{k 1}(2),x{k}(2)],'b

72

p4 = plot([x_est{k 1}(1),x_est{k}(1)],[x_est{k 1}(2),x_est{k}(2)],'k ');

=

73

end

74

if mod(k*dt,dy) == 0

75

=

p3 = plot(y{k}(1),y{k}(2),'r.');

76
77

=

end
end

78
79

legend([p1; p2; p3; p4],{'Starttillst{\aa}nd','Verklig position','M{\"a}tning','
Estimat'},'Interpreter','latex');

80

hold off

81
82

function [x,P] = kf_prediktion(x,P,A,F,Q)

83

x = A * x;

84

P = A * P * A' + F * Q * F';

85

end

86
87

function [x,P] = kf_korrektion(x,P,y,C,G,R)

=

88

K = P * C' * (C * P * C' + G * R * G')^( 1);

89

x = x + K * (y

90

P = P

91

=K

=C

* x);

* C * P;

end
F√∂ljande kod k√∂rs efter ovanst√•ende kod f√∂r att ber√§kna prediktion och korrektion
med l√§ngre m√§tintervall men med samma realisering som i ovanst√•ende kod.

1

dy = 0.4;

2

x_pred = cell(1,n);

x_korr = cell(1,n);

3

P_pred = cell(1,n);

P_korr = cell(1,n);

%m√§tintervall f√∂r bild 2
x_est = cell(1,n);

4
5

[x_pred{1},P_pred{1}] = kf_prediktion(m0,P0,A,F,Pv);

6

x_est_0 = m0;

7
8
9

p1 = plot(x0(1),x0(2),'b*');
hold on
_
_
_
_
p4 = plot(x est 0(1),x est 0(2),'k*');

10
11
12

for k = 1:n
%ber√§na prediktionen

83

BILAGA C.

13

PROGRAMKOD

if k >1

Tuomas Virtanen

=

if isempty(x_korr{k 1})

14

=

=

=

=

[x_pred{k},P_pred{k}] = kf_prediktion(x_pred{k 1},P_pred{k 1},A,F,Pv);

15
16

else

[x_pred{k},P_pred{k}] = kf_prediktion(x_korr{k 1},P_korr{k 1},A,F,Pv);

17
18

end

19

end

20

%ber√§kna korrektion vid varje m√§tintervall dy

21
22

if mod(k*dt,dy) == 0
[x_korr{k},P_korr{k}] = kf_korrektion(x_pred{k},P_pred{k},y{k},C,G,Pw);

23

end

24

if isempty(x_korr{k})
x_est{k} = x_pred{k};

25
26

else
x_est{k} = x_korr{k};

27
28

end

29
30

if k == 1

==');

31

p2 = plot([x0(1),x{1}(1)],[x0(2),x{1}(2)],'b

32

p4 = plot([x_est_0(1),x_est{k}(1)],[x_est_0(2),x_est{k}(2)],'k ');

33

else

=

=

=

==');

34

p2 = plot([x{k 1}(1),x{k}(1)],[x{k 1}(2),x{k}(2)],'b

35

p4 = plot([x_est{k 1}(1),x_est{k}(1)],[x_est{k 1}(2),x_est{k}(2)],'k ');

36

end

37

if mod(k*dt,dy) == 0

38

=

=

p3 = plot(y{k}(1),y{k}(2),'r.');

39
40

=

end
end

41
42

legend([p1; p2; p3; p4],{'Starttillst{\aa}nd','Verklig position','M{\"a}tning','
Estimat'},'Interpreter','latex');

hold off

43
44

function [x,P] = kf_prediktion(x,P,A,F,Q)

45

x = A * x;

46

P = A * P * A' + F * Q * F';

47

end

48

function [x,P] = kf_korrektion(x,P,y,C,G,R)

=

49

K = P * C' * (C * P * C' + G * R * G')^( 1);

50

x = x + K * (y

51

P = P

52

=K

=C

* x);

* C * P;

end

84

BILAGA C.

PROGRAMKOD

Tuomas Virtanen

C.2 Kopplade eln√§tverk
1

clear;

clf;

2

t = 100;

%simuleringstid i sekunder

3

dy = 1;

%m√§tintervall

4

dt = 1;

%samplingsintervall

5

du = dt;

%reglerintervall

6

n = t/dt;

7
8

tp1 = 20;

tp2 = 20;

9

kp1 = 120;

kp2 = 120;

10

tt1 = 0.3;

tt2 = 0.3;

11

tg1 = 0.08;

tg2 = 0.08;

12

r1 = 2.4;

r2 = 2.4;

13

t12 = 0.545;

14
15

%systemmatriser

16

A1 = [ 1/tp1, kp1/tp1,

17

=

0,

18

=1/(tg1*r1),

19

=1/tt1,

0,

0,

0,

0,

=kp1/tp1;

1/tt1,

0,

0,

0,

0;

0,

0,

0,

0;

kp2/tp2,

0,

kp2/tp2;

1/tt2,

0;

0,

=1/tg1,

0,

0,

0,

=1/tp2,

20

0,

0,

0,

0,

21

0,

0,

22

2*pi*t12,

0,

=1/(tg2*r2),
0,
=2*pi*t12,
0,

=1/tt2,

0,

=1/tg2,

0,

0,

23
24
25
26

B1 = [0, 0, 1/tg1, 0, 0,
0, 0,

0, 0;

0, 0, 0, 1/tg2, 0]';

=

27

H1 = [ kp1/tp1, 0, 0,

28

0, 0, 0,

0, 0, 0, 0;

=kp2/tp2,

0, 0, 0]';

29
30
31

C = [1, 0, 0, 0, 0, 0, 0;
0, 0, 0, 0, 0, 0, 1];

32
33

%Wienerprocessens inkrementella kovarians

34

Ph = 10^ 5 * eye(size(H1,2));

=

35
36

%sampla systemet

37

A = expm(A1*dt);

38

B = integral(@(s)expm(A1*s),0,dt,'ArrayValued',true)*B1;

39

H = integral(@(s)expm(A1*s),0,dt,'ArrayValued',true)*H1;

85

0;
0];

BILAGA C.

PROGRAMKOD

Tuomas Virtanen

40
41

%processbrusets v√§ntev√§rde och kovarians

42

Pv = integral(@(s)expm(A1*s)*H1*Ph*H1'*(expm(A1*s)'),0,dt,'ArrayValued',true);

43

mv = zeros(size(Pv,1),1);

44

F = eye(size(Pv,1));

45
46

%m√§tbrusets v√§ntev√§rde och kovarians

47

Pw = 10^ 5 * eye(size(C,1));

48

mw = zeros(size(C,1),1);

49

G = eye(size(Pw,1));

=

50
51

%starttillst√•ndets v√§ntev√§rde och kovarians

52

m0 = zeros(size(A,1),1);

53

P0 = idare(A',C',F*Pv*(F'),Pw);

54

x0 = m0;

55
56

%kostnadsmatriser

57

Q = 5*(C')*C;

58

R = eye(size(B,2));

59

SN = zeros(size(Q));

60
61
62

%L√∂s Riccatiekvationen och ber√§kna √•terkopplingsmatriserna f√∂r regleringen i
f√∂rv√§g
[L0, L, S0, S] = aterkoppling(A,B,SN,Q,R,n);

63
64

%allokering av variabler

65

x = cell(1,n);

y = cell(1,n);

66

x_pred = cell(1,n);

x_korr = cell(1,n);

67

P_pred = cell(1,n);

P_korr = cell(1,n);

68

v = cell(1,n);

w = cell(1,n);

u = cell(1,n);

69
70

%slumpa process- och m√§tbruset

71

v0 = mvnrnd(mv,Pv,1)';

72

w0 = mvnrnd(mw,Pw,1)';

73

for k = 1:n

74

v{k} = mvnrnd(mv,Pv,1)';

75

w{k} = mvnrnd(mw,Pw,1)';

76

end

77
78

%best√§m styrsignalen vid tid t = 0 och ber√§kna prediktionen

79

if dy == dt

80

%om m√§tning g√∂rs vid tid 0 ber√§kna korrektionen

y0 = C*x0 + w0;

86

BILAGA C.

PROGRAMKOD

Tuomas Virtanen

81

[x_korr_0,P_korr_0] = kf_korrektion(m0,P0,y0,C,G,Pw);

82

u0 =

83
84

=

L0*x_korr_0;
_
[x pred{1},P_pred{1}] = kf_prediktion(x_korr_0,P_korr_0,A,B,u0,F,Pv);

else

85

x_pred_0 = m0;

86

u0 =

87

[x_pred{1},P_pred{1}] = kf_prediktion(x_pred_0,P0,A,B,u0,F,Pv);

88

=L0*x_pred_0;

end

89
90

for k = 1:n

91

%iterera tillst√•ndet och ber√§kna prediktionen

92

if k == 1

93

% H ‚àó [0; 1] simulerar en 0.1% √∂kning p√• n√§tverk 2

94

x{1} = A*x0 +B*u0 + H*[0; 1] + F*v0;

95
96

else

=

=

=

x{k} = A*x{k 1} + B*u{k 1} + F*v{k 1};

97

=

if isempty(x_korr{k 1})

98

=

=

=

=

[x_pred{k},P_pred{k}] = kf_prediktion(x_pred{k 1},P_pred{k 1},A,B,u{

99

=

k 1},F,Pv);
100

else

[x_pred{k},P_pred{k}] = kf_prediktion(x_korr{k 1},P_korr{k 1},A,B,u{

101

=

k 1},F,Pv);
102

end

103

end

104

%g√∂r m√§tning och ber√§kna korrektion vid varje m√§tintervall dy

105

if mod(k*dt,dy) == 0

106

y{k} = C*x{k} + G*w{k};
[x_korr{k},P_korr{k}] = kf_korrektion(x_pred{k},P_pred{k},y{k},C,G,Pw);

107
108

end

109

%ber√§kna styrsignalen

110

if mod(k*dt,du) == 0
if isempty(x_korr{k})

111
112
113

u{k} =
else

114
115
116
117
118
119

u{k} =

=L{k}*x_pred{k};
=L{k}*x_korr{k};

end
else
if k == 1
u{1} = u0;
else

87

BILAGA C.

Tuomas Virtanen

=

120

u{k} = u{k 1};

121

end

122
123

PROGRAMKOD

end
end

124
125

%plotta m√§tningarna och styrsignalerna

126

for k = 1:n

127

if k == 1

128

if exist('y0','var')

129

s1 = subplot(2,2,1); plot(0,y0(1),'r.'); hold on;

130

s2 = subplot(2,2,2); plot(0,y0(2),'r.'); hold on;

131

else

132

s1 = subplot(2,2,1); hold on;

133

s2 = subplot(2,2,2); hold on;

134

end

135

s3 = subplot(2,2,3); plot([(k 1)*dt,k*dt],[u0(1),u0(1)],'b '); hold on

136

s4 = subplot(2,2,4);

137

=
=
plot([(k=1)*dt,k*dt],[u0(2),u0(2)],'b=');

hold on

else

138

if ~isempty(y{k})

=
plot((k=1)*dt,y{k}(2),'r.');

139

s1 = subplot(2,2,1); plot((k 1)*dt,y{k}(1),'r.');

140

s2 = subplot(2,2,2);

141

end

142

s3 = subplot(2,2,3); plot([(k 1)*dt,k*dt],[u{k 1}(1),u{k 1}(1)],'b ');

143

s4 = subplot(2,2,4);

144

end

145

if k == n

=
=
=
=
plot([(k=1)*dt,k*dt],[u{k=1}(2),u{k=1}(2)],'b=');

146

subplot(2,2,1); plot([0,t],[0,0],'k:');

hold off

147

subplot(2,2,2); plot([0,t],[0,0],'k:');

hold off

148

subplot(2,2,3); plot([0,t],[0,0],'k:');

hold off

149

subplot(2,2,4); plot([0,t],[0,0],'k:');

hold off

150

end

151

end

152

xlabel(s1, 'tid (s)'); ylabel(s1, '\Delta w_1');

153

xlabel(s2, 'tid (s)'); ylabel(s2, '\Delta P_{tie}');

154

xlabel(s3, 'tid (s)'); ylabel(s3, '\Delta P_{ref1}');

155

xlabel(s4, 'tid (s)'); ylabel(s4, '\Delta P_{ref2}');

156

h = zoom;

h.Motion = 'vertical';

h.Enable = 'on';

157
158

function [x,P] = kf_prediktion(x,P,A,B,u,F,Pv)

159

%Prediktionen av tillst√•ndet

160

x = A * x + B * u;

88

BILAGA C.

PROGRAMKOD

161

%Prediktionens kovarians

162

P = A * P * A' + F * Pv * F';

163

Tuomas Virtanen

end

164
165

function [x,P] = kf_korrektion(x,P,y,C,G,Pw)

166

%Kalmanf√∂rst√§rkningen

167

K = P * C' * (C * P * C' + G * Pw * G')^( 1);

168

%Korrektionen av tillst√•ndet

169

x = x + K * (y

170

%Korrektionens kovarians

171

P = P

172

=K

=C

=

* x);

* C * P;

end

173
174

function [L0, L, S0, S] = aterkoppling(A,B,SN,Q,R,n)

175
176

L = cell(n,1);

177

S = cell(n,1);

178

=

179

L{n} = (B'*SN*B + R)^( 1)*B'*SN*A;

180

S{n} = A'*SN*A + Q

181

= A'*SN*B*(B'*SN*B

=

182

for i = 1:n 1

=
=
=
S{n=i} = A'*S{n=i+1}*A + Q...
= A'*S{n=i+1}*B*(B'*S{n=i+1}*B

183

=

L{n i} = (B'*S{n i+1}*B + R)^( 1)*B'*S{n i+1}*A;

184
185
186

=

=

+ R)^( 1)*B'*S{n i+1}*A;

end

187

=

188

L0 = (B'*S{1}*B + R)^( 1)*B'*S{1}*A;

189

S0 = A'*S{1}*A + Q

190

=

+ R)^( 1)*B'*SN*A;

= A'*S{1}*B*(B'*S{1}*B

end

89

=

+ R)^( 1)*B'*S{1}*A;

LITTERATUR

Tuomas Virtanen

Litteratur
[AA11]

Ehab S. Ali och Sahar M. Abd-Elazim.  Bacteria foraging optimization algorithm based load frequency controller for interconnected
power system. I:

Systems

Internationa Journal of Electrical Power & Energy

33 (3 2011), s. 633638. doi:

10.1016/j.ijepes.2010.12.

022.
[AB89]

Karl G. Andersson och Lars-Christer B√∂iers.

lekvationer.
[DGG86]

Ordin√§ra dierentia-

Lund: Studentlitteratur AB, 1989, s. vi+358.

Carlos E. De Souza, Michel R. Gevers och Graham C. Goodwin.  Riccati equations in optimal ltering of nonstabilizable systems having
singular state transition matrices. I:

tic Control

IEEE Transactions on Automa-

AC-31.9 (1986), s. 831838. doi:

10.1109/TAC.1986.

1104415.
[DV85]

M. H. A. Davis och R. B. Vinter.

Stochastic modelling and control.

Monographs on Statistics and Applied Probability. Chapman & Hall,
London, 1985, s. xii+393. doi:
[Gir03]

Narayan C. Giri.

10.1007/978-94-009-4828-0.

Multivariate statistical analysis.

2. utg. New York:

Marcel Dekker, 2003, s. xiv+558.
[HJ12]

Roger A. Horn och Charles R. Johnson.

Matrix Analysis. 2. utg. New

York, NY, USA: Cambridge University Press, 2012, s. xviii+643.
[HRS07]

Christiaan Heij, Andr√© Ran och Freek van Schagen.

Introduction to

mathematical systems theory: Linear systems, identication and control. Birkh√§user Verlag, Basel, 2007, s. x+166. doi: 10.1007/978-3-

7643-7549-2.

90

LITTERATUR

[JP03]

Tuomas Virtanen

Jean Jacod och Philip Protter.

Probability essentials.

sitext. Springer-Verlag, Berlin, 2003, s. x+254. doi:

2. utg. Univer-

10.1007/978-

3-642-55682-1.
[Kal60]

Rudolph E. Kalman.  A New Approach to Linear Filtering and Prediction Problems. I:

Engineering
[Kay93]

Transactions of the ASMEJournal of Basic

82.1 (1960), s. 3545. doi:

10.1115/1.3662552.

Steven M. Kay.

Fundamentals of Statistical Signal Processing: Esti-

mation Theory.

Upper Saddle River, NJ, USA: Prentice-Hall, Inc.,

1993, s. xii+595.
[Kun94]

Prabha S. Kundur.

Power System Stability and Control.

McGraw-

Hill, Inc., 1994.
[LR95]

Peter Lancaster och Leiba Rodman.

Algebraic Riccati Equations. Ox-

ford science publications. Clarendon Press, jan. 1995, s. xvii+480.
[Lue79]

David G. Luenberger.

Introduction to dynamic systems: Theory, Mo-

dels, and Applications.
[LXP08]

New York: Wiley, 1979, s. xvi+446.

Frank L. Lewis, Lihua Xie och Dan Popa.

Optimal and robust estima-

tion: with an introduction to stochastic control theory.

2. utg. Boca

Raton: Taylor & Francis, 2008, s. xxii+523.
[PMH13]

Sidhartha Panda, Banaja Mohanty och Prakash K. Hota.  Hybrid
BFOAPSO algorithm for automatic generation control of linear and
nonlinear interconnected power systems. I:
13 (12 2013), s. 47181730. doi:

[Ros+13]

Applied Soft Computing

10.1016/j.asoc.2013.07.021.

Samira Roshany-Yamchi m. .  Kalman Filter-Based Distributed Predictive Control of Large-Scale Multi-Rate Systems: Application to Power Networks. I:

IEEE Transactions on Control Systems Technology

21.1 (2013), s. 2739. doi:
[Ros10]

Sheldon M. Ross.

10.1109/TCST.2011.2172444.

A First Course in Probability. 8. utg. Pearson Pren-

tice Hall, 2010, s. xiv+530.
[Sha+16]

Nilaykumar N. Shah m. .  Automatic load frequency control of two
area system using L-Q-R method. I:

Engineering and Scientic Research

21276/Ijcesr.
91

International Journal of Current
3 (6 2016), s. 5466. doi:

10.

LITTERATUR

[S√§r13]

Simo S√§rkk√§.

Tuomas Virtanen

Bayesian Filtering and Smoothing.

Vol. 3. Institute

of Mathematical Statistics Textbooks. Cambridge University Press,
2013, s. xxii+232. doi:
[TSH01]

10.1017/CBO9781139344203.

Harry L. Trentelman, Anton A. Stoorvogel och Malo Hautus.

theory for linear systems.

Control

Communications and Control Engineering

Series. Springer-Verlag London, Ltd., London, 2001, s. xvi+389. doi:

10.1007/978-1-4471-0339-4.
[√Öst70]

Karl J. √Östr√∂m.

Introduction to stochastic control theory.

Mathema-

tics in Science and Engineering, Vol. 70. Academic Press, New YorkLondon, 1970, s. xiv+299.
[√òks98]

Bernt √òksendal.

Stochastic Dierential Equations. An Introduction

with Applications.

5. utg. Universitext. Springer-Verlag, 1998. doi:

10.1007/978-3-662-03620-4.

92

